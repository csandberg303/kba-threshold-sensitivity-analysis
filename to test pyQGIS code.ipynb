{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e245c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import datetime\n",
    "import pathlib\n",
    "import requests\n",
    "import io\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "# from qgis.core import *\n",
    "\n",
    "import earthpy as et\n",
    "import geopandas as gpd\n",
    "import marxanconpy as mx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import kba_thresh_sa_scripts as ks\n",
    "\n",
    "# set global cache override variable\n",
    "CACHE_OVERRIDE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2de00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open full hex.shp file\n",
    "fullhex_data_path = os.path.join(data_path, \"hex_shp\", 'Hex_7mi2.shp')\n",
    "fullhex_layer = gpd.read_file(fullhex_data_path)\n",
    "\n",
    "# Reproject CRS to ESPG 5070\n",
    "fullhex_layer_5070 = fullhex_layer.to_crs(epsg='5070')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83adaf8",
   "metadata": {},
   "source": [
    "### Working with qmarxan functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b49960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write formula to create 'bound.dat' file\n",
    "(# code below taken from 'qmarxan_toolbox_algorithm.py')\n",
    "\n",
    "# # Constants used to refer to parameters and outputs. They will be\n",
    "# # used when calling the algorithm from another algorithm, or when\n",
    "# # calling from the QGIS console.\n",
    "\n",
    "# PU_LAYER = 'PU_LAYER'\n",
    "# PU_FIELD = 'PU_FIELD'\n",
    "# BND_METHOD = 'BND_METHOD'\n",
    "# BND_TREAT = 'BND_TREAT'\n",
    "# BND_VALUE = 'BND_VALUE'\n",
    "# CALC_FIELD = 'CALC_FIELD'\n",
    "# CALC_METHOD = 'CALC_METHOD'\n",
    "# TOL = 'TOL'\n",
    "# OUT_DIR = 'OUT_DIR'\n",
    "\n",
    "# def create_bound_dat(???self, config???):\n",
    "#         \"\"\"\n",
    "#         Here we define the inputs and output of the algorithm, along\n",
    "#         with some other properties.\n",
    "#         \"\"\"\n",
    "#         # pu layer\n",
    "#         self.addParameter(\n",
    "#                 self.PU_LAYER,\n",
    "#                 self.tr('Planning unit layer (source for bound.dat file)'),\n",
    "#                 [QgsProcessing.TypeVectorPolygon]\n",
    "#             )\n",
    "#         )\n",
    "#         # pu id\n",
    "#         self.addParameter(\n",
    "#             QgsProcessingParameterField(\n",
    "#                 self.PU_FIELD,\n",
    "#                 self.tr('Planning unit id field'),\n",
    "#                 parentLayerParameterName=self.PU_LAYER,\n",
    "#                 type=QgsProcessingParameterField.Numeric\n",
    "#             )\n",
    "#         )\n",
    "#         #\n",
    "#         # advanced settings\n",
    "#         #\n",
    "#         #  bnd method\n",
    "#         bndMethod = QgsProcessingParameterEnum(\n",
    "#             self.BND_METHOD,\n",
    "#             self.tr('Boundary method (how lengths between planning units will be set)'),\n",
    "#             options = [\"Single\",\"Measured\",\"Weighted\",\"Field\"],\n",
    "#             defaultValue = 0\n",
    "#         )\n",
    "#         bndMethod.setFlags(bndMethod.flags() | QgsProcessingParameterDefinition.FlagAdvanced)\n",
    "#         self.addParameter(bndMethod)\n",
    "#         # bnd treatment\n",
    "#         bndTreatment = QgsProcessingParameterEnum(\n",
    "#             self.BND_TREAT,\n",
    "#             self.tr('Boundary treatment (how values for PUs on perimeter of study area will be set)'),\n",
    "#             options = [\"Full Value\",\"Half Value\",\"Exclude\"],\n",
    "#             defaultValue = 0\n",
    "#         )\n",
    "#         bndTreatment.setFlags(bndTreatment.flags() | QgsProcessingParameterDefinition.FlagAdvanced)\n",
    "#         self.addParameter(bndTreatment)\n",
    "#         # single value\n",
    "#         bndValue = QgsProcessingParameterNumber(\n",
    "#             self.BND_VALUE,\n",
    "#             self.tr('Boundary value (value for all boundaries regardless of measured length)'),\n",
    "#             type=QgsProcessingParameterNumber.Integer, \n",
    "#             minValue=0, \n",
    "#             defaultValue=1,\n",
    "#             optional=True\n",
    "#         )\n",
    "#         bndValue.setFlags(bndValue.flags() | QgsProcessingParameterDefinition.FlagAdvanced )\n",
    "#         self.addParameter(bndValue)\n",
    "#         # calculation field\n",
    "#         calcField = QgsProcessingParameterField(\n",
    "#             self.CALC_FIELD,\n",
    "#             self.tr('Calculation field (field to weight or assign boundary lengths)'),\n",
    "#             parentLayerParameterName=self.PU_LAYER,\n",
    "#             type=QgsProcessingParameterField.Numeric,\n",
    "#             optional = True\n",
    "#         )\n",
    "#         calcField.setFlags(calcField.flags() | QgsProcessingParameterDefinition.FlagAdvanced)\n",
    "#         self.addParameter(calcField)\n",
    "#         # calculation method\n",
    "#         calcMethod = QgsProcessingParameterEnum(\n",
    "#             self.CALC_METHOD,\n",
    "#             self.tr('Calculation method (how to assign boundary length if values between adjacent planning units differ)'),\n",
    "#             options = [\"Mean\",\"Maximum\",\"Minimum\"],\n",
    "#             defaultValue = 0,\n",
    "#             optional = True\n",
    "#         )\n",
    "#         calcMethod.setFlags(calcMethod.flags() | QgsProcessingParameterDefinition.FlagAdvanced)\n",
    "#         self.addParameter(calcMethod)\n",
    "#         # rounding precision\n",
    "#         tolerance = QgsProcessingParameterEnum(\n",
    "#             self.TOL,\n",
    "#             self.tr('Export precision tolerance (in map units)'),\n",
    "#             options = [\"100\",\"10\",\"1\",\"0.1\",\"0.01\",\"0.001\",\"0.0001\",\"0.00001\"],\n",
    "#             defaultValue = 3\n",
    "#         )\n",
    "#         tolerance.setFlags(tolerance.flags() | QgsProcessingParameterDefinition.FlagAdvanced)\n",
    "#         self.addParameter(tolerance)\n",
    "\n",
    "#         # select output folder\n",
    "#         defDir = os.path.join(os.path.expanduser('~'),'marxanproj1','input')\n",
    "#         self.addParameter(\n",
    "#             QgsProcessingParameterFolderDestination(\n",
    "#                 self.OUT_DIR,\n",
    "#                 self.tr('Marxan input folder (place to write bound.dat file)'),\n",
    "#                 defDir,\n",
    "#                 optional=False\n",
    "#             )\n",
    "#         )\n",
    "#   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0344a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bound.dat\n",
    "# Code pasted from 'qmarxan_toolbox_algorithm' (lines ~500-765) \n",
    "# https://github.com/tsw-apropos/qmarxantoolbox/blob/master/QMarxanToolbox/qmarxan_toolbox_algorithm.py\n",
    "\n",
    "# create temporary file names \n",
    "        tempsegfile = 'tempsegfile_%s.txt' % os.getpid()\n",
    "        tempsortedfile = 'tempsortedfile_%s.txt' % os.getpid()\n",
    "        tempadjfile = 'tempadjfile_%s.txt' % os.getpid()\n",
    "        tempsortedadjfile = 'tempsortedadjfile_%s.txt' % os.getpid()\n",
    "        errorlog = 'topo_error_log_%s.txt' % datetime.date.today().isoformat()\n",
    "        # get field indexes for puid and boundary fields\n",
    "        puIdx = self.puLayer.dataProvider().fields().indexFromName(self.puField)\n",
    "        if self.bndField != None:\n",
    "            fldIdx = self.puLayer.dataProvider().fields().indexFromName(self.bndField)\n",
    "        else:\n",
    "            fldIdx = -1\n",
    "\n",
    "\n",
    "# step 1 - build temporary segment file and dictionary\n",
    "#         #\n",
    "#         # notify users\n",
    "#         feedback.setProgress(0)\n",
    "        # set values\n",
    "        tsf = open(tempsegfile,'w')\n",
    "        inGeom = QgsGeometry()\n",
    "        segLineCnt = 0\n",
    "        # loop through features\n",
    "        lineCount = 0\n",
    "        fCount = self.puLayer.dataProvider().featureCount()\n",
    "#         x = 0\n",
    "#         progPct = 0\n",
    "#         progMin = 0\n",
    "#         progMax = 30\n",
    "#         progPct = progMin\n",
    "#         lastPct = progPct\n",
    "#         progRange = progMax - progMin\n",
    "        for feat in self.puLayer.getFeatures():\n",
    "#             x += 1\n",
    "#             progPct = ((float(x) / float(fCount) * 100) * (progRange/100.0)) + progMin\n",
    "#             if int(progPct) > lastPct:\n",
    "#                 feedback.setProgress(progPct)\n",
    "#                 lastPct = progPct\n",
    "            attr = feat.attributes()\n",
    "            pid = int(attr[puIdx])\n",
    "            if fldIdx != -1:\n",
    "                cost = str(attr[fldIdx])\n",
    "            else:\n",
    "                cost = '1.0'\n",
    "            inGeom = feat.geometry()\n",
    "            pointList = extractPoints(inGeom)\n",
    "            prevPoint = 0\n",
    "            for i in pointList:\n",
    "                if prevPoint == 0:\n",
    "                    prevPoint = i\n",
    "                else:\n",
    "                    # write line segment\n",
    "                    segLen = LineLength([prevPoint[0],prevPoint[1]], [i[0],i[1]])\n",
    "                    # make spatial key to segment file\n",
    "                    if round(float(prevPoint[0]),self.tol) < round(float(i[0]),self.tol) or \\\n",
    "                        (round(float(prevPoint[0]),self.tol) == round(float(i[0]),self.tol) \\\n",
    "                        and round(float(prevPoint[1]),self.tol) < round(float(i[1]),self.tol) ):\n",
    "                        skey = str(round(float(prevPoint[0]),self.tol)) + '|' + \\\n",
    "                            str(round(float(prevPoint[1]),self.tol)) + '|' + \\\n",
    "                            str(round(float(i[0]),self.tol)) + '|' +  \\\n",
    "                            str(round(float(i[1]),self.tol))\n",
    "                    else:\n",
    "                        skey = str(round(float(i[0]),self.tol)) + '|' +  \\\n",
    "                            str(round(float(i[1]),self.tol)) + '|' + \\\n",
    "                            str(round(float(prevPoint[0]),self.tol)) + '|' + \\\n",
    "                            str(round(float(prevPoint[1]),self.tol))\n",
    "                    if segLen > 0:\n",
    "                        outLine = '%s,%d,%f,%f\\n' %  (skey, int(pid), float(cost), segLen)\n",
    "                        tsf.write(outLine)\n",
    "                        lineCount += 1\n",
    "                    prevPoint = i\n",
    "        # clean up\n",
    "        tsf.close()\n",
    "        # sort the file\n",
    "        self.batch_sort(tempsegfile, tempsortedfile)\n",
    "        os.remove(tempsegfile)\n",
    "        #\n",
    "        # step 2 - loop through sorted file and create adjacency file\n",
    "        #    \n",
    "        # notify users\n",
    "        # \n",
    "        tsf = open(tempsortedfile,'r')\n",
    "        taf = open(tempadjfile,'w')\n",
    "        done = False\n",
    "        pl = ''\n",
    "        x = 0\n",
    "        adjFileLen = 0\n",
    "#         progMin = 35\n",
    "#         progMax = 65\n",
    "#         progPct = progMin\n",
    "#         lastPct = progPct\n",
    "#         progRange = progMax - progMin\n",
    "        while not done:\n",
    "#             x += 1\n",
    "#             progPct = ((float(x) / float(lineCount) * 100) * (progRange/100.0)) + progMin\n",
    "#             if int(progPct) > lastPct:\n",
    "#                 feedback.setProgress(progPct)\n",
    "#                 lastPct = progPct\n",
    "            line = tsf.readline()\n",
    "            if line == '':\n",
    "                done = True\n",
    "            else:\n",
    "                cl = line.rstrip().split(',')\n",
    "            if pl != '' and pl != ['']:\n",
    "                if cl != '' and pl[0] == cl[0]:\n",
    "                    fCost = 1\n",
    "                    if self.bndMethod == 'Single':\n",
    "                        fCost = str(self.bndValue)\n",
    "                    elif self.bndMethod == 'Field':\n",
    "                        bCost = 1\n",
    "                        if float(pl[2])== float(cl[2]):\n",
    "                            bCost = float(pl[2])\n",
    "                        else:\n",
    "                            if self.calcMethod == 'Maximum':\n",
    "                                bCost = max([float(pl[2]),float(cl[2])])\n",
    "                            elif self.calcMethod == 'Minimum':\n",
    "                                bCost = min([float(pl[2]),float(cl[2])])\n",
    "                            else:\n",
    "                                bCost = (float(pl[2]) + float(cl[2]))/2.0\n",
    "                        fCost = str(bCost)\n",
    "                    elif self.bndMethod  == 'Weighted':\n",
    "                        bCost = 1\n",
    "                        if float(pl[2])== float(cl[2]):\n",
    "                            bCost = float(pl[2])\n",
    "                        else:\n",
    "                            if self.calcMethod == 'Maximum':\n",
    "                                bCost = max([float(pl[2]),float(cl[2])])\n",
    "                            elif self.calcMethod == 'Minimum':\n",
    "                                bCost = min([float(pl[2]),float(cl[2])])\n",
    "                            else:\n",
    "                                bCost = sum([float(pl[2]),float(cl[2])])/2.0\n",
    "                        fCost = str(float(pl[3]) * bCost)\n",
    "                    else:\n",
    "                        fCost = str(pl[3])\n",
    "                    # topology error test\n",
    "                    # check for more matching lines\n",
    "                    errorLines = True\n",
    "                    topologyErrorFound = False\n",
    "                    pids = ''\n",
    "                    while errorLines:\n",
    "                        line = tsf.readline()\n",
    "                        chkLine = line.rstrip().split(',')\n",
    "                        if chkLine != '' and chkLine[0] == pl[0]:\n",
    "                            topologyErrorFound = True\n",
    "                            # an error exists\n",
    "                            if pids == '':\n",
    "                                pids = str(pl[1]) + ',' + str(cl[1]) + ',' + str(chkLine[1])\n",
    "                            else:\n",
    "                                pids = pids + ',' + str(chkLine[1])\n",
    "                        else:\n",
    "                            errorLines = False\n",
    "                    if topologyErrorFound:\n",
    "                        if topoErrorCount == 0:\n",
    "                            el = open(errorlog, 'w')\n",
    "                            outline = 'There should never be more than 2 overlapping ' + \\\n",
    "                                'line segments. \\n' + \\\n",
    "                                'Below are listed cases where more than 2 have ' + \\\n",
    "                                'been identified. \\n' + 'These should all be ' + \\\n",
    "                                'corrected before using the boundary file\\n' + \\\n",
    "                                '-------\\n' \n",
    "                            el.write(outline)\n",
    "                        outline = 'Line segments defined as %s may be topologically invalid.\\n' % (str(pl[0]))\n",
    "                        outline = outline + 'Area ids %s appear to overlap.\\n--\\n' % (pids) \n",
    "                        el.write(outline)\n",
    "                        topoErrorCount += 1\n",
    "                    else:\n",
    "                        # no error proceed\n",
    "                        if int(pl[1]) < int(cl[1]):\n",
    "                            taf.write('%020d,%020d,%s\\n' % (int(pl[1]),int(cl[1]),fCost))\n",
    "                        else:\n",
    "                            taf.write('%020d,%020d,%s\\n' % (int(cl[1]),int(pl[1]),fCost))\n",
    "                        adjFileLen += 1\n",
    "                elif type(pl) == list:\n",
    "                    fCost = 1\n",
    "                    if self.bndMethod == 'Single':\n",
    "                        fCost = str(self.bndValue)\n",
    "                    elif self.bndMethod  == 'Field':\n",
    "                        fCost = str(pl[2])\n",
    "                    elif self.bndMethod  == 'Weighted':\n",
    "                        fCost = str(float(pl[3]) * float(pl[2]))\n",
    "                    else:\n",
    "                        fCost = str(pl[3])\n",
    "                    taf.write('%020d,%020d,%s\\n' % (int(pl[1]),int(pl[1]),fCost))\n",
    "            pl = line.rstrip().split(',')\n",
    "        tsf.close()\n",
    "        taf.close()\n",
    "        os.remove(tempsortedfile)\n",
    "        # sort adjacency file\n",
    "        self.batch_sort(tempadjfile, tempsortedadjfile)\n",
    "        os.remove(tempadjfile)\n",
    "        #\n",
    "        # step 3 - write boundary file\n",
    "        #\n",
    "        # notify users\n",
    "        #\n",
    "        saf = open(tempsortedadjfile,'r')\n",
    "        faf = open(self.outFName,'w')\n",
    "        faf.write(\"id1\\tid2\\tboundary\\n\")\n",
    "        done = False\n",
    "        pl = ''\n",
    "#         x = 0\n",
    "#         progMin = 70\n",
    "#         progMax = 99\n",
    "#         progPct = progMin\n",
    "#         lastPct = progPct\n",
    "#         progRange = progMax - progMin\n",
    "        while not done:\n",
    "#             x += 1\n",
    "#             progPct = ((float(x) / float(adjFileLen) * 100) * (progRange/100.0)) + progMin\n",
    "#             if int(progPct) > lastPct:\n",
    "#                 feedback.setProgress(progPct)\n",
    "#                 lastPct = progPct\n",
    "            line = saf.readline()\n",
    "            if line == '':\n",
    "                done = True\n",
    "                cl = ''\n",
    "            else:\n",
    "                cl = line.rstrip().split(',')\n",
    "            if pl != '':\n",
    "                if cl != '' and pl[0] == cl[0] and pl[1] == cl[1]:\n",
    "                    if self.bndMethod  == 'Measured' or self.bndMethod == 'Weighted':\n",
    "                        # NOTE: \n",
    "                        # If weighted or measured methods are used\n",
    "                        # then all the segments' lengths are added together\n",
    "                        #\n",
    "                        # If Single or Field methods are used\n",
    "                        # then only the first rows values are used as all \n",
    "                        # other rows are redundant\n",
    "                        pl = [pl[0],pl[1],sum([float(pl[2]),float(cl[2])])]\n",
    "                else:\n",
    "                    bound = adjBound(float(pl[2]),pl[0],pl[1])\n",
    "                    if self.bndMethod  in ('Field','Weighted'):\n",
    "                        boundStr = str(bound)\n",
    "                    else:\n",
    "                        boundStr = str(round(float(bound),self.tol))\n",
    "                    if float(bound) > 0.0:\n",
    "                        faf.write('%d\\t%d\\t%s\\n' % (int(pl[0]),int(pl[1]),boundStr))\n",
    "                    pl = line.rstrip().split(',')\n",
    "            else:\n",
    "                pl = cl\n",
    "        saf.close()\n",
    "        faf.close()\n",
    "        os.remove(tempsortedadjfile)\n",
    "        if topoErrorCount > 0:\n",
    "            el.close()\n",
    "            messageText = '%d possible topological error(s) found. ' % topoErrorCount\n",
    "            messageText += 'Please check error log in same directory as boundary file.'\n",
    "            feedback.pushInfo(messageText)\n",
    "            return {'Status':'Error'}\n",
    "        else:\n",
    "            feedback.pushInfo('Boundary file successfully written')\n",
    "            return {'Status':'Success'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf26a26",
   "metadata": {},
   "source": [
    "FUNCTION TO CREATE PUVSP.DAT & SPEC.DAT (PUVSP_SPORDER.DAT not needed, as currently we are looking at only one ecosystem at a time)\n",
    "\n",
    "find code to replicate the Zonal Histogram tool in QGIS (Processing Toolbox > Raster Analysis > Zonal Histogram) https://docs.qgis.org/3.22/en/docs/user_manual/processing_algs/qgis/rasteranalysis.html#zonal-histogram import processing processing.run(\"algorithm_id\", {parameter_dictionary})\n",
    "I think this comes from pyQGIS, but I don't think that is included with the earth-analytics-python-env??\n",
    "\n",
    "Here's info on running pyQGIS in Jupyter https://lerryws.xyz/posts/PyQGIS-in-Jupyter-Notebook\n",
    "\n",
    "here's my initial guess, using parameters copied from QGIS 'Zonal Histograms' log - from qgis.core import processing processing.run(\"native:zonalhistogram\", { 'COLUMN_PREFIX' : '', 'INPUT_RASTER' : 'F:/NatureServe/LanasData/raster/foothill_r.tif', 'INPUT_VECTOR' : 'F:/NatureServe/LanasData/marxan_prep/foothill/pulayercws.shp', 'OUTPUT' : 'F:/NatureServe/pulayerfeatures.shp', 'RASTER_BAND' : 1 })\n",
    "\n",
    "add column, multiplying pixel count by raster pixel area variable (our data's is 900, 30m x 30m = 900 sq m/pixel), this gives total extent of ecosystem within each individual planning unit hex of the hexfile.shp (ex. if pixelcount = 5, area = 4500, or 5 x 900)\n",
    "\n",
    "use this as the source info for qmarxan 'export feature files' function input parameters copied from QGIS - Input parameters: { 'FEAT_FIELDS' : ['7147'], 'OUT_DIR' : 'F:\\NatureServe\\524 QM test\\input', 'PU_FIELD' : 'PUID', 'PU_LAYER' : 'F:/NatureServe/pulayerfeatures.shp' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c26ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE FUNCTION TO CREATE PUVSP.DAT & SPEC.DAT\n",
    "# (PUVSP_SPORDER.DAT not needed, as currently we are working with just one one \n",
    "# ecosystem at a time, rather than looking at mulitiple conservation features \n",
    "# in a single run)\n",
    "\n",
    "# find code to replicate the Zonal Histogram tool in QGIS \n",
    "# (Processing Toolbox > Raster Analysis > Zonal Histogram) \n",
    "# https://docs.qgis.org/3.22/en/docs/user_manual/processing_algs/qgis/\n",
    "# rasteranalysis.html#zonal-histogram \n",
    "# import processing processing.run(\"algorithm_id\", {parameter_dictionary})\n",
    "\n",
    "# I think the 'import processing' code suggestion comes from pyQGIS, but I \n",
    "# don't think that is included with the earth-analytics-python-env??\n",
    "\n",
    "# Here's info on running pyQGIS in Jupyter \n",
    "# https://lerryws.xyz/posts/PyQGIS-in-Jupyter-Notebook\n",
    "\n",
    "# here's my initial guess at some of the pyQGIS code, using parameters copied \n",
    "# from the QGIS 'Zonal Histograms' log window - \n",
    "from qgis.core import processing processing.run(\n",
    "    \"native:zonalhistogram\", { \n",
    "        'COLUMN_PREFIX' : '', \n",
    "        'INPUT_RASTER' : 'F:/NatureServe/LanasData/raster/foothill_r.tif', \n",
    "        'INPUT_VECTOR' : 'F:/NatureServe/LanasData/marxan_prep/foothill/pulayercws.shp', \n",
    "        'OUTPUT' : 'F:/NatureServe/pulayerfeatures.shp', \n",
    "        'RASTER_BAND' : 1 \n",
    "    })\n",
    "\n",
    "# the result will show the number of raster pixels within each hexgrid cell.\n",
    "\n",
    "# add new column, multiplying this pixel count by the raster pixel area \n",
    "# variable, to give the total extent of ecosystem within each individual \n",
    "# planning unit hex cell.\n",
    "# the pixel area can be determined by looking at the raster saved to the \n",
    "# 'source_data' directory in an earlier formula. Maybe a new function should \n",
    "# be written to get this value, and that function would be called within this\n",
    "# current 'create_puvsp_dat' function? \n",
    "# (our data's pixel area is 900, as 30m x 30m = 900 sq m/pixel. If the \n",
    "# pixelcount = 5, area = 4500, or 5 x 900)\n",
    "\n",
    "# use this table (dataframe?) as the source info for qmarxan 'export feature\n",
    "# files' function (WHICH WOULD ALSO CREATE THE SPEC.DAT FILE)\n",
    "\n",
    "# input parameters copied from QGIS 'export_features_files' log window - \n",
    "Input parameters: { \n",
    "    'FEAT_FIELDS' : ['7147'], \n",
    "    'OUT_DIR' : 'F:\\NatureServe\\524 QM test\\input', \n",
    "    'PU_FIELD' : 'PUID', \n",
    "    'PU_LAYER' : 'F:/NatureServe/pulayerfeatures.shp' \n",
    "}\n",
    "\n",
    "# or try this -\n",
    "# Zonal Statistics Algorithm with Python in 4 Steps\n",
    "# How to summarize raster data for polygon zones\n",
    "# https://towardsdatascience.com/zonal-statistics-algorithm-with-python-in-4-steps-382a3b66648a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adfd00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .qmarxan_utils import runMarxanOnce"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
