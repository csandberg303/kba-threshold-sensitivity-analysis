{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fb7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import datetime\n",
    "import io\n",
    "import requests\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "# from qgis.core import *\n",
    "\n",
    "import earthpy as et\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.plot import plotting_extent\n",
    "import rioxarray as rxr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ebb959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to get Lana's input files (created with ArcGIS) from the \n",
    "# repo to local directory \n",
    "def get_marxan_input_files(eco, files_to_get):\n",
    "     \"\"\"\n",
    "     Currently this formula will find the input files Lana created using the\n",
    "     ArcMarxan Toolbox plugin in ArcGIS, which have been stored to the assets\n",
    "     directory of our GitHub repository.  We hope this may be a placeholder\n",
    "     function, to be replaced with functions that might create these files \n",
    "     directly using the opensource code available from the opensource QMarxan \n",
    "     Toolbox plugin for QGIS.\n",
    "\n",
    "     Parameters\n",
    "     ----------\n",
    "     eco : str\n",
    "     the abbreviated one word short name used for ecosystem being analyzed; \n",
    "     identifies a subdirectory of the timestamped marxan run directory\n",
    "     \n",
    "     files_to_get : list\n",
    "     list of filenames to retrieve from the marxan_input/eco directory of \n",
    "     the repo\n",
    "\n",
    "     -------\n",
    "     returned_data : the specified dat files, saved to eco/input local \n",
    "     directory\n",
    "     \"\"\"\n",
    "     inputfile_ls = files_to_get\n",
    "     \n",
    "     for file in inputfile_ls:\n",
    "        urltext = (\"https://raw.githubusercontent.com/csandberg303/\"\n",
    "                   \"kba-threshold-sensitivity-analysis/main/assets/data/\"\n",
    "                   \"marxan_input/\")\n",
    "        url = urltext + eco + \"/\" + file\n",
    "        # downloading the info from file stored on github\n",
    "        fileinfo = requests.get(url).content\n",
    "        # Reading the downloaded content and turning it to a pandas dataframe\n",
    "        fileinfo_df = pd.read_csv(io.StringIO(fileinfo.decode('utf-8')),\n",
    "                                 index_col=False).squeeze(\"columns\")\n",
    "        filename = file\n",
    "        output = fileinfo_df.to_csv(file, index=False)\n",
    "        print(eco + \": \" + file + \" successfully copied from url\")\n",
    "     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ad2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write formula to get the shapefile and rasters that have been saved to the \n",
    "#''kba_thres_sa/shp_hex' and 'kba_thres_sa/r_tif' local directories\n",
    "\n",
    "# Currently I've manually copied Lana's ArcGIS files to these locations, using \n",
    "# the naming convention 'eco.shp' for hexfiles and 'eco.tif for the rasters.\n",
    "\n",
    "# IN THE FUTURE, the .shp & .tif files may be created and placed in the \n",
    "# 'shp_hex' and 'r_tif' directories using code rather than ArcGIS, but this \n",
    "# 'get_source_files' formula will still function to copy the needed files into\n",
    "# the 'eco' directory when the 'eco/input' directories are created.\n",
    "def get_source_files(path, eco):\n",
    "    \"\"\"\n",
    "    path : str\n",
    "    local directory where the shapefiles or rasters are stored\n",
    "    \n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem being analyzed; \n",
    "    identifies a subdirectory of the timestamped marxan run directory\n",
    "     \n",
    "    \"\"\"\n",
    "    source_file_ls = glob(os.path.join(path, eco + '*'))\n",
    "    if source_file_ls == []:\n",
    "        print(\"no files found in \" + path + \"with expected name \" + eco + \"?\")\n",
    "    else:\n",
    "        for file in source_file_ls:\n",
    "            shutil.copy(file, os.getcwd())\n",
    "            print(eco + \": \"+ os.path.basename(file) + \" copied successfully\")\n",
    "         \n",
    "    return print(eco + \": finished copying source files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6fba6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set crs of shp and tif to ESPG 5070 and save as new files\n",
    "\n",
    "def set_source_files_crs (path, eco, espg='5070'):\n",
    "    \"\"\"\n",
    "    To set crs of shp and tif to ESPG 5070, add columns to shp and save as new \n",
    "    files\n",
    "\n",
    "    Parameters\n",
    "    ----------     \n",
    "    path : str\n",
    "    path to local 'kba_thresh_sa' directory where 'hex_shp' and 'r_tif' \n",
    "    directories are stored\n",
    "        \n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem being analyzed; \n",
    "    identifies a subdirectory of the timestamped marxan run directory\n",
    "    \n",
    "    espg : str\n",
    "    espg number (we're using ESPG:5070)\n",
    "     \n",
    "    -------\n",
    "    returned_data : updated shp and tif \n",
    "         \n",
    "\n",
    "    \"\"\"\n",
    "    # open the shp and tif files saved at given path\n",
    "    shp_data_path = os.path.join(path, \"hex_shp\", eco + '.shp')\n",
    "    shp_layer = gpd.read_file(shp_data_path)\n",
    "    \n",
    "    tif_data_path = os.path.join(path, \"r_tif\", eco + '.tif')\n",
    "    tif_layer = rxr.open_rasterio(tif_data_path, masked=True).squeeze()\n",
    "\n",
    "    # reproject CRS of shp\n",
    "    shp_layer_crs = shp_layer.to_crs(epsg=espg)\n",
    "    \n",
    "    # create shp output variable\n",
    "    shp_espg_file = shp_layer_crs.to_file(eco + \"_espg_\" + espg + \".shp\", \n",
    "                                          index=False)\n",
    "\n",
    "    # reproject CRS of tif\n",
    "    # create a rasterio crs object \n",
    "    crs_espg = CRS.from_string('EPSG:' + espg)\n",
    "    # reproject tif using the crs object\n",
    "    tif_layer_crs = tif_layer.rio.reproject(crs_espg)\n",
    "    \n",
    "    # create path that new tif file will be saved to\n",
    "    tif_layer_crs_path = os.path.join(os.getcwd(), \n",
    "                                      eco + \"_espg_\" + espg + \".tif\")\n",
    "    # create tif output variable\n",
    "    tif_espg_file = tif_layer_crs.rio.to_raster(tif_layer_crs_path)\n",
    "    \n",
    "    # save the reprojected .shp and .tif files\n",
    "    output = (shp_espg_file, tif_espg_file)\n",
    "    \n",
    "    print(eco + \": finished set_source_files_crs\")\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9ab349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create pu.dat file \n",
    "\n",
    "def create_pu_dat(eco, path):\n",
    "    \"\"\"\n",
    "    To create the pu.dat file that stores information about planning units in \n",
    "    hex grid\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem being analyzed; \n",
    "    identifies a subdirectory of the timestamped marxan run directory\n",
    "    \n",
    "    path : str\n",
    "    local directory where 'hex_shp' directory is stored\n",
    "     \n",
    "    -------\n",
    "    returned_data : the pu.dat input file \n",
    "         \n",
    "    \"\"\"\n",
    "\n",
    "    # open hex.shp file with set crs\n",
    "    shp_crs_path = glob(os.path.join(path, eco + '_espg_*.shp'))   \n",
    "    \n",
    "    # create df based on hexfile.shp\n",
    "    shp_crs_layer = gpd.read_file(shp_crs_path[0])\n",
    "        \n",
    "    # create new column in .shp for 'id'    \n",
    "    shp_crs_layer.insert(0, 'id', range(1, 1 + len(shp_crs_layer)))\n",
    "    \n",
    "    # set values in column 'Cost' to 1, and column 'Status' to = 0\n",
    "    shp_crs_layer[\"Cost\"] = 1\n",
    "    shp_crs_layer[\"Status\"] = 0\n",
    "    \n",
    "    # create pu.dat file\n",
    "    pu_dat = shp_crs_layer[[\"id\", \"Cost\", \"Status\"]].set_index(\"id\")\n",
    "    output = pu_dat.to_csv('pu.dat')\n",
    "    print(eco + \": pu.dat file successfully created\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "515f3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to create spec.dat file\n",
    "\n",
    "def create_spec_dat(info_df, eco, prop=0.3, spf=1, minclump=False):\n",
    "    \"\"\"\n",
    "    To create the spec.dat file, which stores information about ecosytem to be \n",
    "    analyzed in marxan run\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    info_df : df\n",
    "    dataframe of ecosystem info, including 'Short_Name', 'US_km2' and\n",
    "    'Current_IUCN_TH' columns\n",
    "     \n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem being analyzed; \n",
    "    identifies a subdirectory of the timestamped marxan run directory\n",
    "    \n",
    "    prop : float\n",
    "    The proportion of the total amount of the feature which must be included \n",
    "    in the solution; must be between 0 and 1 (tutorial suggests 0.3)\n",
    "     \n",
    "    spf : int\n",
    "    species penalty factor\n",
    "     \n",
    "    minclump : bool\n",
    "    determines if additional field 'target2' should be included in results, \n",
    "    to show the 'Minimum clump size for the representation of conservation \n",
    "    features in the reserve system'. Default set to 'False'.  If 'True', \n",
    "    'target2' column is added, with the minimum clump size calculated as the \n",
    "    ecosystem's extent in meters ('US_km2' * 1,000,000) by it's current IUCN\n",
    "    Threshold value ('Current_IUCN_TH' = .05 if CR or EN, or 0.10 if VU)\n",
    "    -------\n",
    "     \n",
    "    returned_data : the spec.dat input file \n",
    "         \n",
    "    \"\"\"\n",
    "    # set columns of spec.dat, if minclump parameter is False\n",
    "    if minclump == False:\n",
    "        data = [{'id': 1, 'prop': prop, 'spf': 1, 'name': eco}]\n",
    "    # include add'l 'target2' column in file if minclump parameter is True\n",
    "    else:\n",
    "        target2 = info_df.at[eco,'Current_IUCN_TH'] * (\n",
    "            info_df.at[eco,'US_km2'] * 1000000)\n",
    "        data = [{'id': 1, 'prop': prop, 'target2': target2, 'spf': 1, \n",
    "                 'name': eco}]    \n",
    "    # set index, and save file as 'spec.dat'\n",
    "    spec_dat = pd.DataFrame(data).set_index('id')\n",
    "    output = spec_dat.to_csv('spec.dat')\n",
    "    print(eco + \": spec.dat file successfully created\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b1b19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to write targets.csv files, for each threshold test value\n",
    "\n",
    "# NOT SURE IF THIS WILL ULTIMATELY BE NEEDED IN ITS CURRENT FORM, AS THE \n",
    "#TARGETS INPUT FILE MIGHT ONLY BE USED BY THE QGIS ADDIN CLUZ, RATHER THAN \n",
    "# MARXAN/MARXANCONPY ITSELF\n",
    "\n",
    "def create_cluz_targets_files(eco, thresholds_test, eco_info, path):\n",
    "    \"\"\"creates the targets.csv files needed for Marxan analysis \n",
    "    (?? only when using CLUZ add-in in QGIS ??).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem being analyzed; \n",
    "    identifies a subdirectory of the timestamped marxan run directory\n",
    "\n",
    "    thresholds_test : list\n",
    "    list of threshold values to be tested for each ecosystem\n",
    "\n",
    "    eco_info : dataframe\n",
    "    source of info for each ecosystem, with columns 'OID' (Unique ID number),\n",
    "    'Name' (ecosystem name), Type (number representing RLE Status), Size of \n",
    "    Ecosystem (units of area measurement) and the Current IUCN Threshold \n",
    "    value, based upon ecosystem's RLE status\n",
    "\n",
    "    path : filepath\n",
    "    filepath to ecosystem subdirectory where targets files will be saved\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    returned_data : csv\n",
    "    csv files are saved to ecosystem directories, one file for each threshold\n",
    "    value to be tested\n",
    "    \"\"\"\n",
    "    for val in thresholds_test:\n",
    "           target_info = {'Id': [eco_info.loc[eco]['OID']], \n",
    "                          'Name': [eco], \n",
    "                          'Type': [eco_info.loc[eco]['Type']], \n",
    "                          'sq_km': [eco_info.loc[eco]['US_km2']],\n",
    "                          'iucn_th': [eco_info.loc[eco]['Current_IUCN_TH']]}\n",
    "           target_df = pd.DataFrame(data=target_info).set_index('Id')\n",
    "           target_df['Target'] = (target_df['sq_km'] * target_df['iucn_th'])\n",
    "           target_df['Target'] = (val * target_df['Target'])\n",
    "           target_df.drop([\"sq_km\", \"iucn_th\"], axis = 1, inplace = True)\n",
    "           outpath = os.path.join(path, 'targets_' +str(val) + '.csv')\n",
    "           output = target_df.to_csv(outpath)\n",
    "    print(eco + \": targets files created for each test threshold value\")       \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18781b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THESE FUNCTIONS ARE TAKEN/ADAPTED FROM QMARXAN TOOLBOX ALGORITHM CODE\n",
    "\n",
    "# taken from lines ~98-104 of QMarxan algorithm\n",
    "\n",
    "# formatAsME - format as Marxan Exponent format like \n",
    "        #              Input File Editor\n",
    "        #\n",
    "def formatAsME(inVal):\n",
    "    outStr = \"%.14E\" % float(inVal)\n",
    "    parts = outStr.split('E')\n",
    "    sign = parts[1][:1]\n",
    "    exponent = \"%04d\" % float(parts[1][1:])\n",
    "    outStr = parts[0] + 'E' +  sign + exponent\n",
    "    return(outStr)\n",
    "\n",
    "\n",
    "\n",
    "# TO CREATE INPUT.DAT (LINES 128-183 OF ALGORITHM FILE)\n",
    "def create_input_dat(dest, prop=0.5, scen_id=(\"eco_xyz\")):\n",
    "    \"\"\"\n",
    "    To create the input.dat file that stores processing parameters\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dest : str\n",
    "    directory input.dat file will be saved to\n",
    "     \n",
    "    prop : float\n",
    "    must be a number between 0 and 1; represents the proportion of PU to be\n",
    "    included in the initial reserve (default value is 0.5)\n",
    "     \n",
    "    scen_id : str\n",
    "    scenario id, info to be included as prefix on generated output files\n",
    "     \n",
    "    other parameters will be added to replace the default initial values \n",
    "    that are included in the QMarxan code \n",
    "\n",
    "    -------\n",
    "    returned_data : the input.dat file \n",
    "         \n",
    "    \"\"\"\n",
    "    output = os.path.join(dest,'input.dat')\n",
    "    f = open(output, 'w')\n",
    "    f.write(\"Input file for Annealing program.\\n\")\n",
    "#     f.write('\\n')\n",
    "    f.write('This file generated for KBA Threshold\\n')\n",
    "    f.write('Analysis project using code from\\n')\n",
    "    f.write('QMarxan Toolbox 2.0\\n')\n",
    "    f.write('created by Apropos Information Systems Inc.\\n')\n",
    "#     f.write('\\n')\n",
    "    f.write(\"General Parameters\\n\")\n",
    "    f.write(\"BLM 1\\n\") # Boundary Length Modifier\n",
    "    f.write(\"PROP %s\\n\" % formatAsME(prop)) # Proportion of PU (or sub TARGET)\n",
    "    f.write(\"RANDSEED -1\\n\") # Random seed number\n",
    "    f.write(\"NUMREPS 100\\n\") # Num of repeat runs (or solutions)\n",
    "#     f.write('\\n')    \n",
    "    f.write(\"Annealing Parameters\\n\")\n",
    "    f.write(\"NUMITNS 1000000\\n\") # Num of iterations for annealing\n",
    "    f.write(\"STARTTEMP %s\\n\" % formatAsME(-1.0)) # start temp for annealing\n",
    "    f.write(\"COOLFAC %s\\n\" % formatAsME(-1.0)) # cooling factor for annealing\n",
    "    f.write(\"NUMTEMP 10000\\n\") # num of temp decreases for annealing\n",
    "    f.write(\"\")\n",
    "    f.write(\"Cost Threshold\\n\") \n",
    "    f.write(\"COSTTHRESH %s\\n\" % formatAsME(0.0)) # cost threshold\n",
    "    f.write(\"THRESHPEN1 %s\\n\" % formatAsME(0.0)) # size of cost thresh penalty\n",
    "    f.write(\"THRESHPEN2 %s\\n\" % formatAsME(0.0)) # shp of cost thresh penalty\n",
    "#     f.write(\"\\n\")\n",
    "    f.write(\"Input Files\\n\")\n",
    "    f.write(\"INPUTDIR input\\n\") # name of dir containing input files\n",
    "    f.write(\"SPECNAME spec.dat\\n\") # Conservation Feature File\n",
    "    f.write(\"PUNAME pu.dat\\n\") # Planning Unit File\n",
    "    f.write(\"PUVSPRNAME puvsp.dat\\n\") # PU vs Conservation Feature File\n",
    "    f.write(\"BOUNDNAME bound.dat\\n\") # Boundary Length File\n",
    "#     f.write(\"BLOCKDEFNAME blockdef.dat\\n\") # Block Definition File\n",
    "#     f.write(\"MATRIXSPORDERNAME puvsp_sporder.dat\\n\") # PUVSPR ordered by SP\n",
    "    f.write(\"SCENNAME \" + scen_id + \"\\n\") # Scenario name for saved output\n",
    "    f.write(\"SAVERUN 3\\n\") # Save each run (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVEBEST 3\\n\") # Save the best run (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVESUMMARY 3\\n\") # Save summary info (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVESCEN 3\\n\") # Save scenario info (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVETARGMET 3\\n\") # Save targets met information\n",
    "    f.write(\"SAVESUMSOLN 3\\n\") # Save summed solution info (1 dat,2 txt,3 csv)\n",
    "    f.write(\"SAVEPENALTY 3\\n\") # Save computed feature penalties \n",
    "    f.write(\"SAVELOG 3\\n\") # Save log files (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVESNAPSTEPS 0\\n\") # Save snapshots of each n steps\n",
    "    f.write(\"SAVESNAPCHANGES 0\\n\") # Save snapshots after every n change\n",
    "    f.write(\"SAVESNAPFREQUENCY 0\\n\") # Frequency of snapshots if used\n",
    "    f.write(\"SAVESOLUTIONS MATRIX 3\\n\") # Save all runs in a single matrix\n",
    "    f.write(\"OUTPUTDIR output\\n\") # name of dir containing output files \n",
    "#     f.write(\"\\n\")\n",
    "    f.write(\"Program control\\n\")\n",
    "    f.write(\"RUNMODE 1\\n\") # Run option\n",
    "    f.write(\"MISSLEVEL %s\\n\" % formatAsME(1.0)) # Species missing proportion\n",
    "    f.write(\"ITIMPTYPE 1\\n\") # Iterative improvement\n",
    "    f.write(\"HEURTYPE -1\\n\") # Heuristic\n",
    "    f.write(\"CLUMPTYPE 0\\n\") # Clumping rule\n",
    "    f.write(\"VERBOSITY 3\\n\") # Screen output\n",
    "#     f.write(\"\\n\")\n",
    "    f.close()\n",
    "    print(os.path.basename(dest) + \": input.dat created successfully\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6cd71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to create plot of best solution from Marxan output, and\n",
    "# also save the shapefile merged with best solution as new file\n",
    "\n",
    "def get_bestshp_and_bestplot(eco, path, espg, scen_id):\n",
    "    \"\"\"\n",
    "    plots an image to show what hex cells were selected in the best run\n",
    "    (also saves the shapefile merged with '_best.csv' needed to produce plot)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem being analyzed; \n",
    "    identifies a subdirectory of the timestamped marxan run directory\n",
    "\n",
    "    path : filepath\n",
    "    filepath to ecosystem subdirectory \n",
    "    \n",
    "    espg : str\n",
    "    espg number (we're using ESPG:5070)\n",
    "    \n",
    "    scen_id : str\n",
    "    scenario id, info to be included as prefix on generated output files\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : list\n",
    "    will generate two files named in output list \n",
    "    (shapefile merged with best solution, and plot of best solution)\n",
    "    \"\"\"\n",
    "    # Open raster data, set plotting extent\n",
    "    raster_path = os.path.normpath(os.path.join(path, \n",
    "                               \"source_data\", \n",
    "                               eco + \"_espg_\" + espg + \".tif\"))\n",
    "    raster_layer = rxr.open_rasterio(raster_path, masked=True).squeeze()\n",
    "    raster_extent = plotting_extent(raster_layer, \n",
    "                                    raster_layer.rio.transform())\n",
    "\n",
    "    # open shapefile created in the 'set_source_files_crs' function\n",
    "    shp_path = os.path.normpath(os.path.join(\n",
    "        path, \"source_data\", eco + \"_espg_\" + espg + \".shp\"))         \n",
    "    shp_layer = gpd.read_file(shp_path)\n",
    "    \n",
    "    # open '_best' file created by Marxan and saved to 'output' directory\n",
    "    globfile = glob(os.path.normpath(os.path.join(path, 'output', '*_best*')))\n",
    "    best_run_path = globfile[0]\n",
    "    best_run = pd.read_csv(best_run_path)\n",
    "\n",
    "    # merge best_run df to shp layer\n",
    "    shp_layer.insert(0, 'PUID', range(1, 1 + len(shp_layer)))\n",
    "    shp_layer = shp_layer.merge(best_run, on='PUID')\n",
    "    shp_w_best = shp_layer.to_file(eco + \"_w_best.shp\", index=False)\n",
    "    print (eco + '.shp merged with ' + scen_id + \"_best.csv, saved as \" + eco \n",
    "           + \"_w_best.shp file\")\n",
    "           \n",
    "    # create visualization showing hexcell selection from best run solution\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    shp_layer.plot(column='SOLUTION', cmap='tab20', ax=ax, alpha=0.65)\n",
    "    ax.imshow(raster_layer, cmap='jet', extent=raster_extent, \n",
    "              interpolation='nearest')\n",
    "    ax.set(title= eco + ': best run solution ')\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    best_plot = plt.savefig('best_plot.png', facecolor='w', edgecolor='k', \n",
    "                            dpi=1200)  \n",
    "    print (eco + \": best plot saved as .png\")\n",
    "    \n",
    "    output = (shp_w_best, best_plot)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "287bef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to create plot of summed solution from Marxan output, and\n",
    "# also save the shapefile merged with best solution as new file\n",
    "\n",
    "def get_ssolnshp_and_ssolnplot(eco, path, espg, scen_id):\n",
    "    \"\"\"\n",
    "    plots an image to show hex cell selection frequency \n",
    "    (also saves the shapefile merged with '_ssoln.csv' needed to produce plot)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem being analyzed; \n",
    "    identifies a subdirectory of the timestamped marxan run directory\n",
    "\n",
    "    path : filepath\n",
    "    filepath to ecosystem subdirectory \n",
    "    \n",
    "    espg : str\n",
    "    espg number (we're using ESPG:5070)\n",
    "    \n",
    "    scen_id : str\n",
    "    scenario id, info to be included as prefix on generated output files\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : list\n",
    "    will generate two files named in output list \n",
    "    (shapefile merged with summed solution, and plot of summed solution)\n",
    "    \"\"\"\n",
    "    # Open raster data, set plotting extent\n",
    "    raster_path = os.path.normpath(os.path.join(path, \n",
    "                               \"source_data\", \n",
    "                               eco + \"_espg_\" + espg + \".tif\"))\n",
    "    raster_layer = rxr.open_rasterio(raster_path, masked=True).squeeze()\n",
    "    raster_extent = plotting_extent(raster_layer, \n",
    "                                    raster_layer.rio.transform())\n",
    "\n",
    "    # open shapefile created in the 'set_source_files_crs' function\n",
    "    shp_path = os.path.normpath(os.path.join(\n",
    "        path, \"source_data\", eco + \"_espg_\" + espg + \".shp\"))         \n",
    "    shp_layer = gpd.read_file(shp_path)\n",
    "    \n",
    "    # open '_ssoln' file created by Marxan and saved to 'output' directory\n",
    "    globfile = glob(os.path.normpath(os.path.join(path, 'output', \n",
    "                                                  '*_ssoln*')))\n",
    "    ssoln_path = globfile[0]\n",
    "    ssoln = pd.read_csv(ssoln_path)\n",
    "    ssoln = ssoln.rename(columns={'planning_unit': 'PUID'})\n",
    "    \n",
    "    # merge ssoln df to shp layer\n",
    "    shp_layer.insert(0, 'PUID', range(1, 1 + len(shp_layer)))\n",
    "    shp_layer = shp_layer.merge(ssoln, on='PUID')\n",
    "    shp_w_ssoln = shp_layer.to_file(eco + \"_w_ssoln.shp\", index=False)\n",
    "    print (eco + '.shp merged with ' + scen_id + \"_ssoln.csv, saved as \" + eco \n",
    "           + \"_w_ssoln.shp file\")\n",
    "           \n",
    "    # create visualization showing hexcell selection from summed solution\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    shp_layer.plot(column='number', cmap='viridis', ax=ax, alpha=0.65)\n",
    "    ax.imshow(raster_layer, cmap='jet', extent=raster_extent, \n",
    "              interpolation='nearest')\n",
    "    ax.set(title= eco + ': summed solution \\n(hex cell selection frequency)')\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    ssoln_plot = plt.savefig('ssoln_plot.png', facecolor='w', edgecolor='k', \n",
    "                            dpi=1200)  \n",
    "    print (eco + \": ssoln plot saved as .png\")\n",
    "    \n",
    "    output = (shp_w_ssoln, ssoln_plot)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4158569",
   "metadata": {},
   "source": [
    "FUNCTION TO CREATE PUVSP.DAT & SPEC.DAT\n",
    "(PUVSP_SPORDER.DAT not needed, as currently we are looking at only one ecosystem at a time)\n",
    "\n",
    "* find code to replicate the Zonal Histogram tool in QGIS (Processing Toolbox > Raster Analysis > Zonal Histogram)\n",
    "https://docs.qgis.org/3.22/en/docs/user_manual/processing_algs/qgis/rasteranalysis.html#zonal-histogram\n",
    "import processing\n",
    "processing.run(\"algorithm_id\", {parameter_dictionary})\n",
    "\n",
    "I think this comes from pyQGIS, but I don't think that is included with the earth-analytics-python-env??\n",
    "\n",
    "Here's info on running pyQGIS in Jupyter\n",
    "https://lerryws.xyz/posts/PyQGIS-in-Jupyter-Notebook\n",
    "\n",
    "here's my initial guess, using parameters copied from QGIS 'Zonal Histograms' log -\n",
    "from qgis.core import processing\n",
    "processing.run(\"native:zonalhistogram\", { 'COLUMN_PREFIX' : '', 'INPUT_RASTER' : 'F:/NatureServe/LanasData/raster/foothill_r.tif', 'INPUT_VECTOR' : 'F:/NatureServe/LanasData/marxan_prep/foothill/pulayercws.shp', 'OUTPUT' : 'F:/NatureServe/pulayerfeatures.shp', 'RASTER_BAND' : 1 })\n",
    "\n",
    "* add column, multiplying pixel count by raster pixel area variable (our data's is 900, 30m x 30m = 900 sq m/pixel), this gives total extent of ecosystem within each individual planning unit hex of the hexfile.shp (ex. if pixelcount = 5, area = 4500, or 5 x 900)\n",
    "\n",
    "* use this as the source info for qmarxan 'export feature files' function\n",
    "input parameters copied from QGIS -\n",
    "Input parameters:\n",
    "{ 'FEAT_FIELDS' : ['7147'], 'OUT_DIR' : 'F:\\\\NatureServe\\\\524 QM test\\\\input', 'PU_FIELD' : 'PUID', 'PU_LAYER' : 'F:/NatureServe/pulayerfeatures.shp' }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
