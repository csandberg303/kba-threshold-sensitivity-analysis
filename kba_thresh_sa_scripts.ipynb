{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fb7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import datetime\n",
    "import io\n",
    "import requests\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "# from qgis.core import *\n",
    "\n",
    "import earthpy as et\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ebb959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to get Lana's input files (created with ArcGIS) from the \n",
    "# repo to local directory \n",
    "def get_marxan_input_files(eco, files_to_get):\n",
    "     \"\"\"\n",
    "     Currently this formula will find the input files Lana created using the\n",
    "     ArcMarxan Toolbox plugin in ArcGIS, which have been stored to the assets\n",
    "     directory of our GitHub repository.  We hope this may be a placeholder\n",
    "     function, to be replaced with functions that might create these files \n",
    "     directly using the opensource code available from the opensource QMarxan \n",
    "     Toolbox plugin for QGIS.\n",
    "\n",
    "     Parameters\n",
    "     ----------\n",
    "     eco : str\n",
    "     the abbreviated one word short name used for ecosystem, identifies a\n",
    "     subdirectory of the marxan_input directory\n",
    "     \n",
    "     files_to_get : list\n",
    "     list of filenames to retrieve from the marxan_input/eco directory of \n",
    "     the repo\n",
    "\n",
    "     -------\n",
    "     returned_data : the specified dat files, saved to eco/input local \n",
    "     directory\n",
    "     \"\"\"\n",
    "     inputfile_ls = files_to_get\n",
    "     \n",
    "     for file in inputfile_ls:\n",
    "        urltext = (\"https://raw.githubusercontent.com/csandberg303/\"\n",
    "                   \"kba-threshold-sensitivity-analysis/main/assets/data/\"\n",
    "                   \"marxan_input/\")\n",
    "        url = urltext + eco + \"/\" + file\n",
    "        # downloading the info from file stored on github\n",
    "        fileinfo = requests.get(url).content\n",
    "        # Reading the downloaded content and turning it to a pandas dataframe\n",
    "        fileinfo_df = pd.read_csv(io.StringIO(fileinfo.decode('utf-8')),\n",
    "                                 index_col=False).squeeze(\"columns\")\n",
    "        filename = file\n",
    "        output = fileinfo_df.to_csv(file, index=False)\n",
    "        print(eco + \": \" + file + \" successfully copied from url\")\n",
    "     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ad2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write formula to get the shapefile and rasters that have been saved to the \n",
    "#''kba_thres_sa/shp_hex' and 'kba_thres_sa/r_tif' local directories\n",
    "\n",
    "# Currently I've manually copied Lana's ArcGIS files to these locations, using \n",
    "# the naming convention 'eco.shp' for hexfiles and 'eco.tif for the rasters.\n",
    "\n",
    "# IN THE FUTURE, the .shp & .tif files may be created and placed in the \n",
    "# 'shp_hex' and 'r_tif' directories using code rather than ArcGIS, but this \n",
    "# 'get_source_files' formula will still function to copy the needed files into\n",
    "# the 'eco' directory when the 'eco/input' directories are created.\n",
    "def get_source_files(path, eco):\n",
    "    \"\"\"\n",
    "    path : str\n",
    "    local directory where the shapefiles or rasters are stored\n",
    "    \n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem\n",
    "    \"\"\"\n",
    "    source_file_ls = glob(os.path.join(path, eco + '*'))\n",
    "    if source_file_ls == []:\n",
    "        print(\"no files found in \" + path + \"with expected name \" + eco + \"?\")\n",
    "    else:\n",
    "        for file in source_file_ls:\n",
    "            shutil.copy(file, os.getcwd())\n",
    "            print(eco + \": \"+ os.path.basename(file) + \" copied successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9ab349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO CREATE PU.DAT FILE\n",
    "# create df based on hexfile.shp\n",
    "# 3 columns - puid, cost & status\n",
    "# No. of rows to equal number of hex cells in the hexfile.shp\n",
    "# save as a csv .dat \n",
    "\n",
    "def create_pu_dat(eco, path):\n",
    "    \"\"\"\n",
    "     To create the pu.dat file that stores information about planning units in \n",
    "     hex grid\n",
    "\n",
    "     Parameters\n",
    "     ----------\n",
    "     eco : str\n",
    "     name of ecosystem that will be analyzed by Marxan\n",
    "     \n",
    "     path : str\n",
    "     local directory where 'hex_shp' directory is stored\n",
    "     \n",
    "     -------\n",
    "     returned_data : the pu.dat input file \n",
    "         \n",
    "    \"\"\"\n",
    "\n",
    "    # open hex.shp file\n",
    "    shp_data_path = os.path.join(path, \"hex_shp\", eco + '.shp')\n",
    "    shp_layer = gpd.read_file(shp_data_path)\n",
    "\n",
    "    # Reproject CRS to ESPG 5070\n",
    "    shp_layer_5070 = shp_layer.to_crs(epsg='5070')\n",
    "\n",
    "    # create columns for 'pu_id', cost' (value = 1) and 'status' (value = 0)    \n",
    "    shp_layer_5070.insert(0, 'pu_id', range(1, 1 + len(shp_layer_5070)))\n",
    "    shp_layer_5070[\"cost\"] = 1\n",
    "    shp_layer_5070[\"status\"] = 0\n",
    "\n",
    "    # create pu.dat file\n",
    "    pu_dat = shp_layer_5070[[\"pu_id\", \"cost\", \"status\"]].set_index(\"pu_id\")\n",
    "    output = pu_dat.to_csv('pu2.dat')\n",
    "    print(eco + \": pu.dat file successfully created\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1b19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to write targets.csv files, for each threshold test value\n",
    "\n",
    "# NOT SURE IF THIS WILL ULTIMATELY BE NEEDED IN ITS CURRENT FORM, AS THE \n",
    "#TARGETS INPUT FILE MIGHT ONLY BE USED BY THE QGIS ADDIN CLUZ, RATHER THAN \n",
    "# MARXAN/MARXANCONPY ITSELF\n",
    "\n",
    "def create_cluz_targets_files(eco, thresholds_test, eco_info, path):\n",
    "     \"\"\"creates the targets.csv files needed for Marxan analysis \n",
    "     (?? only when using CLUZ add-in in QGIS ??).\n",
    "\n",
    "     Parameters\n",
    "     ----------\n",
    "     eco : str\n",
    "     name of ecosystem that will be analyzed by Marxan\n",
    "\n",
    "     thresholds_test : list\n",
    "     list of threshold values to be tested for each ecosystem\n",
    "\n",
    "     eco_info : dataframe\n",
    "     source of info for each ecosystem, with columns 'OID' (Unique ID number),\n",
    "     'Name' (ecosystem name), Type (number representing RLE Status), Size of \n",
    "     Ecosystem (units of area measurement) and the Current IUCN Threshold \n",
    "     value, based upon ecosystem's RLE status\n",
    "\n",
    "     path : filepath\n",
    "     filepath to ecosystem subdirectory where targets files will be saved\n",
    "\n",
    "     Returns\n",
    "     -------\n",
    "     returned_data : csv\n",
    "     csv files are saved to ecosystem directories, one file for each threshold\n",
    "     value to be tested\n",
    "     \"\"\"\n",
    "     for val in thresholds_test:\n",
    "            target_info = {'Id': [eco_info.loc[eco]['OID']], \n",
    "                           'Name': [eco], \n",
    "                           'Type': [eco_info.loc[eco]['Type']], \n",
    "                           'sq_km': [eco_info.loc[eco]['US_km2']],\n",
    "                           'iucn_th': [eco_info.loc[eco]['Current_IUCN_TH']]}\n",
    "            target_df = pd.DataFrame(data=target_info).set_index('Id')\n",
    "            target_df['Target'] = (target_df['sq_km'] * target_df['iucn_th'])\n",
    "            target_df['Target'] = (val * target_df['Target'])\n",
    "            target_df.drop([\"sq_km\", \"iucn_th\"], axis = 1, inplace = True)\n",
    "            outpath = os.path.join(path, 'targets_' +str(val) + '.csv')\n",
    "            csv = target_df.to_csv(outpath)\n",
    "     print(eco + \": targets files created for each test threshold value\")       \n",
    "     return csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee56ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE FUNCTION TO CREATE PUVSP.DAT & SPEC.DAT\n",
    "# (PUVSP_SPORDER.DAT not needed, as currently we are working with just one one \n",
    "# ecosystem at a time, rather than looking at mulitiple conservation features \n",
    "# in a single run)\n",
    "\n",
    "# find code to replicate the Zonal Histogram tool in QGIS \n",
    "# (Processing Toolbox > Raster Analysis > Zonal Histogram) \n",
    "# https://docs.qgis.org/3.22/en/docs/user_manual/processing_algs/qgis/\n",
    "# rasteranalysis.html#zonal-histogram \n",
    "# import processing processing.run(\"algorithm_id\", {parameter_dictionary})\n",
    "\n",
    "# I think the 'import processing' code suggestion comes from pyQGIS, but I \n",
    "# don't think that is included with the earth-analytics-python-env??\n",
    "\n",
    "# Here's info on running pyQGIS in Jupyter \n",
    "# https://lerryws.xyz/posts/PyQGIS-in-Jupyter-Notebook\n",
    "\n",
    "# here's my initial guess at some of the pyQGIS code, using parameters copied \n",
    "# from the QGIS 'Zonal Histograms' log window - \n",
    "# from qgis.core import processing processing.run(\n",
    "#     \"native:zonalhistogram\", { \n",
    "#         'COLUMN_PREFIX' : '', \n",
    "#         'INPUT_RASTER' : 'F:/NatureServe/LanasData/raster/foothill_r.tif', \n",
    "#         'INPUT_VECTOR' : 'F:/NatureServe/LanasData/marxan_prep/foothill/pulayercws.shp', \n",
    "#         'OUTPUT' : 'F:/NatureServe/pulayerfeatures.shp', \n",
    "#         'RASTER_BAND' : 1 \n",
    "#     })\n",
    "\n",
    "# the result will show the number of raster pixels within each hexgrid cell.\n",
    "\n",
    "# add new column, multiplying this pixel count by the raster pixel area \n",
    "# variable, to give the total extent of ecosystem within each individual \n",
    "# planning unit hex cell.\n",
    "# the pixel area can be determined by looking at the raster saved to the \n",
    "# 'source_data' directory in an earlier formula. Maybe a new function should \n",
    "# be written to get this value, and that function would be called within this\n",
    "# current 'create_puvsp_dat' function? \n",
    "# (our data's pixel area is 900, as 30m x 30m = 900 sq m/pixel. If the \n",
    "# pixelcount = 5, area = 4500, or 5 x 900)\n",
    "\n",
    "# use this table (dataframe?) as the source info for qmarxan 'export feature\n",
    "# files' function (WHICH WOULD ALSO CREATE THE SPEC.DAT FILE)\n",
    "\n",
    "# input parameters copied from QGIS 'export_features_files' log window - \n",
    "# Input parameters: { \n",
    "#     'FEAT_FIELDS' : ['7147'], \n",
    "#     'OUT_DIR' : 'F:\\NatureServe\\524 QM test\\input', \n",
    "#     'PU_FIELD' : 'PUID', \n",
    "#     'PU_LAYER' : 'F:/NatureServe/pulayerfeatures.shp' \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18781b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THESE FUNCTIONS ARE TAKEN/ADAPTED FROM QMARXAN TOOLBOX ALGORITHM CODE\n",
    "\n",
    "# taken from lines ~98-104 of QMarxan algorithm\n",
    "\n",
    "# formatAsME - format as Marxan Exponent format like \n",
    "        #              Input File Editor\n",
    "        #\n",
    "def formatAsME(inVal):\n",
    "    outStr = \"%.14E\" % float(inVal)\n",
    "    parts = outStr.split('E')\n",
    "    sign = parts[1][:1]\n",
    "    exponent = \"%04d\" % float(parts[1][1:])\n",
    "    outStr = parts[0] + 'E' +  sign + exponent\n",
    "    return(outStr)\n",
    "\n",
    "\n",
    "\n",
    "# TO CREATE INPUT.DAT (LINES 128-183 OF ALGORITHM FILE)\n",
    "def create_input_dat(dest, prop, scen_name):\n",
    "    \"\"\"\n",
    "     To create the input.dat file that stores processing parameters\n",
    "\n",
    "     Parameters\n",
    "     ----------\n",
    "     dest : str\n",
    "     directory input.dat file will be saved to\n",
    "     \n",
    "     prop : float\n",
    "     must be a number between 0 and 1; represents the proportion of PU to be\n",
    "     included in the initial reserve (default value is 0.5)\n",
    "     \n",
    "     scen_name : str\n",
    "     scenario name, to be included as ID on generated output files\n",
    "     \n",
    "     other parameters will be added to replace the default initial values \n",
    "     that are included in the QMarxan code \n",
    "\n",
    "     -------\n",
    "     returned_data : the input.dat file \n",
    "         \n",
    "    \"\"\"\n",
    "    output = os.path.join(dest,'qm_input.dat')\n",
    "    f = open(output, 'w')\n",
    "    f.write(\"Input file for Annealing program.\\n\")\n",
    "    f.write('\\n')\n",
    "    f.write('This file generated for KBA Threshold\\n')\n",
    "    f.write('Analysis project using code from\\n')\n",
    "    f.write('QMarxan Toolbox 2.0\\n')\n",
    "    f.write('created by Apropos Information Systems Inc.\\n')\n",
    "    f.write('\\n')\n",
    "    f.write(\"General Parameters\\n\")\n",
    "    f.write(\"BLM 1\\n\") # Boundary Length Modifier\n",
    "    f.write(\"PROP %s\\n\" % formatAsME(prop)) # Proportion of PU (or sub TARGET)\n",
    "    f.write(\"RANDSEED -1\\n\") # Random seed number\n",
    "    f.write(\"NUMREPS 100\\n\") # Num of repeat runs (or solutions)\n",
    "    f.write('\\n')    \n",
    "    f.write(\"Annealing Parameters\\n\")\n",
    "    f.write(\"NUMITNS 1000000\\n\") # Num of iterations for annealing\n",
    "    f.write(\"STARTTEMP %s\\n\" % formatAsME(-1.0)) # start temp for annealing\n",
    "    f.write(\"COOLFAC %s\\n\" % formatAsME(-1.0)) # cooling factor for annealing\n",
    "    f.write(\"NUMTEMP 10000\\n\") # num of temp decreases for annealing\n",
    "    f.write(\"\")\n",
    "    f.write(\"Cost Threshold\\n\") \n",
    "    f.write(\"COSTTHRESH %s\\n\" % formatAsME(0.0)) # cost threshold\n",
    "    f.write(\"THRESHPEN1 %s\\n\" % formatAsME(0.0)) # size of cost thresh penalty\n",
    "    f.write(\"THRESHPEN2 %s\\n\" % formatAsME(0.0)) # shp of cost thresh penalty\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Input Files\\n\")\n",
    "    f.write(\"INPUTDIR input\\n\") # name of dir containing input files\n",
    "    f.write(\"SPECNAME spec.dat\\n\") # Conservation Feature File\n",
    "    f.write(\"PUNAME pu.dat\\n\") # Planning Unit File\n",
    "    f.write(\"PUVSPRNAME puvsp.dat\\n\") # PU vs Conservation Feature File\n",
    "    f.write(\"BOUNDNAME bound.dat\\n\") # Boundary Length File\n",
    "    f.write(\"BLOCKDEFNAME blockdef.dat\\n\") # Block Definition File\n",
    "    f.write(\"MATRIXSPORDERNAME puvsp_sporder.dat\\n\") # PUVSPR ordered by SP\n",
    "    f.write(\"SCENNAME \" + scen_name + \"\\n\") # Scenario name for saved output\n",
    "    f.write(\"SAVERUN 3\\n\") # Save each run (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVEBEST 3\\n\") # Save the best run (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVESUMMARY 3\\n\") # Save summary info (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVESCEN 3\\n\") # Save scenario info (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVETARGMET 3\\n\") # Save targets met information\n",
    "    f.write(\"SAVESUMSOLN 3\\n\") # Save summed solution info (1 dat,2 txt,3 csv)\n",
    "    f.write(\"SAVEPENALTY 3\\n\") # Save computed feature penalties \n",
    "    f.write(\"SAVELOG 3\\n\") # Save log files (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVESNAPSTEPS 0\\n\") # Save snapshots of each n steps\n",
    "    f.write(\"SAVESNAPCHANGES 0\\n\") # Save snapshots after every n change\n",
    "    f.write(\"SAVESNAPFREQUENCY 0\\n\") # Frequency of snapshots if used\n",
    "    f.write(\"SAVESOLUTIONS MATRIX 3\\n\") # Save all runs in a single matrix\n",
    "    f.write(\"OUTPUTDIR output\\n\") # name of dir containing output files \n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Program control\\n\")\n",
    "    f.write(\"RUNMODE 1\\n\") # Run option\n",
    "    f.write(\"MISSLEVEL %s\\n\" % formatAsME(1.0)) # Species missing proportion\n",
    "    f.write(\"ITIMPTYPE 1\\n\") # Iterative improvement\n",
    "    f.write(\"HEURTYPE -1\\n\") # Heuristic\n",
    "    f.write(\"CLUMPTYPE 0\\n\") # Clumping rule\n",
    "    f.write(\"VERBOSITY 3\\n\") # Screen output\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd3eae",
   "metadata": {},
   "source": [
    "# Write formula to create 'bound.dat' file\n",
    "(# code below taken from 'qmarxan_toolbox_algorithm.py')\n",
    "\n",
    "# # Constants used to refer to parameters and outputs. They will be\n",
    "# # used when calling the algorithm from another algorithm, or when\n",
    "# # calling from the QGIS console.\n",
    "\n",
    "# PU_LAYER = 'PU_LAYER'\n",
    "# PU_FIELD = 'PU_FIELD'\n",
    "# BND_METHOD = 'BND_METHOD'\n",
    "# BND_TREAT = 'BND_TREAT'\n",
    "# BND_VALUE = 'BND_VALUE'\n",
    "# CALC_FIELD = 'CALC_FIELD'\n",
    "# CALC_METHOD = 'CALC_METHOD'\n",
    "# TOL = 'TOL'\n",
    "# OUT_DIR = 'OUT_DIR'\n",
    "\n",
    "# def create_bound_dat(???self, config???):\n",
    "#         \"\"\"\n",
    "#         Here we define the inputs and output of the algorithm, along\n",
    "#         with some other properties.\n",
    "#         \"\"\"\n",
    "#         # pu layer\n",
    "#         self.addParameter(\n",
    "#                 self.PU_LAYER,\n",
    "#                 self.tr('Planning unit layer (source for bound.dat file)'),\n",
    "#                 [QgsProcessing.TypeVectorPolygon]\n",
    "#             )\n",
    "#         )\n",
    "#         # pu id\n",
    "#         self.addParameter(\n",
    "#             QgsProcessingParameterField(\n",
    "#                 self.PU_FIELD,\n",
    "#                 self.tr('Planning unit id field'),\n",
    "#                 parentLayerParameterName=self.PU_LAYER,\n",
    "#                 type=QgsProcessingParameterField.Numeric\n",
    "#             )\n",
    "#         )\n",
    "#         #\n",
    "#         # advanced settings\n",
    "#         #\n",
    "#         #  bnd method\n",
    "#         bndMethod = QgsProcessingParameterEnum(\n",
    "#             self.BND_METHOD,\n",
    "#             self.tr('Boundary method (how lengths between planning units will be set)'),\n",
    "#             options = [\"Single\",\"Measured\",\"Weighted\",\"Field\"],\n",
    "#             defaultValue = 0\n",
    "#         )\n",
    "#         bndMethod.setFlags(bndMethod.flags() | QgsProcessingParameterDefinition.FlagAdvanced)\n",
    "#         self.addParameter(bndMethod)\n",
    "#         # bnd treatment\n",
    "#         bndTreatment = QgsProcessingParameterEnum(\n",
    "#             self.BND_TREAT,\n",
    "#             self.tr('Boundary treatment (how values for PUs on perimeter of study area will be set)'),\n",
    "#             options = [\"Full Value\",\"Half Value\",\"Exclude\"],\n",
    "#             defaultValue = 0\n",
    "#         )\n",
    "#         bndTreatment.setFlags(bndTreatment.flags() | QgsProcessingParameterDefinition.FlagAdvanced)\n",
    "#         self.addParameter(bndTreatment)\n",
    "#         # single value\n",
    "#         bndValue = QgsProcessingParameterNumber(\n",
    "#             self.BND_VALUE,\n",
    "#             self.tr('Boundary value (value for all boundaries regardless of measured length)'),\n",
    "#             type=QgsProcessingParameterNumber.Integer, \n",
    "#             minValue=0, \n",
    "#             defaultValue=1,\n",
    "#             optional=True\n",
    "#         )\n",
    "#         bndValue.setFlags(bndValue.flags() | QgsProcessingParameterDefinition.FlagAdvanced )\n",
    "#         self.addParameter(bndValue)\n",
    "#         # calculation field\n",
    "#         calcField = QgsProcessingParameterField(\n",
    "#             self.CALC_FIELD,\n",
    "#             self.tr('Calculation field (field to weight or assign boundary lengths)'),\n",
    "#             parentLayerParameterName=self.PU_LAYER,\n",
    "#             type=QgsProcessingParameterField.Numeric,\n",
    "#             optional = True\n",
    "#         )\n",
    "#         calcField.setFlags(calcField.flags() | QgsProcessingParameterDefinition.FlagAdvanced)\n",
    "#         self.addParameter(calcField)\n",
    "#         # calculation method\n",
    "#         calcMethod = QgsProcessingParameterEnum(\n",
    "#             self.CALC_METHOD,\n",
    "#             self.tr('Calculation method (how to assign boundary length if values between adjacent planning units differ)'),\n",
    "#             options = [\"Mean\",\"Maximum\",\"Minimum\"],\n",
    "#             defaultValue = 0,\n",
    "#             optional = True\n",
    "#         )\n",
    "#         calcMethod.setFlags(calcMethod.flags() | QgsProcessingParameterDefinition.FlagAdvanced)\n",
    "#         self.addParameter(calcMethod)\n",
    "#         # rounding precision\n",
    "#         tolerance = QgsProcessingParameterEnum(\n",
    "#             self.TOL,\n",
    "#             self.tr('Export precision tolerance (in map units)'),\n",
    "#             options = [\"100\",\"10\",\"1\",\"0.1\",\"0.01\",\"0.001\",\"0.0001\",\"0.00001\"],\n",
    "#             defaultValue = 3\n",
    "#         )\n",
    "#         tolerance.setFlags(tolerance.flags() | QgsProcessingParameterDefinition.FlagAdvanced)\n",
    "#         self.addParameter(tolerance)\n",
    "\n",
    "#         # select output folder\n",
    "#         defDir = os.path.join(os.path.expanduser('~'),'marxanproj1','input')\n",
    "#         self.addParameter(\n",
    "#             QgsProcessingParameterFolderDestination(\n",
    "#                 self.OUT_DIR,\n",
    "#                 self.tr('Marxan input folder (place to write bound.dat file)'),\n",
    "#                 defDir,\n",
    "#                 optional=False\n",
    "#             )\n",
    "#         )\n",
    "#   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4158569",
   "metadata": {},
   "source": [
    "FUNCTION TO CREATE PUVSP.DAT & SPEC.DAT\n",
    "(PUVSP_SPORDER.DAT not needed, as currently we are looking at only one ecosystem at a time)\n",
    "\n",
    "* find code to replicate the Zonal Histogram tool in QGIS (Processing Toolbox > Raster Analysis > Zonal Histogram)\n",
    "https://docs.qgis.org/3.22/en/docs/user_manual/processing_algs/qgis/rasteranalysis.html#zonal-histogram\n",
    "import processing\n",
    "processing.run(\"algorithm_id\", {parameter_dictionary})\n",
    "\n",
    "I think this comes from pyQGIS, but I don't think that is included with the earth-analytics-python-env??\n",
    "\n",
    "Here's info on running pyQGIS in Jupyter\n",
    "https://lerryws.xyz/posts/PyQGIS-in-Jupyter-Notebook\n",
    "\n",
    "here's my initial guess, using parameters copied from QGIS 'Zonal Histograms' log -\n",
    "from qgis.core import processing\n",
    "processing.run(\"native:zonalhistogram\", { 'COLUMN_PREFIX' : '', 'INPUT_RASTER' : 'F:/NatureServe/LanasData/raster/foothill_r.tif', 'INPUT_VECTOR' : 'F:/NatureServe/LanasData/marxan_prep/foothill/pulayercws.shp', 'OUTPUT' : 'F:/NatureServe/pulayerfeatures.shp', 'RASTER_BAND' : 1 })\n",
    "\n",
    "* add column, multiplying pixel count by raster pixel area variable (our data's is 900, 30m x 30m = 900 sq m/pixel), this gives total extent of ecosystem within each individual planning unit hex of the hexfile.shp (ex. if pixelcount = 5, area = 4500, or 5 x 900)\n",
    "\n",
    "* use this as the source info for qmarxan 'export feature files' function\n",
    "input parameters copied from QGIS -\n",
    "Input parameters:\n",
    "{ 'FEAT_FIELDS' : ['7147'], 'OUT_DIR' : 'F:\\\\NatureServe\\\\524 QM test\\\\input', 'PU_FIELD' : 'PUID', 'PU_LAYER' : 'F:/NatureServe/pulayerfeatures.shp' }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
