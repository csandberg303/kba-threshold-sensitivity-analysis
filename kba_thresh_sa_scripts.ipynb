{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fb7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import datetime\n",
    "import io\n",
    "import requests\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "# from qgis.core import *\n",
    "\n",
    "import earthpy as et\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.plot import plotting_extent\n",
    "import rioxarray as rxr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ebb959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to get Lana's input files (created with ArcGIS) from the \n",
    "# repo to local directory \n",
    "def get_marxan_input_files(eco, files_to_get, scen_id):\n",
    "     \"\"\"\n",
    "     Currently this formula will find the input files Lana created using the\n",
    "     ArcMarxan Toolbox plugin in ArcGIS, which have been stored to the assets\n",
    "     directory of our GitHub repository.  We hope this may be a placeholder\n",
    "     function, to be replaced with functions that might create these files \n",
    "     directly using the opensource code available from the opensource QMarxan \n",
    "     Toolbox plugin for QGIS.\n",
    "\n",
    "     Parameters\n",
    "     ----------\n",
    "     eco : str\n",
    "     the abbreviated one word short name used for ecosystem being analyzed; \n",
    "     identifies a subdirectory of the timestamped marxan run directory\n",
    "     \n",
    "     files_to_get : list\n",
    "     list of filenames to retrieve from the marxan_input/eco directory of \n",
    "     the repo\n",
    "\n",
    "     -------\n",
    "     returned_data : the specified dat files, saved to eco/input local \n",
    "     directory\n",
    "     \"\"\"\n",
    "     inputfile_ls = files_to_get\n",
    "     \n",
    "     for file in inputfile_ls:\n",
    "        urltext = (\"https://raw.githubusercontent.com/csandberg303/\"\n",
    "                   \"kba-threshold-sensitivity-analysis/main/assets/data/\"\n",
    "                   \"marxan_input/\")\n",
    "        url = urltext + eco + \"/\" + file\n",
    "        # downloading the info from file stored on github\n",
    "        fileinfo = requests.get(url).content\n",
    "        # Reading the downloaded content and turning it to a pandas dataframe\n",
    "        fileinfo_df = pd.read_csv(io.StringIO(fileinfo.decode('utf-8')),\n",
    "                                 index_col=False).squeeze(\"columns\")\n",
    "        filename = file\n",
    "        output = fileinfo_df.to_csv(file, index=False)\n",
    "        print(scen_id + \": \" + file + \" successfully copied from url\")\n",
    "     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ad2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write formula to get the shapefile and rasters that have been saved to the \n",
    "#''kba_thres_sa/shp_hex' and 'kba_thres_sa/r_tif' local directories\n",
    "\n",
    "# Currently I've manually copied Lana's ArcGIS files to these locations, using \n",
    "# the naming convention 'eco.shp' for hexfiles and 'eco.tif for the rasters.\n",
    "\n",
    "# IN THE FUTURE, the .shp & .tif files may be created and placed in the \n",
    "# 'shp_hex' and 'r_tif' directories using code rather than ArcGIS, but this \n",
    "# 'get_source_files' formula will still function to copy the needed files into\n",
    "# the 'eco' directory when the 'eco/input' directories are created.\n",
    "def get_source_files(path, eco, scen_id):\n",
    "    \"\"\"\n",
    "    path : str\n",
    "    local directory where the shapefiles or rasters are stored\n",
    "    \n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem being analyzed; \n",
    "    identifies a subdirectory of the timestamped marxan run directory\n",
    "    \n",
    "    scen_id : str\n",
    "    scenario id, info to be included as prefix on generated output\n",
    "     \n",
    "    \"\"\"\n",
    "    source_file_ls = glob(os.path.join(path, eco + '*'))\n",
    "    if source_file_ls == []:\n",
    "        print(\"no files found in \" + path + \"with expected name \" + eco + \"?\")\n",
    "    else:\n",
    "        for file in source_file_ls:\n",
    "            shutil.copy(file, os.getcwd())\n",
    "            print(scen_id + \": \"+ os.path.basename(file) + \n",
    "                  \" copied successfully\")\n",
    "         \n",
    "    return print(scen_id + \": finished copying source files from \" + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6fba6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set crs of shp and tif to ESPG 5070 and save as new files\n",
    "\n",
    "def set_source_files_crs (path, eco, espg, scen_id):\n",
    "    \"\"\"\n",
    "    To set crs of shp and tif to ESPG 5070, add columns to shp and save as new \n",
    "    files\n",
    "\n",
    "    Parameters\n",
    "    ----------     \n",
    "    path : str\n",
    "    path to local 'kba_thresh_sa' directory where 'hex_shp' and 'r_tif' \n",
    "    directories are stored\n",
    "        \n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem being analyzed; \n",
    "    identifies a subdirectory of the timestamped marxan run directory\n",
    "    \n",
    "    espg : str\n",
    "    espg number (we're using ESPG:5070)\n",
    "    \n",
    "    scen_id : str\n",
    "    scenario id, info to be included as prefix on generated output\n",
    "     \n",
    "    -------\n",
    "    returned_data : updated shp and tif \n",
    "         \n",
    "\n",
    "    \"\"\"\n",
    "    # open the shp and tif files saved at given path\n",
    "    shp_data_path = os.path.join(path, \"hex_shp\", eco + '.shp')\n",
    "    shp_layer = gpd.read_file(shp_data_path)\n",
    "    \n",
    "    tif_data_path = os.path.join(path, \"r_tif\", eco + '.tif')\n",
    "    tif_layer = rxr.open_rasterio(tif_data_path, masked=True).squeeze()\n",
    "\n",
    "    # reproject CRS of shp\n",
    "    shp_layer_crs = shp_layer.to_crs(epsg=espg)\n",
    "    \n",
    "    # create shp output variable\n",
    "    shp_espg_file = shp_layer_crs.to_file(eco + \"_espg_\" + espg + \".shp\", \n",
    "                                          index=False)\n",
    "\n",
    "    # reproject CRS of tif\n",
    "    # create a rasterio crs object \n",
    "    crs_espg = CRS.from_string('EPSG:' + espg)\n",
    "    # reproject tif using the crs object\n",
    "    tif_layer_crs = tif_layer.rio.reproject(crs_espg)\n",
    "    \n",
    "    # create path that new tif file will be saved to\n",
    "    tif_layer_crs_path = os.path.join(os.getcwd(), \n",
    "                                      eco + \"_espg_\" + espg + \".tif\")\n",
    "    # create tif output variable\n",
    "    tif_espg_file = tif_layer_crs.rio.to_raster(tif_layer_crs_path)\n",
    "    \n",
    "    # save the reprojected .shp and .tif files\n",
    "    output = (shp_espg_file, tif_espg_file)\n",
    "    \n",
    "    print(scen_id + \": finished set_source_files_crs\")\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9ab349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create pu.dat file \n",
    "\n",
    "def create_pu_dat(eco, path, scen_id):\n",
    "    \"\"\"\n",
    "    To create the pu.dat file that stores information about planning units in \n",
    "    hex grid\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem being analyzed; \n",
    "    identifies a subdirectory of the timestamped marxan run directory\n",
    "    \n",
    "    path : str\n",
    "    local directory where 'hex_shp' directory is stored\n",
    "    \n",
    "    scen_id : str\n",
    "    scenario id, info to be included as prefix on generated output\n",
    "     \n",
    "    -------\n",
    "    returned_data : the pu.dat input file \n",
    "         \n",
    "    \"\"\"\n",
    "\n",
    "    # open hex.shp file with set crs\n",
    "    shp_crs_path = glob(os.path.join(path, eco + '_espg_*.shp'))   \n",
    "    \n",
    "    # create df based on hexfile.shp\n",
    "    shp_crs_layer = gpd.read_file(shp_crs_path[0])\n",
    "        \n",
    "    # create new column in .shp for 'id'    \n",
    "    shp_crs_layer.insert(0, 'id', range(1, 1 + len(shp_crs_layer)))\n",
    "    \n",
    "    # set values in column 'Cost' to 1, and column 'Status' to = 0\n",
    "    shp_crs_layer[\"Cost\"] = 1\n",
    "    shp_crs_layer[\"Status\"] = 0\n",
    "    \n",
    "    # create pu.dat file\n",
    "    pu_dat = shp_crs_layer[[\"id\", \"Cost\", \"Status\"]].set_index(\"id\")\n",
    "    output = pu_dat.to_csv('pu.dat')\n",
    "    print(scen_id + \": pu.dat file successfully created\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "515f3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # funtion to create spec.dat file\n",
    "\n",
    "# def create_spec_dat(info_df, eco, prop=0.3, spf=1, minclump=False):\n",
    "#     \"\"\"\n",
    "#     To create the spec.dat file, which stores information about ecosytem to be \n",
    "#     analyzed in marxan run\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     info_df : df\n",
    "#     dataframe of ecosystem info, including 'Short_Name', 'US_km2' and\n",
    "#     'Current_IUCN_TH' columns\n",
    "     \n",
    "#     eco : str\n",
    "#     the abbreviated one word short name used for ecosystem being analyzed; \n",
    "#     identifies a subdirectory of the timestamped marxan run directory\n",
    "    \n",
    "#     prop : float\n",
    "#     The proportion of the total amount of the feature which must be included \n",
    "#     in the solution; must be between 0 and 1 (tutorial suggests 0.3)\n",
    "     \n",
    "#     spf : int\n",
    "#     species penalty factor\n",
    "     \n",
    "#     minclump : bool\n",
    "#     determines if additional field 'target2' should be included in results, \n",
    "#     to show the 'Minimum clump size for the representation of conservation \n",
    "#     features in the reserve system'. Default set to 'False'.  If 'True', \n",
    "#     'target2' column is added, with the minimum clump size calculated as the \n",
    "#     ecosystem's extent in meters ('US_km2' * 1,000,000) by it's current IUCN\n",
    "#     Threshold value ('Current_IUCN_TH' = .05 if CR or EN, or 0.10 if VU)\n",
    "#     -------\n",
    "     \n",
    "#     returned_data : the spec.dat input file \n",
    "         \n",
    "#     \"\"\"\n",
    "#     # set columns of spec.dat, if minclump parameter is False\n",
    "#     if minclump == False:\n",
    "#         data = [{'id': 1, 'prop': prop, 'spf': 1, 'name': eco}]\n",
    "#     # include add'l 'target2' column in file if minclump parameter is True\n",
    "#     else:\n",
    "#         target2 = info_df.at[eco,'Current_IUCN_TH'] * (\n",
    "#             info_df.at[eco,'US_km2'] * 1000000)\n",
    "#         data = [{'id': 1, 'prop': prop, 'target2': target2, 'spf': 1, \n",
    "#                  'name': eco}]    \n",
    "#     # set index, and save file as 'spec.dat'\n",
    "#     spec_dat = pd.DataFrame(data).set_index('id')\n",
    "#     output = spec_dat.to_csv('spec.dat')\n",
    "#     print(eco + \": spec.dat file successfully created\")\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4abab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd try - funtion to create spec.dat file\n",
    "\n",
    "def create_spec_dat_v2(info_df, prop, target2, spf, eco, scen_id):\n",
    "    \"\"\"\n",
    "    To create the spec.dat file, which stores information about ecosytem to be \n",
    "    analyzed in marxan run\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    info_df : df\n",
    "    dataframe of ecosystem info, including 'Short_Name', 'US_km2' and\n",
    "    'Current_IUCN_TH' columns\n",
    "        \n",
    "    prop : float\n",
    "    The proportion of total ecosystem area that must be included in solution\n",
    "    \n",
    "    target2: float\n",
    "    minimum clumpsize of area, in order to be included in solution (*KBA*)\n",
    "    \n",
    "    spf : int\n",
    "    species penalty factor\n",
    "    \n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem being analyzed; \n",
    "    identifies a subdirectory of the timestamped marxan run directory\n",
    "    \n",
    "    scen_id : str\n",
    "    scenario id, info to be included as prefix on generated output\n",
    "    -------\n",
    "     \n",
    "    returned_data : the spec.dat input file \n",
    "         \n",
    "    \"\"\"\n",
    "#     # set columns of spec.dat, if minclump parameter is False\n",
    "#     if minclump == False:\n",
    "#         data = [{'id': 1, 'prop': prop, 'spf': spf, 'name': eco}]\n",
    "#     # include add'l 'target2' column in file if minclump parameter is True\n",
    "#     else:\n",
    "\n",
    "    # this is where the KBA threshold can be tested -\n",
    "    # KBA @ 100% = info_df.at[eco,'Current_IUCN_TH'] * (info_df.at[eco,'US_km2'] * 1000000\n",
    "    # iterate by - test_threshold = [1.0, 0.75, 0.50, 0.25]\n",
    "    # ITERATION WILL HAPPEN OUTSIDE FORMULA - SOMEWHERE IN MAIN LOOP\n",
    "    # target2 = (target2 * 1000000) / 0.30\n",
    "    data = [{'id': 1, \n",
    "             'prop': prop,\n",
    "             'spf': spf, \n",
    "             'target2': target2, \n",
    "             'name': eco\n",
    "            }]    \n",
    "    # set index, and save file as 'spec.dat'\n",
    "    spec_dat = pd.DataFrame(data).set_index('id')\n",
    "    output = spec_dat.to_csv('spec.dat')\n",
    "    print(scen_id + \": spec.dat file successfully created\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b1b19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to write targets.csv files, for each threshold test value\n",
    "\n",
    "# NOT SURE IF THIS WILL ULTIMATELY BE NEEDED IN ITS CURRENT FORM, AS THE \n",
    "#TARGETS INPUT FILE MIGHT ONLY BE USED BY THE QGIS ADDIN CLUZ, RATHER THAN \n",
    "# MARXAN/MARXANCONPY ITSELF\n",
    "\n",
    "def create_cluz_targets_files(eco, thresholds_test, eco_info, path):\n",
    "    \"\"\"creates the targets.csv files needed for Marxan analysis \n",
    "    (?? only when using CLUZ add-in in QGIS ??).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem being analyzed; \n",
    "    identifies a subdirectory of the timestamped marxan run directory\n",
    "\n",
    "    thresholds_test : list\n",
    "    list of threshold values to be tested for each ecosystem\n",
    "\n",
    "    eco_info : dataframe\n",
    "    source of info for each ecosystem, with columns 'OID' (Unique ID number),\n",
    "    'Name' (ecosystem name), Type (number representing RLE Status), Size of \n",
    "    Ecosystem (units of area measurement) and the Current IUCN Threshold \n",
    "    value, based upon ecosystem's RLE status\n",
    "\n",
    "    path : filepath\n",
    "    filepath to ecosystem subdirectory where targets files will be saved\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    returned_data : csv\n",
    "    csv files are saved to ecosystem directories, one file for each threshold\n",
    "    value to be tested\n",
    "    \"\"\"\n",
    "    for val in thresholds_test:\n",
    "           target_info = {'Id': [eco_info.loc[eco]['OID']], \n",
    "                          'Name': [eco], \n",
    "                          'Type': [eco_info.loc[eco]['Type']], \n",
    "                          'sq_km': [eco_info.loc[eco]['US_km2']],\n",
    "                          'iucn_th': [eco_info.loc[eco]['Current_IUCN_TH']]}\n",
    "           target_df = pd.DataFrame(data=target_info).set_index('Id')\n",
    "           target_df['Target'] = (target_df['sq_km'] * target_df['iucn_th'])\n",
    "           target_df['Target'] = (val * target_df['Target'])\n",
    "           target_df.drop([\"sq_km\", \"iucn_th\"], axis = 1, inplace = True)\n",
    "           outpath = os.path.join(path, 'targets_' +str(val) + '.csv')\n",
    "           output = target_df.to_csv(outpath)\n",
    "    print(eco + \": targets files created for each test threshold value\")       \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18781b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THESE FUNCTIONS ARE TAKEN/ADAPTED FROM QMARXAN TOOLBOX ALGORITHM CODE\n",
    "\n",
    "# taken from lines ~98-104 of QMarxan algorithm\n",
    "\n",
    "# formatAsME - format as Marxan Exponent format like \n",
    "        #              Input File Editor\n",
    "        #\n",
    "def formatAsME(inVal):\n",
    "    outStr = \"%.14E\" % float(inVal)\n",
    "    parts = outStr.split('E')\n",
    "    sign = parts[1][:1]\n",
    "    exponent = \"%04d\" % float(parts[1][1:])\n",
    "    outStr = parts[0] + 'E' +  sign + exponent\n",
    "    return(outStr)\n",
    "\n",
    "\n",
    "\n",
    "# TO CREATE INPUT.DAT (LINES 128-183 OF ALGORITHM FILE)\n",
    "def create_input_dat(dest, blm, scen_id):\n",
    "    \"\"\"\n",
    "    To create the input.dat file that stores processing parameters\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dest : str\n",
    "    directory input.dat file will be saved to\n",
    "     \n",
    "    prop : float\n",
    "    must be a number between 0 and 1; represents the proportion of PU to be\n",
    "    included in the initial reserve (default value is 0.5)\n",
    "     \n",
    "    scen_id : str\n",
    "    scenario id, info to be included as prefix on generated output files\n",
    "     \n",
    "    other parameters will be added to replace the default initial values \n",
    "    that are included in the QMarxan code \n",
    "\n",
    "    -------\n",
    "    returned_data : the input.dat file \n",
    "         \n",
    "    \"\"\"\n",
    "    output = os.path.join(dest,'input.dat')\n",
    "    f = open(output, 'w')\n",
    "    f.write(\"Input file for Annealing program.\\n\")\n",
    "#     f.write('\\n')\n",
    "    f.write('This file generated for KBA Threshold\\n')\n",
    "    f.write('Analysis project using code from\\n')\n",
    "    f.write('QMarxan Toolbox 2.0\\n')\n",
    "    f.write('created by Apropos Information Systems Inc.\\n')\n",
    "#     f.write('\\n')\n",
    "    f.write(\"General Parameters\\n\")\n",
    "    f.write(\"BLM \" + str(blm) + \"\\n\") # Boundary Length Modifier\n",
    "    f.write(\"PROP %s\\n\" % formatAsME(0.5)) # Proportion of PU selected 1st run\n",
    "    f.write(\"RANDSEED -1\\n\") # Random seed number\n",
    "    f.write(\"NUMREPS 100\\n\") # Num of repeat runs (or solutions)\n",
    "#     f.write('\\n')    \n",
    "    f.write(\"Annealing Parameters\\n\")\n",
    "    f.write(\"NUMITNS 1000000\\n\") # Num of iterations for annealing\n",
    "    f.write(\"STARTTEMP %s\\n\" % formatAsME(-1.0)) # start temp for annealing\n",
    "    f.write(\"COOLFAC %s\\n\" % formatAsME(-1.0)) # cooling factor for annealing\n",
    "    f.write(\"NUMTEMP 10000\\n\") # num of temp decreases for annealing\n",
    "    f.write(\"\")\n",
    "    f.write(\"Cost Threshold\\n\") \n",
    "    f.write(\"COSTTHRESH %s\\n\" % formatAsME(0.0)) # cost threshold\n",
    "    f.write(\"THRESHPEN1 %s\\n\" % formatAsME(0.0)) # size of cost thresh penalty\n",
    "    f.write(\"THRESHPEN2 %s\\n\" % formatAsME(0.0)) # shp of cost thresh penalty\n",
    "#     f.write(\"\\n\")\n",
    "    f.write(\"Input Files\\n\")\n",
    "    f.write(\"INPUTDIR input\\n\") # name of dir containing input files\n",
    "    f.write(\"SPECNAME spec.dat\\n\") # Conservation Feature File\n",
    "    f.write(\"PUNAME pu.dat\\n\") # Planning Unit File\n",
    "    f.write(\"PUVSPRNAME puvsp.dat\\n\") # PU vs Conservation Feature File\n",
    "    f.write(\"BOUNDNAME bound.dat\\n\") # Boundary Length File\n",
    "#     f.write(\"BLOCKDEFNAME blockdef.dat\\n\") # Block Definition File\n",
    "#     f.write(\"MATRIXSPORDERNAME puvsp_sporder.dat\\n\") # PUVSPR ordered by SP\n",
    "    f.write(\"SCENNAME \" + scen_id + \"\\n\") # Scenario name for saved output\n",
    "    f.write(\"SAVERUN 3\\n\") # Save each run (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVEBEST 3\\n\") # Save the best run (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVESUMMARY 3\\n\") # Save summary info (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVESCEN 3\\n\") # Save scenario info (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVETARGMET 3\\n\") # Save targets met information\n",
    "    f.write(\"SAVESUMSOLN 3\\n\") # Save summed solution info (1 dat,2 txt,3 csv)\n",
    "    f.write(\"SAVEPENALTY 3\\n\") # Save computed feature penalties \n",
    "    f.write(\"SAVELOG 3\\n\") # Save log files (1-.dat, 2-.txt, 3-.csv)\n",
    "    f.write(\"SAVESNAPSTEPS 0\\n\") # Save snapshots of each n steps\n",
    "    f.write(\"SAVESNAPCHANGES 0\\n\") # Save snapshots after every n change\n",
    "    f.write(\"SAVESNAPFREQUENCY 0\\n\") # Frequency of snapshots if used\n",
    "    f.write(\"SAVESOLUTIONS MATRIX 3\\n\") # Save all runs in a single matrix\n",
    "    f.write(\"OUTPUTDIR output\\n\") # name of dir containing output files \n",
    "#     f.write(\"\\n\")\n",
    "    f.write(\"Program control\\n\")\n",
    "    f.write(\"RUNMODE 1\\n\") # Run option\n",
    "    f.write(\"MISSLEVEL %s\\n\" % formatAsME(1.0)) # Species missing proportion\n",
    "    f.write(\"ITIMPTYPE 1\\n\") # Iterative improvement\n",
    "    f.write(\"HEURTYPE -1\\n\") # Heuristic\n",
    "    f.write(\"CLUMPTYPE 0\\n\") # Clumping rule\n",
    "    f.write(\"VERBOSITY 3\\n\") # Screen output\n",
    "#     f.write(\"\\n\")\n",
    "    f.close()\n",
    "    print(os.path.basename(dest) + \": input.dat created successfully\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accd1fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO CREATE summary of the marxan run, incl info from the output file scenario \n",
    "# details (sen.dat), input variables within the workflow (ALSO ADD AREA & \n",
    "# OUTPUT STATS)\n",
    "def create_mxrun_summary(dest, espg, prop, blm, target2, spf, scen_id, eco, df):\n",
    "    \"\"\"\n",
    "    To create an output summary, showing local variables and info from sen.dat \n",
    "    output file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dest : str\n",
    "    path to the 'eco' subdirectory \n",
    "    \n",
    "    espg : str\n",
    "    espg number (we're using ESPG:5070)\n",
    "   \n",
    "    prop : float - USE BLM HERE INSTEAD\n",
    "    The proportion of the total amount of the feature which must be included \n",
    "    in the solution; must be between 0 and 1 (tutorial suggests 0.3)\n",
    "    \n",
    "    target2 : float\n",
    "    the min acceptable clump size - SHOULD EQUAL KBA (5 or 10 % x test thresh)\n",
    "     \n",
    "    spf : int\n",
    "    species penalty factor\n",
    "     \n",
    "    scen_id : str\n",
    "    scenario id, info to be included as prefix on generated output files\n",
    "    \n",
    "    df : df \n",
    "    provided df with info about ecosystem's RLE status and area extent\n",
    "     \n",
    "    other parameters may be added to replace the default initial values \n",
    "    that are included in the QMarxan code \n",
    "\n",
    "    -------\n",
    "    returned_data : the input.dat file \n",
    "         \n",
    "    \"\"\"\n",
    "    # display info from sen.dat output file\n",
    "    sen_path = glob(os.path.normpath(os.path.join(dest, \"output\", \"*_sen.*\")))\n",
    "    sen_df = pd.read_table(sen_path[0], header=None)\n",
    "    sen_l1 = sen_df[0].iloc[0]\n",
    "    sen_l2 = sen_df[0].iloc[1]\n",
    "    sen_l3 = sen_df[0].iloc[2]\n",
    "    sen_l4 = sen_df[0].iloc[3]\n",
    "    sen_l5 = sen_df[0].iloc[4]\n",
    "    sen_l6 = sen_df[0].iloc[5]\n",
    "    sen_l7 = sen_df[0].iloc[6]\n",
    "    sen_l8 = sen_df[0].iloc[7]\n",
    "    sen_l9 = sen_df[0].iloc[8]\n",
    "    sen_l10 = sen_df[0].iloc[9]\n",
    "    sen_l11 = sen_df[0].iloc[10]\n",
    "    sen_l12 = sen_df[0].iloc[11]\n",
    "    sen_l13 = sen_df[0].iloc[12]\n",
    "    sen_l14 = sen_df[0].iloc[13]\n",
    "    sen_l14 = sen_df[0].iloc[14]\n",
    "    sen_l15 = sen_df[0].iloc[15]\n",
    "    \n",
    "    output = os.path.join(dest, 'output', scen_id + '_mxrun_summary.dat')\n",
    "    f = open(output, 'w')\n",
    "    f.write(\"Scenario Details\\n\")\n",
    "    f.write(sen_l1 + \"\\n\")\n",
    "    f.write(sen_l2 + \"\\n\")\n",
    "    f.write(sen_l3 + \"\\n\")\n",
    "    f.write(sen_l4 + \"\\n\")\n",
    "    f.write(sen_l5 + \"\\n\")\n",
    "    f.write(sen_l6 + \"\\n\")\n",
    "    f.write(sen_l7 + \"\\n\")\n",
    "    f.write(sen_l8 + \"\\n\")\n",
    "    f.write(sen_l9 + \"\\n\")\n",
    "    f.write(sen_l10 + \"\\n\")\n",
    "    f.write(sen_l11 + \"\\n\")\n",
    "    f.write(sen_l12 + \"\\n\")\n",
    "    f.write(sen_l13 + \"\\n\")\n",
    "    f.write(sen_l14 + \"\\n\")\n",
    "    f.write(sen_l15 + \"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "     # display info from stored variables in workflow\n",
    "    blmstr = str(blm)\n",
    "    propstr = str(prop)\n",
    "    tgt2str = str(target2)\n",
    "    spfstr = str(spf)\n",
    "    f.write('Variables Set Locally -\\n')\n",
    "    f.write('ESPG value for raster and shapefile: ' + espg + \"\\n\")\n",
    "    f.write('input file variables:\\n')\n",
    "    f.write('BLM: ' +  blmstr + \"\\n\")\n",
    "    f.write('prop: ' +  propstr + \"\\n\")\n",
    "    f.write('target2: ' +  tgt2str + \" (\" + str(target2/1000000) + \" km2)\\n\")\n",
    "    f.write('Species Penalty Factor: ' + spfstr +'\\n')\n",
    "    f.write('scen_id: ' + scen_id + '\\n')\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    # display data from eco df\n",
    "    f.write('Spatial Extent of Ecosystem & KBA Thresholds\\n')\n",
    "    f.write('eco: ' + eco + '\\n')\n",
    "    f.write('US_km2: ' + str(df.at[eco,'US_km2']) + '\\n')\n",
    "    f.write('RLE_FINAL: ' + df.at[eco,'RLE_FINAL'] + '\\n')\n",
    "    f.write('Current_IUCN_TH: ' + str(df.at[eco,'Current_IUCN_TH']) + '\\n') \n",
    "    f.write('KBA @ 1.00 IUCN TH: ' + str(df.at[eco,'US_km2']*df.at[eco,'Current_IUCN_TH']) + \" km2\\n\")\n",
    "    f.write('KBA @ 0.75 IUCN TH: ' + str(0.75*(df.at[eco,'US_km2']*df.at[eco,'Current_IUCN_TH'])) + \" km2\\n\")\n",
    "    f.write('KBA @ 0.50 IUCN TH: ' + str(0.50*(df.at[eco,'US_km2']*df.at[eco,'Current_IUCN_TH'])) + \" km2\\n\")\n",
    "    f.write('KBA @ 0.25 IUCN TH: ' + str(0.25*(df.at[eco,'US_km2']*df.at[eco,'Current_IUCN_TH'])) + \" km2\\n\")\n",
    "    f.close()\n",
    "    print(os.path.basename(dest) + (': mxrunsummary created successfully\\n'\n",
    "                                    'End run: ') + os.path.basename(dest) + \n",
    "                                    '\\n')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6cd71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to create plot of best solution from Marxan output, and\n",
    "# also save the shapefile merged with best solution as new file\n",
    "\n",
    "def get_bestshp_and_bestplot(eco, path, espg, scen_id):\n",
    "    \"\"\"\n",
    "    plots an image to show what hex cells were selected in the best run\n",
    "    (also saves the shapefile merged with '_best.csv' needed to produce plot)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem being analyzed; \n",
    "    identifies a subdirectory of the timestamped marxan run directory\n",
    "\n",
    "    path : filepath\n",
    "    filepath to ecosystem subdirectory \n",
    "    \n",
    "    espg : str\n",
    "    espg number (we're using ESPG:5070)\n",
    "    \n",
    "    scen_id : str\n",
    "    scenario id, info to be included as prefix on generated output files\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : list\n",
    "    will generate two files named in output list \n",
    "    (shapefile merged with best solution, and plot of best solution)\n",
    "    \"\"\"\n",
    "    # Open raster data, set plotting extent\n",
    "    raster_path = os.path.normpath(os.path.join(path, \n",
    "                               \"source_data\", \n",
    "                               eco + \"_espg_\" + espg + \".tif\"))\n",
    "    raster_layer = rxr.open_rasterio(raster_path, masked=True).squeeze()\n",
    "    raster_extent = plotting_extent(raster_layer, \n",
    "                                    raster_layer.rio.transform())\n",
    "\n",
    "    # open shapefile created in the 'set_source_files_crs' function\n",
    "    shp_path = os.path.normpath(os.path.join(\n",
    "        path, \"source_data\", eco + \"_espg_\" + espg + \".shp\"))         \n",
    "    shp_layer = gpd.read_file(shp_path)\n",
    "    \n",
    "    # open '_best' file created by Marxan and saved to 'output' directory\n",
    "    globfile = glob(os.path.normpath(os.path.join(path, 'output', '*_best*')))\n",
    "    \n",
    "    if globfile == []:\n",
    "        output = print (\n",
    "            \"ERROR: best run file not found - check output/log. \\nWill need \"\n",
    "            \"to resolve error and rerun Marxan if not completed successfully\")\n",
    "    \n",
    "    else:\n",
    "        best_run_path = globfile[0]\n",
    "        best_run = pd.read_csv(best_run_path)\n",
    "\n",
    "        # merge best_run df to shp layer\n",
    "        shp_layer.insert(0, 'PUID', range(1, 1 + len(shp_layer)))\n",
    "        shp_layer = shp_layer.merge(best_run, on='PUID')\n",
    "\n",
    "        # open 'puvsp.dat' and merge with shp layer to get 'amount' from puvsp\n",
    "        puvsp_path = os.path.normpath(os.path.join(path, 'input', 'puvsp.dat'))\n",
    "        puvsp = pd.read_csv(puvsp_path)\n",
    "        puvsp = puvsp.rename(columns={'pu': 'PUID'})\n",
    "        shp_layer = shp_layer.merge(puvsp, on='PUID')\n",
    "\n",
    "        fig_title_metr = shp_layer.query(\"SOLUTION == 1\")['amount'].sum()/1000000\n",
    "        ftm_string = str(fig_title_metr)\n",
    "\n",
    "        # save merged shp as new file\n",
    "        shp_w_best_and_amt = shp_layer.to_file(eco + \"_w_best.shp\", index=False)\n",
    "        print (eco + '.shp merged with ' + scen_id + \n",
    "               \"_best.csv and puvsp.dat, saved as \" + eco + \n",
    "               \"_w_best_and_amt.shp file\")\n",
    "        print ('preparing plots...')\n",
    "\n",
    "        # create visualization showing hexcell selection from best run solution\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        shp_layer.plot(column='SOLUTION', cmap='tab20', ax=ax, alpha=0.65)\n",
    "        ax.imshow(raster_layer, cmap='jet', extent=raster_extent, \n",
    "                  interpolation='nearest')\n",
    "        ax.set(title= scen_id + ': best run solution' +  \n",
    "               '\\nTotal Selected Ecoystem = ' + ftm_string + ' sq km')\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        best_plot = plt.savefig('best_plot.png', facecolor='w', edgecolor='k', \n",
    "                                dpi=1200)  \n",
    "        plt.close(fig)\n",
    "        print (scen_id + \": best plot saved as .png\")\n",
    "\n",
    "        output = (shp_w_best_and_amt, best_plot)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "287bef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to create plot of summed solution from Marxan output, and\n",
    "# also save the shapefile merged with best solution as new file\n",
    "\n",
    "def get_ssolnshp_and_ssolnplot(eco, path, espg, scen_id):\n",
    "    \"\"\"\n",
    "    plots an image to show hex cell selection frequency \n",
    "    (also saves the shapefile merged with '_ssoln.csv' needed to produce plot)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eco : str\n",
    "    the abbreviated one word short name used for ecosystem being analyzed; \n",
    "    identifies a subdirectory of the timestamped marxan run directory\n",
    "\n",
    "    path : filepath\n",
    "    filepath to ecosystem subdirectory \n",
    "    \n",
    "    espg : str\n",
    "    espg number (we're using ESPG:5070)\n",
    "    \n",
    "    scen_id : str\n",
    "    scenario id, info to be included as prefix on generated output files\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : list\n",
    "    will generate two files named in output list \n",
    "    (shapefile merged with summed solution, and plot of summed solution)\n",
    "    \"\"\"\n",
    "    # Open raster data, set plotting extent\n",
    "    raster_path = os.path.normpath(os.path.join(path, \n",
    "                               \"source_data\", \n",
    "                               eco + \"_espg_\" + espg + \".tif\"))\n",
    "    raster_layer = rxr.open_rasterio(raster_path, masked=True).squeeze()\n",
    "    raster_extent = plotting_extent(raster_layer, \n",
    "                                    raster_layer.rio.transform())\n",
    "\n",
    "    # open shapefile created in the 'set_source_files_crs' function\n",
    "    shp_path = os.path.normpath(os.path.join(\n",
    "        path, \"source_data\", eco + \"_espg_\" + espg + \".shp\"))         \n",
    "    shp_layer = gpd.read_file(shp_path)\n",
    "    \n",
    "    # open '_ssoln' file created by Marxan and saved to 'output' directory\n",
    "    globfile = glob(os.path.normpath(os.path.join(path, 'output', \n",
    "                                                  '*_ssoln*')))\n",
    "    if globfile == []:\n",
    "        output = print (\n",
    "            \"ERROR: summed solutions file not found - check output/log. \\n\"\n",
    "            \"Will need to resolve error and rerun Marxan if not completed \"\n",
    "            \"successfully\")\n",
    "    else:\n",
    "        ssoln_path = globfile[0]\n",
    "        ssoln = pd.read_csv(ssoln_path)\n",
    "        ssoln = ssoln.rename(columns={'planning_unit': 'PUID'})\n",
    "\n",
    "        # merge ssoln df to shp layer\n",
    "        shp_layer.insert(0, 'PUID', range(1, 1 + len(shp_layer)))\n",
    "        shp_layer = shp_layer.merge(ssoln, on='PUID')\n",
    "        shp_w_ssoln = shp_layer.to_file(eco + \"_w_ssoln.shp\", index=False)\n",
    "        print (eco + '.shp merged with ' + scen_id + \"_ssoln.csv, saved as \" + eco \n",
    "               + \"_w_ssoln.shp file\")\n",
    "        print ('preparing plots...')\n",
    "\n",
    "        # create visualization showing hexcell selection from summed solution\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        shp_layer.plot(column='number', cmap='viridis', ax=ax, alpha=0.65)\n",
    "        ax.imshow(raster_layer, cmap='jet', extent=raster_extent, \n",
    "                  interpolation='nearest')\n",
    "        ax.set(title= scen_id + ': summed solution' + \n",
    "               '\\n(hex cell selection frequency)')\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        ssoln_plot = plt.savefig('ssoln_plot.png', facecolor='w', edgecolor='k', \n",
    "                                dpi=1200)  \n",
    "        plt.close(fig)\n",
    "        print (scen_id + \": ssoln plot saved as .png\")\n",
    "\n",
    "        output = (shp_w_ssoln, ssoln_plot)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4158569",
   "metadata": {},
   "source": [
    "FUNCTION TO CREATE PUVSP.DAT & SPEC.DAT\n",
    "(PUVSP_SPORDER.DAT not needed, as currently we are looking at only one ecosystem at a time)\n",
    "\n",
    "* find code to replicate the Zonal Histogram tool in QGIS (Processing Toolbox > Raster Analysis > Zonal Histogram)\n",
    "https://docs.qgis.org/3.22/en/docs/user_manual/processing_algs/qgis/rasteranalysis.html#zonal-histogram\n",
    "import processing\n",
    "processing.run(\"algorithm_id\", {parameter_dictionary})\n",
    "\n",
    "I think this comes from pyQGIS, but I don't think that is included with the earth-analytics-python-env??\n",
    "\n",
    "Here's info on running pyQGIS in Jupyter\n",
    "https://lerryws.xyz/posts/PyQGIS-in-Jupyter-Notebook\n",
    "\n",
    "here's my initial guess, using parameters copied from QGIS 'Zonal Histograms' log -\n",
    "from qgis.core import processing\n",
    "processing.run(\"native:zonalhistogram\", { 'COLUMN_PREFIX' : '', 'INPUT_RASTER' : 'F:/NatureServe/LanasData/raster/foothill_r.tif', 'INPUT_VECTOR' : 'F:/NatureServe/LanasData/marxan_prep/foothill/pulayercws.shp', 'OUTPUT' : 'F:/NatureServe/pulayerfeatures.shp', 'RASTER_BAND' : 1 })\n",
    "\n",
    "* add column, multiplying pixel count by raster pixel area variable (our data's is 900, 30m x 30m = 900 sq m/pixel), this gives total extent of ecosystem within each individual planning unit hex of the hexfile.shp (ex. if pixelcount = 5, area = 4500, or 5 x 900)\n",
    "\n",
    "* use this as the source info for qmarxan 'export feature files' function\n",
    "input parameters copied from QGIS -\n",
    "Input parameters:\n",
    "{ 'FEAT_FIELDS' : ['7147'], 'OUT_DIR' : 'F:\\\\NatureServe\\\\524 QM test\\\\input', 'PU_FIELD' : 'PUID', 'PU_LAYER' : 'F:/NatureServe/pulayerfeatures.shp' }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
