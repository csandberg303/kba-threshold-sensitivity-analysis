{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa221e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import io\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import shutil\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "# from qgis.core import *\n",
    "# import qmarxan_utils as qmu # import runMarxanOnce\n",
    "# import marxanconpy as mx\n",
    "\n",
    "import contextily as cx\n",
    "import earthpy as et\n",
    "import earthpy.plot as ep\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.plot import plotting_extent\n",
    "import rioxarray as rxr\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "\n",
    "import kba_thresh_sa_scripts as ks\n",
    "\n",
    "# set global cache override variable\n",
    "CACHE_OVERRIDE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1fc750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST CELL\n",
    "# # bigrunpath = os.path.normpath(os.path.join(G:\\CHRISTY\\fromHarddrive\\kba_thresh_sa\\20220619_144619rm_3r_1000000i_10000))\n",
    "# bigfile = open(r\"G:/CHRISTY/fromHarddrive/kba_thresh_sa/20220619_144619rm_3r_1000000i_10000/final_summary.csv\", \"r\")\n",
    "# bigfile = pd.read_csv(bigfile)\n",
    "# file_mv = bigfile.loc[bigfile['Missing_Values'] == 0]\n",
    "# file_mv = file_mv.sort_values(\"Score\")\n",
    "# file_mv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a6fa16",
   "metadata": {},
   "source": [
    "#### Check for 'earth-analytics/data/kba_thresh_sa' directory\n",
    "* If it exists, it will be set as the working directory.\n",
    "* If it doesn't exist, user is prompted to return to first notebook in workflow.\n",
    "\n",
    "#### *IN THE FUTURE -* \n",
    "* Should there also be a check to verify that the 'hex_shp' dir exists, and/or \n",
    "that the 'hex_shp' directory actually contains shapefiles? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1dd032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory is set to earth-analytics/data/kba_thresh_sa.\n"
     ]
    }
   ],
   "source": [
    "# Define a filepath to 'earth-analytics/data/kba_thresh_sa' directory\n",
    "data_path = os.path.normpath(os.path.join(et.io.HOME, \n",
    "                                          'earth-analytics', \n",
    "                                          'data', \n",
    "                                          'kba_thresh_sa'))\n",
    "\n",
    "# Check if 'kba_thresh_sa' directory exists.  If it doesn't, prompt user to \n",
    "# return to the first notebook to begin workflow.  If it does, change working\n",
    "# directory to 'earth-analytics/data/kba_thresh_sa', and define the path to \n",
    "# hex files directory that was created in the first notebook.\n",
    "if os.path.exists(data_path):\n",
    " print('Working directory is set to earth-analytics/data/kba_thresh_sa.')\n",
    " os.chdir(data_path)\n",
    " # define the path to the hexfiles that was created in the 1st notebook\n",
    " shp_data_path = os.path.normpath(os.path.join(data_path, 'hex_shp'))\n",
    "else:\n",
    " print(\"Please go to first notebook in workflow to set up initial'\\\n",
    "      'directories\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd9e6b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to Marxan.exe executable file has been manually copied over to \n",
    "# 'kba_thresh_sa' directory (maybe it can be copied to there from repo?\n",
    "\n",
    "# v4.0.6 (might be causing 'target2' crash? use 2.43 instead)\n",
    "marxan_path = os.path.join(data_path, \"Marxan_x64.exe\")\n",
    "\n",
    "# v2.43\n",
    "marxan_243_path = os.path.join(data_path, 'Marxan_x64_243.exe')\n",
    "\n",
    "# v1.8.10\n",
    "marxan_1810_path = os.path.join(data_path, 'Marxan_1_8_10.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8976ca3c",
   "metadata": {},
   "source": [
    "#### Save table of information to 'earth-analytics/data/kba_thresh_sa'  \n",
    "\n",
    "* The workflow requires an associated table, with information about the \n",
    "ecosystems to be analyzed *(Need to provide more detail about what specific \n",
    "information this table requires... Or will we simply work with the full Landfire\n",
    "readme info, which is saved to the repo?  If so, do we need to add a unique \n",
    "one-word 'Short_Name' to each ecosystem listed, or change the file-naming system \n",
    "to use one of the existing numerical unique identifiers - like 'OID' or \n",
    "'Value'?)*.  \n",
    "\n",
    "* This file will be saved locally to the 'earth-analytics/data/kba_thresh_sa' \n",
    "directory.  \n",
    "\n",
    "* In our inital workflow, we are using the 'LF_EVT_2020_README' file that was\n",
    "provided along with the Landfire raster.  \n",
    "&nbsp; I've manually edited this file to  \n",
    "&emsp; 1. show only the rows for the nine ecosystems selected for initial \n",
    "analysis.  \n",
    "&emsp; 2. add a new column to show the one word short name Lana used when creating \n",
    "her initial files in ArcGIS.  \n",
    "\n",
    "* This file has been manually uploaded to our GitHub repo as 'Assets/Data/\n",
    "from_LF_EVT_2020_README.csv'. \n",
    "\n",
    "* The code below will download that file from URL to a pandas dataframe, then\n",
    "save that dataframe locally as a csv.  \n",
    "\n",
    "#### *IN THE FUTURE -* \n",
    "* This existing code could be reused if the user were prompted for a url where \n",
    "they have their table stored?\n",
    "* Or,  \n",
    "&emsp; 1. prompt user to save their table to 'earth-analytics/data/kba_thresh_sa' \n",
    "as specifically named 'ecosystem_info.csv'  \n",
    "&emsp; 2. Then check for 'ecosystem_info.csv' in \n",
    "'earth-analytics/data/kba_thresh_sa'  \n",
    "&emsp; 3. If found, load to dataframe  \n",
    "&emsp; &emsp; If not found, prompt user to \"Save ecosystm_info.csv' to 'earth-analytics\n",
    "/data/kba_thresh_sa' directory, then rerun notebook\" \n",
    "        \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd802b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OID</th>\n",
       "      <th>Value</th>\n",
       "      <th>Count_30m</th>\n",
       "      <th>US_hectare</th>\n",
       "      <th>US_km2</th>\n",
       "      <th>EVT_Name_1</th>\n",
       "      <th>LFRDB</th>\n",
       "      <th>elcode</th>\n",
       "      <th>element_gl</th>\n",
       "      <th>NatureServ</th>\n",
       "      <th>...</th>\n",
       "      <th>A3_FINAL</th>\n",
       "      <th>B1_FINAL</th>\n",
       "      <th>B2_FINAL</th>\n",
       "      <th>C3_FINAL</th>\n",
       "      <th>D3_FINAL</th>\n",
       "      <th>RLE_FINAL</th>\n",
       "      <th>GRANK_EQUI</th>\n",
       "      <th>RED</th>\n",
       "      <th>GREEN</th>\n",
       "      <th>BLUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short_Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prairie</th>\n",
       "      <td>132</td>\n",
       "      <td>7142</td>\n",
       "      <td>106116</td>\n",
       "      <td>9550</td>\n",
       "      <td>96</td>\n",
       "      <td>Columbia Basin Palouse Prairie</td>\n",
       "      <td>7142</td>\n",
       "      <td>CES304.792</td>\n",
       "      <td>722880</td>\n",
       "      <td>Columbia Basin Palouse Prairie</td>\n",
       "      <td>...</td>\n",
       "      <td>CR</td>\n",
       "      <td>LC</td>\n",
       "      <td>LC</td>\n",
       "      <td>EN</td>\n",
       "      <td>VU</td>\n",
       "      <td>CR</td>\n",
       "      <td>G1</td>\n",
       "      <td>204</td>\n",
       "      <td>252</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foothill</th>\n",
       "      <td>137</td>\n",
       "      <td>7147</td>\n",
       "      <td>4546277</td>\n",
       "      <td>409165</td>\n",
       "      <td>4092</td>\n",
       "      <td>Western Great Plains Foothill and Piedmont Gra...</td>\n",
       "      <td>7147</td>\n",
       "      <td>CES303.817</td>\n",
       "      <td>722856</td>\n",
       "      <td>Western Great Plains Foothill and Piedmont Gra...</td>\n",
       "      <td>...</td>\n",
       "      <td>VU</td>\n",
       "      <td>LC</td>\n",
       "      <td>LC</td>\n",
       "      <td>NT</td>\n",
       "      <td>LC</td>\n",
       "      <td>VU</td>\n",
       "      <td>G3</td>\n",
       "      <td>218</td>\n",
       "      <td>238</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesic</th>\n",
       "      <td>224</td>\n",
       "      <td>7322</td>\n",
       "      <td>1090956</td>\n",
       "      <td>98186</td>\n",
       "      <td>982</td>\n",
       "      <td>Crowley's Ridge Mesic Loess Slope Forest</td>\n",
       "      <td>7322</td>\n",
       "      <td>CES203.079</td>\n",
       "      <td>798100</td>\n",
       "      <td>Crowley's Ridge Mesic Loess Slope Forest</td>\n",
       "      <td>...</td>\n",
       "      <td>LC</td>\n",
       "      <td>EN</td>\n",
       "      <td>EN</td>\n",
       "      <td>VU</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR (EN-CR)</td>\n",
       "      <td>G1G2</td>\n",
       "      <td>144</td>\n",
       "      <td>201</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bluff</th>\n",
       "      <td>229</td>\n",
       "      <td>7327</td>\n",
       "      <td>2050154</td>\n",
       "      <td>184514</td>\n",
       "      <td>1845</td>\n",
       "      <td>East Gulf Coastal Plain Northern Loess Bluff F...</td>\n",
       "      <td>7327</td>\n",
       "      <td>CES203.481</td>\n",
       "      <td>723105</td>\n",
       "      <td>East Gulf Coastal Plain Northern Loess Bluff F...</td>\n",
       "      <td>...</td>\n",
       "      <td>EN</td>\n",
       "      <td>LC</td>\n",
       "      <td>LC</td>\n",
       "      <td>VU-EN</td>\n",
       "      <td>EN</td>\n",
       "      <td>EN</td>\n",
       "      <td>G2</td>\n",
       "      <td>149</td>\n",
       "      <td>143</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pine</th>\n",
       "      <td>244</td>\n",
       "      <td>7346</td>\n",
       "      <td>5015841</td>\n",
       "      <td>451426</td>\n",
       "      <td>4514</td>\n",
       "      <td>Atlantic Coastal Plain Fall-line Sandhills Lon...</td>\n",
       "      <td>7346</td>\n",
       "      <td>CES203.254</td>\n",
       "      <td>723231</td>\n",
       "      <td>Atlantic Coastal Plain Fall-line Sandhills Lon...</td>\n",
       "      <td>...</td>\n",
       "      <td>EN</td>\n",
       "      <td>LC</td>\n",
       "      <td>LC</td>\n",
       "      <td>VU</td>\n",
       "      <td>CR</td>\n",
       "      <td>EN (EN-CR)</td>\n",
       "      <td>G1G2</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tallgrass</th>\n",
       "      <td>314</td>\n",
       "      <td>7421</td>\n",
       "      <td>10225903</td>\n",
       "      <td>920331</td>\n",
       "      <td>9203</td>\n",
       "      <td>Central Tallgrass Prairie</td>\n",
       "      <td>7421</td>\n",
       "      <td>CES205.683</td>\n",
       "      <td>722976</td>\n",
       "      <td>Central Tallgrass Prairie</td>\n",
       "      <td>...</td>\n",
       "      <td>CR</td>\n",
       "      <td>LC</td>\n",
       "      <td>LC</td>\n",
       "      <td>DD</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>G1</td>\n",
       "      <td>243</td>\n",
       "      <td>201</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dune</th>\n",
       "      <td>323</td>\n",
       "      <td>7431</td>\n",
       "      <td>19717</td>\n",
       "      <td>1775</td>\n",
       "      <td>18</td>\n",
       "      <td>Southwest Florida Dune and Coastal Grassland</td>\n",
       "      <td>7431</td>\n",
       "      <td>CES203.539</td>\n",
       "      <td>723063</td>\n",
       "      <td>Southwest Florida Dune and Coastal Grassland</td>\n",
       "      <td>...</td>\n",
       "      <td>DD</td>\n",
       "      <td>LC</td>\n",
       "      <td>LC</td>\n",
       "      <td>NE</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>G1</td>\n",
       "      <td>245</td>\n",
       "      <td>252</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dome</th>\n",
       "      <td>335</td>\n",
       "      <td>7447</td>\n",
       "      <td>900234</td>\n",
       "      <td>81021</td>\n",
       "      <td>810</td>\n",
       "      <td>South Florida Cypress Dome</td>\n",
       "      <td>7447</td>\n",
       "      <td>CES411.365</td>\n",
       "      <td>723151</td>\n",
       "      <td>South Florida Cypress Dome</td>\n",
       "      <td>...</td>\n",
       "      <td>DD</td>\n",
       "      <td>VU</td>\n",
       "      <td>LC</td>\n",
       "      <td>DD</td>\n",
       "      <td>LC</td>\n",
       "      <td>VU</td>\n",
       "      <td>G3</td>\n",
       "      <td>54</td>\n",
       "      <td>163</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marsh</th>\n",
       "      <td>676</td>\n",
       "      <td>9197</td>\n",
       "      <td>1634510</td>\n",
       "      <td>147106</td>\n",
       "      <td>1471</td>\n",
       "      <td>Northern Atlantic Coastal Plain Tidal Salt Marsh</td>\n",
       "      <td>9197</td>\n",
       "      <td>CES203.519</td>\n",
       "      <td>723073</td>\n",
       "      <td>Northern Atlantic Coastal Plain Tidal Salt Marsh</td>\n",
       "      <td>...</td>\n",
       "      <td>EN</td>\n",
       "      <td>LC</td>\n",
       "      <td>LC</td>\n",
       "      <td>DD</td>\n",
       "      <td>EN</td>\n",
       "      <td>EN</td>\n",
       "      <td>G2</td>\n",
       "      <td>131</td>\n",
       "      <td>173</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            OID  Value  Count_30m  US_hectare  US_km2  \\\n",
       "Short_Name                                              \n",
       "prairie     132   7142     106116        9550      96   \n",
       "foothill    137   7147    4546277      409165    4092   \n",
       "mesic       224   7322    1090956       98186     982   \n",
       "bluff       229   7327    2050154      184514    1845   \n",
       "pine        244   7346    5015841      451426    4514   \n",
       "tallgrass   314   7421   10225903      920331    9203   \n",
       "dune        323   7431      19717        1775      18   \n",
       "dome        335   7447     900234       81021     810   \n",
       "marsh       676   9197    1634510      147106    1471   \n",
       "\n",
       "                                                   EVT_Name_1  LFRDB  \\\n",
       "Short_Name                                                             \n",
       "prairie                        Columbia Basin Palouse Prairie   7142   \n",
       "foothill    Western Great Plains Foothill and Piedmont Gra...   7147   \n",
       "mesic                Crowley's Ridge Mesic Loess Slope Forest   7322   \n",
       "bluff       East Gulf Coastal Plain Northern Loess Bluff F...   7327   \n",
       "pine        Atlantic Coastal Plain Fall-line Sandhills Lon...   7346   \n",
       "tallgrass                           Central Tallgrass Prairie   7421   \n",
       "dune             Southwest Florida Dune and Coastal Grassland   7431   \n",
       "dome                               South Florida Cypress Dome   7447   \n",
       "marsh        Northern Atlantic Coastal Plain Tidal Salt Marsh   9197   \n",
       "\n",
       "                elcode  element_gl  \\\n",
       "Short_Name                           \n",
       "prairie     CES304.792      722880   \n",
       "foothill    CES303.817      722856   \n",
       "mesic       CES203.079      798100   \n",
       "bluff       CES203.481      723105   \n",
       "pine        CES203.254      723231   \n",
       "tallgrass   CES205.683      722976   \n",
       "dune        CES203.539      723063   \n",
       "dome        CES411.365      723151   \n",
       "marsh       CES203.519      723073   \n",
       "\n",
       "                                                   NatureServ  ... A3_FINAL  \\\n",
       "Short_Name                                                     ...            \n",
       "prairie                        Columbia Basin Palouse Prairie  ...       CR   \n",
       "foothill    Western Great Plains Foothill and Piedmont Gra...  ...       VU   \n",
       "mesic                Crowley's Ridge Mesic Loess Slope Forest  ...       LC   \n",
       "bluff       East Gulf Coastal Plain Northern Loess Bluff F...  ...       EN   \n",
       "pine        Atlantic Coastal Plain Fall-line Sandhills Lon...  ...       EN   \n",
       "tallgrass                           Central Tallgrass Prairie  ...       CR   \n",
       "dune             Southwest Florida Dune and Coastal Grassland  ...       DD   \n",
       "dome                               South Florida Cypress Dome  ...       DD   \n",
       "marsh        Northern Atlantic Coastal Plain Tidal Salt Marsh  ...       EN   \n",
       "\n",
       "           B1_FINAL B2_FINAL  C3_FINAL D3_FINAL   RLE_FINAL GRANK_EQUI  RED  \\\n",
       "Short_Name                                                                    \n",
       "prairie          LC       LC        EN       VU          CR         G1  204   \n",
       "foothill         LC       LC        NT       LC          VU         G3  218   \n",
       "mesic            EN       EN        VU       CR  CR (EN-CR)       G1G2  144   \n",
       "bluff            LC       LC     VU-EN       EN          EN         G2  149   \n",
       "pine             LC       LC        VU       CR  EN (EN-CR)       G1G2   70   \n",
       "tallgrass        LC       LC        DD       CR          CR         G1  243   \n",
       "dune             LC       LC        NE       CR          CR         G1  245   \n",
       "dome             VU       LC        DD       LC          VU         G3   54   \n",
       "marsh            LC       LC        DD       EN          EN         G2  131   \n",
       "\n",
       "           GREEN BLUE  \n",
       "Short_Name             \n",
       "prairie      252  105  \n",
       "foothill     238  243  \n",
       "mesic        201  143  \n",
       "bluff        143   26  \n",
       "pine          96   32  \n",
       "tallgrass    201   28  \n",
       "dune         252  179  \n",
       "dome         163  120  \n",
       "marsh        173  223  \n",
       "\n",
       "[9 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the csv file stored on GitHub repository \n",
    "# (contains info on selected ecosystems taken from LF_EVT_2020_README \n",
    "# file, with an added 'Short_Name' field that is used as index)\n",
    "\n",
    "# Provide the URL (using raw content at GitHub)\n",
    "ecoinfo_url = (\"https://raw.githubusercontent.com/csandberg303/\"\n",
    "               \"kba-threshold-sensitivity-analysis/main/assets/data/\"\n",
    "               \"from_LF_EVT_2020_README.csv\")\n",
    "\n",
    "# Create local cache overide variable\n",
    "cache_override = True or CACHE_OVERRIDE\n",
    "\n",
    "# Provide the path to local directory\n",
    "ecoinfo_path = os.path.normpath(\n",
    "    os.path.join(data_path, 'from_LF_EVT_2020_README.csv'))\n",
    "\n",
    "# Create dataframe from information at provided URL\n",
    "ecoinfo_df = pd.read_csv(ecoinfo_url).set_index('Short_Name')\n",
    "\n",
    "# Check for csv in local directory and create from df if needed\n",
    "if not os.path.exists(ecoinfo_path) or cache_override:\n",
    "    # Read csv at URL into pandas dataframe, using 'Short_Name' col as index\n",
    "    ecoinfo_df.to_csv(ecoinfo_path)\n",
    "    \n",
    "ecoinfo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7d67038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OID</th>\n",
       "      <th>Value</th>\n",
       "      <th>Count_30m</th>\n",
       "      <th>US_hectare</th>\n",
       "      <th>US_km2</th>\n",
       "      <th>EVT_Name_1</th>\n",
       "      <th>LFRDB</th>\n",
       "      <th>elcode</th>\n",
       "      <th>element_gl</th>\n",
       "      <th>NatureServ</th>\n",
       "      <th>...</th>\n",
       "      <th>B2_FINAL</th>\n",
       "      <th>C3_FINAL</th>\n",
       "      <th>D3_FINAL</th>\n",
       "      <th>RLE_FINAL</th>\n",
       "      <th>GRANK_EQUI</th>\n",
       "      <th>RED</th>\n",
       "      <th>GREEN</th>\n",
       "      <th>BLUE</th>\n",
       "      <th>Type</th>\n",
       "      <th>Current_IUCN_TH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short_Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prairie</th>\n",
       "      <td>132</td>\n",
       "      <td>7142</td>\n",
       "      <td>106116</td>\n",
       "      <td>9550</td>\n",
       "      <td>96</td>\n",
       "      <td>Columbia Basin Palouse Prairie</td>\n",
       "      <td>7142</td>\n",
       "      <td>CES304.792</td>\n",
       "      <td>722880</td>\n",
       "      <td>Columbia Basin Palouse Prairie</td>\n",
       "      <td>...</td>\n",
       "      <td>LC</td>\n",
       "      <td>EN</td>\n",
       "      <td>VU</td>\n",
       "      <td>CR</td>\n",
       "      <td>G1</td>\n",
       "      <td>204</td>\n",
       "      <td>252</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foothill</th>\n",
       "      <td>137</td>\n",
       "      <td>7147</td>\n",
       "      <td>4546277</td>\n",
       "      <td>409165</td>\n",
       "      <td>4092</td>\n",
       "      <td>Western Great Plains Foothill and Piedmont Gra...</td>\n",
       "      <td>7147</td>\n",
       "      <td>CES303.817</td>\n",
       "      <td>722856</td>\n",
       "      <td>Western Great Plains Foothill and Piedmont Gra...</td>\n",
       "      <td>...</td>\n",
       "      <td>LC</td>\n",
       "      <td>NT</td>\n",
       "      <td>LC</td>\n",
       "      <td>VU</td>\n",
       "      <td>G3</td>\n",
       "      <td>218</td>\n",
       "      <td>238</td>\n",
       "      <td>243</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesic</th>\n",
       "      <td>224</td>\n",
       "      <td>7322</td>\n",
       "      <td>1090956</td>\n",
       "      <td>98186</td>\n",
       "      <td>982</td>\n",
       "      <td>Crowley's Ridge Mesic Loess Slope Forest</td>\n",
       "      <td>7322</td>\n",
       "      <td>CES203.079</td>\n",
       "      <td>798100</td>\n",
       "      <td>Crowley's Ridge Mesic Loess Slope Forest</td>\n",
       "      <td>...</td>\n",
       "      <td>EN</td>\n",
       "      <td>VU</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR (EN-CR)</td>\n",
       "      <td>G1G2</td>\n",
       "      <td>144</td>\n",
       "      <td>201</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bluff</th>\n",
       "      <td>229</td>\n",
       "      <td>7327</td>\n",
       "      <td>2050154</td>\n",
       "      <td>184514</td>\n",
       "      <td>1845</td>\n",
       "      <td>East Gulf Coastal Plain Northern Loess Bluff F...</td>\n",
       "      <td>7327</td>\n",
       "      <td>CES203.481</td>\n",
       "      <td>723105</td>\n",
       "      <td>East Gulf Coastal Plain Northern Loess Bluff F...</td>\n",
       "      <td>...</td>\n",
       "      <td>LC</td>\n",
       "      <td>VU-EN</td>\n",
       "      <td>EN</td>\n",
       "      <td>EN</td>\n",
       "      <td>G2</td>\n",
       "      <td>149</td>\n",
       "      <td>143</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pine</th>\n",
       "      <td>244</td>\n",
       "      <td>7346</td>\n",
       "      <td>5015841</td>\n",
       "      <td>451426</td>\n",
       "      <td>4514</td>\n",
       "      <td>Atlantic Coastal Plain Fall-line Sandhills Lon...</td>\n",
       "      <td>7346</td>\n",
       "      <td>CES203.254</td>\n",
       "      <td>723231</td>\n",
       "      <td>Atlantic Coastal Plain Fall-line Sandhills Lon...</td>\n",
       "      <td>...</td>\n",
       "      <td>LC</td>\n",
       "      <td>VU</td>\n",
       "      <td>CR</td>\n",
       "      <td>EN (EN-CR)</td>\n",
       "      <td>G1G2</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tallgrass</th>\n",
       "      <td>314</td>\n",
       "      <td>7421</td>\n",
       "      <td>10225903</td>\n",
       "      <td>920331</td>\n",
       "      <td>9203</td>\n",
       "      <td>Central Tallgrass Prairie</td>\n",
       "      <td>7421</td>\n",
       "      <td>CES205.683</td>\n",
       "      <td>722976</td>\n",
       "      <td>Central Tallgrass Prairie</td>\n",
       "      <td>...</td>\n",
       "      <td>LC</td>\n",
       "      <td>DD</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>G1</td>\n",
       "      <td>243</td>\n",
       "      <td>201</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dune</th>\n",
       "      <td>323</td>\n",
       "      <td>7431</td>\n",
       "      <td>19717</td>\n",
       "      <td>1775</td>\n",
       "      <td>18</td>\n",
       "      <td>Southwest Florida Dune and Coastal Grassland</td>\n",
       "      <td>7431</td>\n",
       "      <td>CES203.539</td>\n",
       "      <td>723063</td>\n",
       "      <td>Southwest Florida Dune and Coastal Grassland</td>\n",
       "      <td>...</td>\n",
       "      <td>LC</td>\n",
       "      <td>NE</td>\n",
       "      <td>CR</td>\n",
       "      <td>CR</td>\n",
       "      <td>G1</td>\n",
       "      <td>245</td>\n",
       "      <td>252</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dome</th>\n",
       "      <td>335</td>\n",
       "      <td>7447</td>\n",
       "      <td>900234</td>\n",
       "      <td>81021</td>\n",
       "      <td>810</td>\n",
       "      <td>South Florida Cypress Dome</td>\n",
       "      <td>7447</td>\n",
       "      <td>CES411.365</td>\n",
       "      <td>723151</td>\n",
       "      <td>South Florida Cypress Dome</td>\n",
       "      <td>...</td>\n",
       "      <td>LC</td>\n",
       "      <td>DD</td>\n",
       "      <td>LC</td>\n",
       "      <td>VU</td>\n",
       "      <td>G3</td>\n",
       "      <td>54</td>\n",
       "      <td>163</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marsh</th>\n",
       "      <td>676</td>\n",
       "      <td>9197</td>\n",
       "      <td>1634510</td>\n",
       "      <td>147106</td>\n",
       "      <td>1471</td>\n",
       "      <td>Northern Atlantic Coastal Plain Tidal Salt Marsh</td>\n",
       "      <td>9197</td>\n",
       "      <td>CES203.519</td>\n",
       "      <td>723073</td>\n",
       "      <td>Northern Atlantic Coastal Plain Tidal Salt Marsh</td>\n",
       "      <td>...</td>\n",
       "      <td>LC</td>\n",
       "      <td>DD</td>\n",
       "      <td>EN</td>\n",
       "      <td>EN</td>\n",
       "      <td>G2</td>\n",
       "      <td>131</td>\n",
       "      <td>173</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            OID  Value  Count_30m  US_hectare  US_km2  \\\n",
       "Short_Name                                              \n",
       "prairie     132   7142     106116        9550      96   \n",
       "foothill    137   7147    4546277      409165    4092   \n",
       "mesic       224   7322    1090956       98186     982   \n",
       "bluff       229   7327    2050154      184514    1845   \n",
       "pine        244   7346    5015841      451426    4514   \n",
       "tallgrass   314   7421   10225903      920331    9203   \n",
       "dune        323   7431      19717        1775      18   \n",
       "dome        335   7447     900234       81021     810   \n",
       "marsh       676   9197    1634510      147106    1471   \n",
       "\n",
       "                                                   EVT_Name_1  LFRDB  \\\n",
       "Short_Name                                                             \n",
       "prairie                        Columbia Basin Palouse Prairie   7142   \n",
       "foothill    Western Great Plains Foothill and Piedmont Gra...   7147   \n",
       "mesic                Crowley's Ridge Mesic Loess Slope Forest   7322   \n",
       "bluff       East Gulf Coastal Plain Northern Loess Bluff F...   7327   \n",
       "pine        Atlantic Coastal Plain Fall-line Sandhills Lon...   7346   \n",
       "tallgrass                           Central Tallgrass Prairie   7421   \n",
       "dune             Southwest Florida Dune and Coastal Grassland   7431   \n",
       "dome                               South Florida Cypress Dome   7447   \n",
       "marsh        Northern Atlantic Coastal Plain Tidal Salt Marsh   9197   \n",
       "\n",
       "                elcode  element_gl  \\\n",
       "Short_Name                           \n",
       "prairie     CES304.792      722880   \n",
       "foothill    CES303.817      722856   \n",
       "mesic       CES203.079      798100   \n",
       "bluff       CES203.481      723105   \n",
       "pine        CES203.254      723231   \n",
       "tallgrass   CES205.683      722976   \n",
       "dune        CES203.539      723063   \n",
       "dome        CES411.365      723151   \n",
       "marsh       CES203.519      723073   \n",
       "\n",
       "                                                   NatureServ  ... B2_FINAL  \\\n",
       "Short_Name                                                     ...            \n",
       "prairie                        Columbia Basin Palouse Prairie  ...       LC   \n",
       "foothill    Western Great Plains Foothill and Piedmont Gra...  ...       LC   \n",
       "mesic                Crowley's Ridge Mesic Loess Slope Forest  ...       EN   \n",
       "bluff       East Gulf Coastal Plain Northern Loess Bluff F...  ...       LC   \n",
       "pine        Atlantic Coastal Plain Fall-line Sandhills Lon...  ...       LC   \n",
       "tallgrass                           Central Tallgrass Prairie  ...       LC   \n",
       "dune             Southwest Florida Dune and Coastal Grassland  ...       LC   \n",
       "dome                               South Florida Cypress Dome  ...       LC   \n",
       "marsh        Northern Atlantic Coastal Plain Tidal Salt Marsh  ...       LC   \n",
       "\n",
       "           C3_FINAL D3_FINAL   RLE_FINAL GRANK_EQUI  RED GREEN BLUE Type  \\\n",
       "Short_Name                                                                 \n",
       "prairie          EN       VU          CR         G1  204   252  105    1   \n",
       "foothill         NT       LC          VU         G3  218   238  243    2   \n",
       "mesic            VU       CR  CR (EN-CR)       G1G2  144   201  143    1   \n",
       "bluff         VU-EN       EN          EN         G2  149   143   26    1   \n",
       "pine             VU       CR  EN (EN-CR)       G1G2   70    96   32    1   \n",
       "tallgrass        DD       CR          CR         G1  243   201   28    1   \n",
       "dune             NE       CR          CR         G1  245   252  179    1   \n",
       "dome             DD       LC          VU         G3   54   163  120    2   \n",
       "marsh            DD       EN          EN         G2  131   173  223    1   \n",
       "\n",
       "           Current_IUCN_TH  \n",
       "Short_Name                  \n",
       "prairie               0.05  \n",
       "foothill              0.10  \n",
       "mesic                 0.05  \n",
       "bluff                 0.05  \n",
       "pine                  0.05  \n",
       "tallgrass             0.05  \n",
       "dune                  0.05  \n",
       "dome                  0.10  \n",
       "marsh                 0.05  \n",
       "\n",
       "[9 rows x 57 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add 2 columns to 'ecoinfo_df'\n",
    "\n",
    "# 1st column - Add column 'Type' (needed for CLUZ addin input file \n",
    "#'targets.csv'; might not be needed for marxanconpy) Uses np.select to assign \n",
    "# a number (1 or 2), based upon the string seen in the 'RLE_FINAL' column\n",
    "# (Type = 1 if 'CR', 'CR (CR-EN)', 'EN (CR-EN) or 'EN'; Type = 2 if 'VU')\n",
    "\n",
    "# create a list of conditions\n",
    "type_conditions = [(ecoinfo_df['RLE_FINAL'] == 'CR'), \n",
    "                  (ecoinfo_df['RLE_FINAL'] == 'CR (EN-CR)'),\n",
    "                  (ecoinfo_df['RLE_FINAL'] == 'EN'),\n",
    "                  (ecoinfo_df['RLE_FINAL'] == 'EN (EN-CR)'),\n",
    "                  (ecoinfo_df['RLE_FINAL'] == 'VU')]\n",
    "\n",
    "# create a list of the values to assign for each condition\n",
    "type_values = [1, 1, 1, 1, 2]\n",
    "\n",
    "# create new column using np.select to assign values using lists as arguments\n",
    "ecoinfo_df['Type'] = np.select(type_conditions, type_values)\n",
    "\n",
    "# 2nd column - Add column 'Current_IUCN_TH'. Uses np.select to assign a \n",
    "# threshold percentage, based upon the column 'Type' (5% if 1, 10% if 2)\n",
    "\n",
    "# create a list of conditions\n",
    "current_threshold_conditions = [(ecoinfo_df['Type'] == 1), \n",
    "                               (ecoinfo_df['Type'] == 2)]\n",
    "\n",
    "# create a list of the values to assign for each condition\n",
    "current_threshold_values = [.05, .10]\n",
    "\n",
    "# create new column using np.select to assign values using lists as arguments\n",
    "ecoinfo_df['Current_IUCN_TH'] = np.select(\n",
    "    current_threshold_conditions, current_threshold_values)\n",
    "\n",
    "ecoinfo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118406c0",
   "metadata": {},
   "source": [
    "#### *IN THE FUTURE -* \n",
    "\n",
    "Currently our code will work with the ecosystem raster and hex files that Lana \n",
    "created in ArcGIS using the ArcMarxan plugin.  Ultimately we hope to work directly\n",
    "with the full Landfire EVT 2020 raster, but the file is proving too large to \n",
    "effectively manage with our personal laptops. A solution may be found using the \n",
    "2016 Landfire data which has an available API (the 2020 data is scheduled to be \n",
    "published to the API later this year). An alternitive solution may be found using \n",
    "Dask, or possibly Amazon Web Services.\n",
    "\n",
    "If/When our code can access the full CONUS raster, the source data in repo assets \n",
    "(and links that file in this code) will need to be updated to the full version of \n",
    "the raster's LF_2020_EVT_README file. Once that occurs, we could ask for user \n",
    "input to get entries matching the 'Values' column in that file, as a way of \n",
    "selecting specific ecosystems from the full Landfire EVT 2020 data. That user \n",
    "input would be assigned to a list variable 'value_filter'. \n",
    "\n",
    "The user would then be prompted for a one-word 'Short_Name' value for each \n",
    "ecosystem being analyzed (ex. mesic, dune, dome), to be used in file naming. This \n",
    "abbreviated name would be added to the ecoinfo_df.  \n",
    "\n",
    "Currently the 'Short_Name' values have been hardcoded, to match what Lana chose \n",
    "when creating her ArcGis files. The 'value_filter' variable will also be \n",
    "hardcoded, to match the values seen in the LF_2020_EVT_README file for the three \n",
    "ecosystems we are using as test data (Crowley's Ridge Mesic Loess Slope Forest, \n",
    "Southwest Florida Dune and Coastal Grassland, and South Florida Cypress Dome).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58116e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dome', 'dune', 'mesic']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE LISTS THAT WILL BE USED LATER IN ITERATION LOOPS\n",
    "\n",
    "# Create list of threshold values to test\n",
    "test_threshold = [1.0, 0.25, 0.50, 0.75] \n",
    "\n",
    "# Define list variable 'value_filter' to show the values matching the 'Values' \n",
    "# column of 'ecoinfo_df' for the three ecosystems which have shp and hex files \n",
    "# uploaded to the GitHub repository - 'dome', 'dune', and 'mesic', \n",
    "value_filter = [\n",
    "    7431, # dune\n",
    "    7322, # mesic\n",
    "    7447 # dome\n",
    "    ]\n",
    "\n",
    "# use value_filter to create a new df with only matching records\n",
    "eco_subset_df = ecoinfo_df[ecoinfo_df['Value'].isin(value_filter)]\n",
    "\n",
    "# Create alphabetical list of ecosystems to be analyzed, taken from the \n",
    "# 'Short_Name' column of eco_subset_df\n",
    "eco_list = eco_subset_df.index.values.tolist()\n",
    "eco_list.sort()\n",
    "\n",
    "# print(eco_list)\n",
    "eco_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93362939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE VARIABLES TO BE USED IN MARXAN RUN\n",
    "\n",
    "# provide a testrun_basename (will appear in filename for final summary files)\n",
    "testrun_basename = 'fullrun_2plots'\n",
    "\n",
    "# ESPG value to set as CRS for raster and shapefile\n",
    "espg = '5070'\n",
    "\n",
    "# # Set prop for spec.dat (default value = 30% of total extent) \n",
    "# (must be between 0 and 1, Lana tutorial suggested 0.3)\n",
    "prop = 0.3\n",
    "\n",
    "# Species Penalty Factor - more detail needed... we're using default val of 1\n",
    "spf = 10\n",
    "\n",
    "# Number of repeat runs (or solutions) - orig value in qmarxan = 100\n",
    "numreps = 100\n",
    "\n",
    "# Number of iterations for annealing \n",
    "# orig value 1000000\n",
    "# (RUNMODE 1 & 3 did not complete successfully with numitins=10 (or 1000?)\n",
    "numitns = 10000\n",
    "\n",
    "# Set blm (default value from qmarxan code = 1)\n",
    "blm = 100\n",
    "    \n",
    "# test runmode\n",
    "# runmode_ls = [1 , 3] # runmode_ls used for test loop only, no longer needed\n",
    "runmode = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b275729",
   "metadata": {},
   "source": [
    "#### Loop through the eco_list, create directories and input files needed by Marxan.\n",
    "\n",
    "Each time the code below runs, a new timestamped diretory is created. Inside will\n",
    "be subdirectories created from the 'Short_Name' value of the selected ecosystems \n",
    "seen in the 'eco_subset' variable.\n",
    "\n",
    "Each of these ecosystem subdirectories will have the following named \n",
    "subdirectories -\n",
    "* input - where files needed by marxan analysis are stored (bound.dat, pu.dat, \n",
    "puvsp.dat, spec.dat)\n",
    "* output - where files generated by marxan analysis are stored\n",
    "* pu - pu and report seen in qmarxan setup (purpose tbd)\n",
    "* report - pu and report seen in qmarxan setup (purpose tbd)\n",
    "* source data - where the rasters and PU hex_shp files are moved to, after they\n",
    "are copied from the 'r_tif' and 'hex_shp' folders\n",
    "\n",
    "A fifth input file 'input.dat' is created and placed in the main ecosystem \n",
    "directory.\n",
    "\n",
    "The code below will also create a 'targets.csv' file for each value in \n",
    "the 'test_threshold' list variable.  This is done using the function \n",
    "'create_targets_files'. These 'targets.csv' files are used by the CLUZ \n",
    "plugin in QGIS.  They are not used by the QMarxan QGIS plugin, and ultimately may\n",
    "not be needed for our marxanconpy workflow.  *Perhaps the loop inside\n",
    "the function that uses the 'test_threshold' variable could be reused for another \n",
    "purpose?*\n",
    "\n",
    "Currently, we are using the input files that Lana created using ArcGIS, that have \n",
    "been saved to the repo.  The code below will simply copy those files from the repo \n",
    "and save them into each ecosystem's 'input' folder.\n",
    "\n",
    "#### *IN THE FUTURE -* \n",
    "* Our project sponsor has said that the set of input files are commonly prepared \n",
    "using GIS tools.  If that is the practice we will continue, new files for \n",
    "additional ecosystmes will be generated using QGIS/QMarxan.\n",
    "* Another option may be to create a new function in this workflow for each \n",
    "specific input file (input.dat, bound.dat, pu.dat, puvsp.dat, spec.dat.).  A \n",
    "function has been written to create the input.dat file, using code seen in the \n",
    "qmarxan repository from Apropos Information Systems (used under the GPL-2.0 \n",
    "license). Creating the input files programatically rather than in GIS may allow \n",
    "for easier manipulation of the files within the workflow to perform the \n",
    "sensitivity analysis of the KBA threshold values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee45611",
   "metadata": {},
   "source": [
    " #### Conducting a Sensitivity Analysis of the IUCN TH - spec.dat 'target2'\n",
    " \n",
    " The KBA threshold can be tested using the 'target2' column in the spec.dat \n",
    " input file.  \n",
    "'target2' sets a minimum size for an identified area to count against \n",
    "the target value.  If a patch of selected hexcells does not meet that\n",
    "minimum value, it won't appear in a final solution. \n",
    "This value is calculated for each ecosystem -\n",
    "iterate by - test_threshold = [1.0, 0.75, 0.50, 0.25]\n",
    "'target2' = (total area * 'Current_IUCN_TH') x test_threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8573264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testrun_basename: fullrun_2plots\n",
      "C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\n",
      "\n",
      "runmode: 1\n",
      "heurtype: -1\n",
      "\n",
      "finished copying source files from C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\hex_shp\n",
      "finished copying source files from C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\r_tif\n",
      "pu.dat file created successfully\n",
      "bound.dat successfully copied from url\n",
      "puvsp.dat successfully copied from url\n",
      "orig_input_files: input.dat created successfully\n",
      "spec.dat file created successfully (v4)\n",
      "Begin: dome10_run\n",
      "\n",
      "\n",
      "dome10_run loop_01: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[387, 388, 389, 438, 439, 440, 441, 445, 448, 449, 450, 451, 484, 489]\n",
      "dome10_runinfo from dome10_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome10_run loop_02: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[181, 182, 190, 249, 250, 251, 255, 256, 257, 258, 259, 260, 261, 321, 322, 326, 327]\n",
      "dome10_runinfo from dome10_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome10_run loop_03: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[172, 173, 174, 175, 176, 183, 184, 241, 242, 243, 244, 245, 247, 253, 254, 308]\n",
      "dome10_runinfo from dome10_run will be added to final summary\n",
      "\n",
      "orig_input_files: input.dat created successfully\n",
      "spec.dat file created successfully (v4)\n",
      "Begin: dome025_run\n",
      "\n",
      "\n",
      "dome025_run loop_01: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[438, 439, 444]\n",
      "dome025_runinfo from dome025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome025_run loop_02: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[227, 231, 232]\n",
      "dome025_runinfo from dome025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome025_run loop_03: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[431, 432, 433]\n",
      "dome025_runinfo from dome025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome025_run loop_04: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[377, 381, 383]\n",
      "dome025_runinfo from dome025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome025_run loop_05: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[148, 149, 150, 154]\n",
      "dome025_runinfo from dome025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome025_run loop_06: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[328, 330, 331, 404]\n",
      "dome025_runinfo from dome025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome025_run loop_07: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[391, 392, 393, 402, 403]\n",
      "dome025_runinfo from dome025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome025_run loop_08: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[303, 370, 374, 375, 376]\n",
      "dome025_runinfo from dome025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome025_run loop_09: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[309, 314, 318, 319]\n",
      "dome025_runinfo from dome025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome025_run loop_10: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[229, 230, 300, 304, 305, 306]\n",
      "dome025_runinfo from dome025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome025_run loop_11: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[483, 485, 486, 490, 495]\n",
      "dome025_runinfo from dome025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome025_run loop_12: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[234, 235, 236, 237, 238, 301, 312, 313]\n",
      "dome025_runinfo from dome025_run will be added to final summary\n",
      "\n",
      "orig_input_files: input.dat created successfully\n",
      "spec.dat file created successfully (v4)\n",
      "Begin: dome05_run\n",
      "\n",
      "\n",
      "dome05_run loop_01: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[387, 388, 438, 439, 440, 444, 450]\n",
      "dome05_runinfo from dome05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome05_run loop_02: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[191, 394, 446, 447, 452, 453, 454, 455, 456, 457, 458, 463, 464, 491, 492, 496, 502, 503]\n",
      "dome05_runinfo from dome05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome05_run loop_03: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[108, 111, 112, 113, 316, 317, 324, 325, 329, 385, 390, 426, 430, 442, 482]\n",
      "dome05_runinfo from dome05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome05_run loop_04: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[222, 223, 286, 287, 288, 289, 293, 296, 297, 298, 299, 323, 332, 333, 334, 356, 357, 358, 359, 360, 361, 362, 368, 396, 397, 412, 424]\n",
      "dome05_runinfo from dome05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome05_run loop_05: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[97, 153, 159, 162, 163, 164, 165, 166, 228, 233, 239, 240, 307, 443]\n",
      "dome05_runinfo from dome05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome05_run loop_06: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[15, 103, 104, 179, 180, 311, 320, 378, 437, 488]\n",
      "dome05_runinfo from dome05_run will be added to final summary\n",
      "\n",
      "orig_input_files: input.dat created successfully\n",
      "spec.dat file created successfully (v4)\n",
      "Begin: dome075_run\n",
      "\n",
      "\n",
      "dome075_run loop_01: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[377, 379, 380, 381, 432, 433, 438, 442, 443, 444]\n",
      "dome075_runinfo from dome075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome075_run loop_02: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[57, 94, 96, 99, 102, 109, 116, 118, 151, 160, 161, 185, 208, 209, 213, 214, 215, 216, 217, 218, 219, 220, 221, 224, 225, 226, 252, 280, 281, 282, 283, 285, 290, 291, 292, 295, 349, 350, 354, 355, 363, 364, 365, 369, 386, 395, 398, 401]\n",
      "dome075_runinfo from dome075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome075_run loop_03: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 98, 100, 101, 106, 107, 110, 114, 115, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 152, 156, 157, 158, 167, 168, 169, 170, 171, 177, 178, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 212, 246, 248, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 277, 294, 302, 310, 315, 335, 336, 337, 338, 339, 340, 341, 344, 345, 346, 347, 348, 351, 352, 353, 366, 367, 371, 372, 373, 382, 384, 399, 400, 407, 408, 409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 425, 427, 428, 429, 434, 435, 436, 459, 460, 465, 470, 471, 472, 473, 476, 477, 478, 479, 480, 481, 487, 493, 494, 497, 498, 499, 500, 501, 506, 507, 508, 509, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 527, 528, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 552, 553, 555, 556]\n",
      "dome075_runinfo from dome075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dome075_run loop_04: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 13, 14, 18, 19, 20, 21, 22, 63, 83, 105, 144, 205, 207, 210, 211, 275, 276, 278, 279, 284, 342, 343, 405, 406, 461, 462, 466, 467, 468, 469, 474, 475, 504, 505, 510, 526, 529, 551, 554, 557, 558, 559, 560, 561, 562, 563]\n",
      "dome075_runinfo from dome075_run will be added to final summary\n",
      "\n",
      "finished copying source files from C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\hex_shp\n",
      "finished copying source files from C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\r_tif\n",
      "pu.dat file created successfully\n",
      "bound.dat successfully copied from url\n",
      "puvsp.dat successfully copied from url\n",
      "orig_input_files: input.dat created successfully\n",
      "spec.dat file created successfully (v4)\n",
      "Begin: dune10_run\n",
      "\n",
      "\n",
      "dune10_run loop_01: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[225, 236]\n",
      "dune10_runinfo from dune10_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune10_run loop_02: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[112, 247]\n",
      "dune10_runinfo from dune10_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune10_run loop_03: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[214, 222]\n",
      "dune10_runinfo from dune10_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune10_run loop_04: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[151, 152, 155, 161, 162]\n",
      "dune10_runinfo from dune10_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune10_run loop_05: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[122, 131, 132, 134]\n",
      "dune10_runinfo from dune10_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune10_run loop_06: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[77, 107, 268, 270, 271, 279]\n",
      "dune10_runinfo from dune10_run will be added to final summary\n",
      "\n",
      "orig_input_files: input.dat created successfully\n",
      "spec.dat file created successfully (v4)\n",
      "Begin: dune025_run\n",
      "\n",
      "\n",
      "dune025_run loop_01: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[233]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_02: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[76]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_03: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[115]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_04: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[129]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_05: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[262]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_06: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[220]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_07: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[244]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_08: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[198]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_09: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[160]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_10: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[306, 307]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_11: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[143, 154]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_12: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[223, 227]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_13: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[37, 61]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_14: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[211, 212]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_15: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[264, 272]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_16: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[221, 232]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_17: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[164, 273]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_18: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[177, 206]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_19: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[53, 278]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_20: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[116, 118, 119]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_21: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[158, 285]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_22: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[121, 149]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_23: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[57, 248, 260]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune025_run loop_24: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[171, 259, 265]\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "orig_input_files: input.dat created successfully\n",
      "spec.dat file created successfully (v4)\n",
      "Begin: dune05_run\n",
      "\n",
      "\n",
      "dune05_run loop_01: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[222]\n",
      "dune05_runinfo from dune05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune05_run loop_02: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[56, 133, 137, 140, 141, 142, 144, 145, 146, 243, 245]\n",
      "dune05_runinfo from dune05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune05_run loop_03: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[48, 75, 80, 82, 83, 84, 95, 117, 190]\n",
      "dune05_runinfo from dune05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune05_run loop_04: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[36, 70, 71, 180, 182, 188, 195, 207]\n",
      "dune05_runinfo from dune05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune05_run loop_05: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[170, 204, 228, 237, 239, 240, 241, 249, 310]\n",
      "dune05_runinfo from dune05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune05_run loop_06: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[14, 23, 157, 159, 163, 276, 301, 318, 333]\n",
      "dune05_runinfo from dune05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune05_run loop_07: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[55, 60, 62, 64, 65, 66, 165, 251, 252, 254, 255, 256, 257, 261]\n",
      "dune05_runinfo from dune05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune05_run loop_08: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[7, 11, 12, 52, 153, 208, 258, 263, 281, 284, 286, 287, 288]\n",
      "dune05_runinfo from dune05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune05_run loop_09: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[35, 89, 90, 92, 93, 94, 106, 113, 114, 169, 226, 277, 334]\n",
      "dune05_runinfo from dune05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune05_run loop_10: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[19, 22, 41, 42, 43, 47, 128, 168, 192, 197, 202, 246, 269, 274, 275, 280]\n",
      "dune05_runinfo from dune05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune05_run loop_11: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[8, 9, 15, 16, 25, 67, 68, 69, 81, 85, 99, 120, 147, 193, 210, 224, 230, 294, 330]\n",
      "dune05_runinfo from dune05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune05_run loop_12: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[13, 17, 18, 21, 27, 28, 29, 30, 31, 39, 54, 58, 63, 87, 96, 108, 124, 125, 167, 173, 174, 175, 176, 179, 184, 185, 200, 201, 203, 205, 213, 215, 216, 231, 253, 266, 295, 320]\n",
      "dune05_runinfo from dune05_run will be added to final summary\n",
      "\n",
      "orig_input_files: input.dat created successfully\n",
      "spec.dat file created successfully (v4)\n",
      "Begin: dune075_run\n",
      "\n",
      "\n",
      "dune075_run loop_01: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[236]\n",
      "dune075_runinfo from dune075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune075_run loop_02: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[1, 2, 3, 4, 5, 6, 10, 20, 24, 26, 32, 33, 34, 38, 40, 44, 45, 46, 49, 50, 51, 59, 72, 73, 74, 78, 79, 86, 88, 91, 97, 98, 100, 101, 102, 103, 104, 105, 109, 110, 111, 123, 126, 127, 130, 135, 136, 138, 139, 148, 150, 166, 172, 178, 181, 183, 186, 187, 189, 191, 194, 196, 199, 209, 217, 218, 219, 234, 235, 238, 242, 250, 267, 282, 283, 289, 290, 291, 292, 293, 296, 297, 298, 299, 300, 302, 303, 304, 305, 308, 309, 311, 312, 313, 314, 315, 316, 317, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332]\n",
      "dune075_runinfo from dune075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune075_run loop_03: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "dune075_run: ERROR: 'pu_selected' file not found - check output/log. \n",
      "Will need to resolve error and rerun Marxan if final output files haven't completed successfully\n",
      "dune075_runinfo from dune075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune075_run loop_04: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "dune075_run: ERROR: 'pu_selected' file not found - check output/log. \n",
      "Will need to resolve error and rerun Marxan if final output files haven't completed successfully\n",
      "dune075_runinfo from dune075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune075_run loop_05: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[]\n",
      "dune075_runinfo from dune075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune075_run loop_06: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[]\n",
      "dune075_runinfo from dune075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune075_run loop_07: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "dune075_run: ERROR: 'pu_selected' file not found - check output/log. \n",
      "Will need to resolve error and rerun Marxan if final output files haven't completed successfully\n",
      "dune075_runinfo from dune075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "dune075_run loop_08: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "dune075_run: ERROR: 'pu_selected' file not found - check output/log. \n",
      "Will need to resolve error and rerun Marxan if final output files haven't completed successfully\n",
      "dune075_runinfo from dune075_run will be added to final summary\n",
      "\n",
      "finished copying source files from C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\hex_shp\n",
      "finished copying source files from C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\r_tif\n",
      "pu.dat file created successfully\n",
      "bound.dat successfully copied from url\n",
      "puvsp.dat successfully copied from url\n",
      "orig_input_files: input.dat created successfully\n",
      "spec.dat file created successfully (v4)\n",
      "Begin: mesic10_run\n",
      "\n",
      "\n",
      "mesic10_run loop_01: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[138, 139, 140, 141, 144, 148]\n",
      "mesic10_runinfo from mesic10_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic10_run loop_02: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[230, 231, 235, 241, 242]\n",
      "mesic10_runinfo from mesic10_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic10_run loop_03: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[153, 163, 164, 173, 174, 175]\n",
      "mesic10_runinfo from mesic10_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic10_run loop_04: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[114, 115, 127, 128, 129, 135, 136]\n",
      "mesic10_runinfo from mesic10_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic10_run loop_05: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[208, 210, 211, 212, 213, 215, 220]\n",
      "mesic10_runinfo from mesic10_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic10_run loop_06: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[102, 103, 109, 113, 118, 119, 123, 124]\n",
      "mesic10_runinfo from mesic10_run will be added to final summary\n",
      "\n",
      "orig_input_files: input.dat created successfully\n",
      "spec.dat file created successfully (v4)\n",
      "Begin: mesic025_run\n",
      "\n",
      "\n",
      "mesic025_run loop_01: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[242]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_02: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[52]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_03: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[50]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_04: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[48]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_05: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[244]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_06: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[217, 226]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_07: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44, 46]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_08: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[18, 21]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_09: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[152, 160]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_10: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[54, 55]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_11: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[166, 177]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_12: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[203, 204]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_13: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[142, 151]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_14: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[40, 246]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_15: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[150, 155]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_16: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[240, 248]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_17: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[228, 229]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_18: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[14, 27]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_19: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[36, 38]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_20: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[57, 58]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_21: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[130, 131]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_22: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[188, 245]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_23: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[225, 232]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic025_run loop_24: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[9, 162]\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "orig_input_files: input.dat created successfully\n",
      "spec.dat file created successfully (v4)\n",
      "Begin: mesic05_run\n",
      "\n",
      "\n",
      "mesic05_run loop_01: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[130, 139, 148]\n",
      "mesic05_runinfo from mesic05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic05_run loop_02: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[22, 216, 237]\n",
      "mesic05_runinfo from mesic05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic05_run loop_03: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[15, 16, 24, 67, 69, 70]\n",
      "mesic05_runinfo from mesic05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic05_run loop_04: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[65, 74, 105, 110, 111]\n",
      "mesic05_runinfo from mesic05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic05_run loop_05: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[176, 178, 179, 180, 187, 189, 195]\n",
      "mesic05_runinfo from mesic05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic05_run loop_06: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[17, 20, 169, 227]\n",
      "mesic05_runinfo from mesic05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic05_run loop_07: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[30, 83, 84, 143, 243]\n",
      "mesic05_runinfo from mesic05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic05_run loop_08: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[45, 53, 121, 122, 133, 137]\n",
      "mesic05_runinfo from mesic05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic05_run loop_09: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[64, 71, 72, 73, 80, 81, 134, 149]\n",
      "mesic05_runinfo from mesic05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic05_run loop_10: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[8, 11, 35, 89, 90, 95, 96, 154]\n",
      "mesic05_runinfo from mesic05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic05_run loop_11: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[19, 39, 159, 165, 170, 197, 198, 199]\n",
      "mesic05_runinfo from mesic05_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic05_run loop_12: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[4, 5, 41, 68, 100, 104, 182, 183, 214]\n",
      "mesic05_runinfo from mesic05_run will be added to final summary\n",
      "\n",
      "orig_input_files: input.dat created successfully\n",
      "spec.dat file created successfully (v4)\n",
      "Begin: mesic075_run\n",
      "\n",
      "\n",
      "mesic075_run loop_01: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[152, 153, 174, 175]\n",
      "mesic075_runinfo from mesic075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic075_run loop_02: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[12, 28, 31, 66, 82, 98, 106, 108, 112, 161, 167, 168, 190, 192, 193, 201, 222, 239]\n",
      "mesic075_runinfo from mesic075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic075_run loop_03: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[3, 6, 7, 23, 25, 33, 34, 49, 51, 56, 75, 76, 77, 78, 79, 85, 120, 126, 147, 172, 181, 186, 205, 206, 207, 209, 223, 233, 234, 236, 238, 247]\n",
      "mesic075_runinfo from mesic075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic075_run loop_04: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[1, 2, 13, 26, 29, 32, 37, 42, 43, 47, 59, 60, 62, 63, 86, 88, 91, 92, 93, 94, 97, 101, 107, 117, 132, 145, 146, 156, 157, 158, 171, 184, 196, 218, 219, 221, 224]\n",
      "mesic075_runinfo from mesic075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic075_run loop_05: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "[10, 61, 87, 99, 116, 185, 191, 194, 200, 202]\n",
      "mesic075_runinfo from mesic075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic075_run loop_06: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125, 249]\n",
      "mesic075_runinfo from mesic075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic075_run loop_07: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "mesic075_run: ERROR: 'pu_selected' file not found - check output/log. \n",
      "Will need to resolve error and rerun Marxan if final output files haven't completed successfully\n",
      "mesic075_runinfo from mesic075_run will be added to final summary\n",
      "\n",
      "\n",
      "\n",
      "mesic075_run loop_08: MARXAN ANALYSIS INITIATED\n",
      "time.sleep(15) applied to pause workflow execution while Marxan output files are written\n",
      "mesic075_run: ERROR: 'pu_selected' file not found - check output/log. \n",
      "Will need to resolve error and rerun Marxan if final output files haven't completed successfully\n",
      "mesic075_runinfo from mesic075_run will be added to final summary\n",
      "\n",
      "\n",
      "'final_summary.csv' saved to C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\n",
      "\n",
      "loop completed successfully\n"
     ]
    }
   ],
   "source": [
    "# ********* NEW TEST FOR WHILE LOOP *********\n",
    "# USE THIS CELL FOR MARXAN v4.06 AND MARXAN v2.43 (CURRENTLY USING 2.43)\n",
    "\n",
    "# RUN THIS CELL TO BEGIN AUTOMATED WORKFLOW \n",
    "# (1ST CELL OF TWO - BEGIN MARXAN ANALYSIS)\n",
    "\n",
    "# checks to see if a directory based upon provided 'testrun_basename' has \n",
    "# already been made. If so, a number will be added to the end \n",
    "# 'testrun_basename' before creating new directory (so that each named \n",
    "# directory will be identifiably unique).\n",
    "testrun_basename_ck = glob(os.path.join(data_path, '*' + testrun_basename))\n",
    "if testrun_basename_ck:\n",
    "    expand = 1\n",
    "    while True:\n",
    "        expand +=1\n",
    "        new_tr_bn = testrun_basename + str(expand)\n",
    "        testrun_basename_ck = glob(os.path.join(data_path, '*' + new_tr_bn))\n",
    "        if testrun_basename_ck:\n",
    "            continue\n",
    "        else:\n",
    "            testrun_basename = new_tr_bn\n",
    "            break\n",
    "print('testrun_basename: ' + testrun_basename)\n",
    "\n",
    "# set new directory name, based upon timestamp and provided 'testrun_basename'\n",
    "new_dir = os.path.normpath(\n",
    "    os.path.join(data_path, datetime.datetime.now().strftime('%Y%m%d_%H%M%S') \n",
    "                 + '_' + testrun_basename))\n",
    "os.makedirs(new_dir)\n",
    "print(new_dir + '\\n')\n",
    "\n",
    "# Set 'heurtype' - Determined by runmode entry in input.dat \n",
    "# if RUNMODE = 3 then use heurtype = 1 (greedy), else -1 (not used)\n",
    "# (NOTE: this variable is used for RUNMODE 3 only, and currently this\n",
    "# multiloop workflow is using RUNMODE 1. Keeping it in notebook in case that \n",
    "# may ever change)\n",
    "\n",
    "if runmode == 3:\n",
    "    heurtype = 1\n",
    "else:\n",
    "    heurtype = -1\n",
    "print('runmode: ' + str(runmode) +'\\nheurtype: ' + str(heurtype) +'\\n')\n",
    "\n",
    "\n",
    "### 1ST LOOP BEGINS HERE \n",
    "\n",
    "# LOOP THROUGH ECOSYSTEMS (in 'ecolist') \n",
    "for eco in eco_list:\n",
    "    os.chdir(new_dir)\n",
    "    # create directory for each ecosystem selected for analysis\n",
    "    os.makedirs('eco_' + eco)\n",
    "    os.chdir('eco_' + eco)\n",
    "    eco_data_path = os.path.normpath(os.path.join(new_dir, 'eco_' + eco))\n",
    "    # create 'source_data' directory to store ArcGIS shp and tif files\n",
    "    os.makedirs('source_data')\n",
    "    os.chdir('source_data')\n",
    "    source_data_path = (new_dir, 'eco_' + eco, 'source_data')\n",
    "    # copy source files that were stored locally to the 'hex_shp' and 'r_tif' \n",
    "    # directories after running 1st notebook. Our workflow is currently  \n",
    "    # using the files Lana created manually using ArcGIS\n",
    "    ks.get_source_files_targetloops(os.path.join(data_path, \"hex_shp\"), eco)\n",
    "    ks.get_source_files_targetloops(os.path.join(data_path, \"r_tif\"), eco)\n",
    "     \n",
    "    # create 'orig_input_files' directory to store the 5 .dat files) for the \n",
    "    # ecosystem so that each Marxan analysis loop will pick them up from this \n",
    "    # location (since much info for the analysis runs will remain constant as \n",
    "    # the KBA threshold size is tested) \n",
    "    os.chdir(eco_data_path)\n",
    "    os.makedirs('orig_input_files')\n",
    "    os.chdir('orig_input_files')\n",
    "    orig_input_data_path = os.path.normpath(os.path.join(data_path, \n",
    "                                                         new_dir, \n",
    "                                                         'eco_' + eco, \n",
    "                                                         'orig_input_files'))\n",
    "    \n",
    "    # CREATE INPUT FILES THAT WILL REMAIN CONSTANT DESPITE TEST LEVELS \n",
    "    # (pu.dat, puvsp.dat, bound.dat).  \n",
    "    \n",
    "    # CREATE INITIAL PU.DAT FROM ORIGINAL FORMULA \n",
    "    # Provides a record of each planning unit hex cell in the .shp file,  \n",
    "    # using a default uniform cost of '1', and  a status of '0' which \n",
    "    # indicates that unit is avaialable to Marxan for selection. As the loops \n",
    "    # continue until set proportion target of 30% overall extent is reached, \n",
    "    # this pu.dat file will be updated so that selected cells will show a \n",
    "    # status value of '3' for unavailable/locked-out.\n",
    "    ks.create_pu_dat_targetloops(eco, \n",
    "                                 eco_data_path)  \n",
    "    orig_pu_dat_path = os.path.normpath(os.path.join(\n",
    "        orig_input_data_path, 'pu.dat'))\n",
    "    pu_dat = pd.read_csv(orig_pu_dat_path)\n",
    "\n",
    "    # CREATE 'updated_pu_dat' DF; BASED UPON 'pu.dat'\n",
    "    # This df will be used to track selected cells as loops progress, so that \n",
    "    # those cells will be locked out of selection in future loops.\n",
    "    # (THIS BECOMES THE NEW 'pu.dat' INPUT FILE IN FUTURE LOOPS)\n",
    "    updated_pu_dat = pu_dat.set_index('id')\n",
    "\n",
    "    # CREATE 'pu_selected' DF BASED UPON 'pu.dat'. \n",
    "    # This df will be used to keep an overall record of which cell was \n",
    "    # selected in each loop, so that each loop's selection can be seen and \n",
    "    # measured independently.\n",
    "    pu_selected = pu_dat.set_index('id')\n",
    "    # Initial value of 'select' column is set to 'not selected'\n",
    "    pu_selected['select'] = 'not selected'\n",
    "     \n",
    "    # USE 'get_marxan_input_files' FUNCTION TO COPY IN ANY REMAINING .DAT \n",
    "    # FILES NEEDED THAT ARE CREATED IN ArcGIS/QGIS RATHER THAN PYTHON.\n",
    "    # This formula currently is used for 'bound.dat' and 'puvsp.dat'.\n",
    "    # Formula will copy files that have been created using ArcMarxan tool \n",
    "    # in ArcGIS then saved to the repository.\n",
    "    ks.get_marxan_input_files_targetloops(eco, \n",
    "                                          ['bound.dat', \n",
    "    #                                     \"pu.dat\", \n",
    "                                           'puvsp.dat', \n",
    "    #                                     \"spec.dat\"\n",
    "                                          ])\n",
    "    bound_dat_path = os.path.normpath(os.path.join(\n",
    "        orig_input_data_path, 'bound.dat'))\n",
    "    bound_dat = pd.read_csv(bound_dat_path)\n",
    "    puvsp_dat_path = os.path.normpath(os.path.join(\n",
    "        orig_input_data_path, 'puvsp.dat'))\n",
    "    puvsp_dat = pd.read_csv(puvsp_dat_path)\n",
    "    \n",
    "    os.chdir(eco_data_path)\n",
    "    \n",
    "    # create empty list variable that will be used to collect summary info \n",
    "    # from loops\n",
    "    select_summary_ls = []\n",
    "        \n",
    "    # LOOP THROUGH EACH KBA THRESHOLD SIZE TEST \n",
    "    # (values in 'test_threshold', defined in initial 'CREATE LISTS' cell)\n",
    "    for test in test_threshold:\n",
    "        # set 'target2' variable \n",
    "        # to equal KBA Threshold Value for Ecosystem at Test Level\n",
    "        # target2 = US_m2 x Current_IUCN_TH x threshold test level\n",
    "        current_iucn_th = eco_subset_df.at[eco,'Current_IUCN_TH']\n",
    "        us_km2 = eco_subset_df.at[eco,'US_km2']\n",
    "        us_m2 = us_km2 * 1000000\n",
    "\n",
    "        target2 = test * current_iucn_th * us_m2 \n",
    "        target2 = round(target2)\n",
    "\n",
    "        # set the 'target' used in spec.dat file to equal 'target2'\n",
    "        target = target2\n",
    "        \n",
    "        # create Scenario ID from 'eco' & 'test' \n",
    "        # (used as prefix in filenames, so any '.' seen in 'test' are removed) \n",
    "        scen_id = (eco + str(test).translate(\n",
    "            str.maketrans('', '', '.')) + '_run')\n",
    "        \n",
    "        # CREATE INPUT FILES IN THIS LOOP WHEN THEY REQUIRE TEST LEVEL INFO \n",
    "        # (input.dat, spec.dat)\n",
    "             \n",
    "        # CREATE 'input.dat' FILE USING FORMULA ADAPTED FROM 'qmarxan_toolbox' \n",
    "        # (including the 'formatAsME' format as Marxan Exponent function)\n",
    "        # Some input parameters are provided to the formula, to replace the \n",
    "        # default values provided in the formula code. \n",
    "        ks.create_input_dat(orig_input_data_path, \n",
    "                            blm, numreps, \n",
    "                            numitns, \n",
    "                            runmode, \n",
    "                            heurtype, \n",
    "                            scen_id)\n",
    "        input_dat_path = os.path.normpath(os.path.join(\n",
    "            orig_input_data_path, \"input.dat\"))\n",
    "        input_dat = pd.read_csv(input_dat_path)\n",
    "        \n",
    "        # CREATE THE 'spec.dat' FILE FROM v4 FORMULA (includes 'target' only)\n",
    "        os.chdir(orig_input_data_path)\n",
    "        ks.create_spec_dat_v4_targetloops(eco_subset_df, eco, target, spf)\n",
    "        spec_dat_path = os.path.normpath(os.path.join(\n",
    "            orig_input_data_path, 'spec.dat'))\n",
    "\n",
    "        # Print initial info statement for test loop and begin creating the \n",
    "        # needed directories\n",
    "        print(\"Begin: \" + scen_id)\n",
    "        os.chdir(eco_data_path)\n",
    "        os.makedirs(scen_id) \n",
    "        ecotest_data_path = os.path.normpath(os.path.join(data_path, new_dir, \n",
    "                                                          'eco_' + eco, \n",
    "                                                          scen_id))\n",
    "\n",
    "        # SET 'end_count' VALUE TO END MULTILOOP\n",
    "        # Based upon given 'prop' value of 30% and 'Current_IUCN_TH' \n",
    "        # 1st ex: if prop = 30% & eco is VU(KBA 10%); then 3 x 10% KBA = 30% \n",
    "        # end_count = 3 (@ 1.0 test), 6 @ 0.50 test and 12 @ 0.25 test\n",
    "        # 2nd ex: if prop = 30% & eco is CR/EN(KBA 5%); then 6 x 5% KBA = 30% \n",
    "        # end_count = 6 (@ 1.0 test), 12 @ 0.50 test and 24 @ 0.25 test\n",
    "        end_count = round(prop/(ecoinfo_df['Current_IUCN_TH'] * test))\n",
    "        count = 1\n",
    "        \n",
    "        # create path for 'pu_selected' file in 'scen_id' directory\n",
    "        pu_selected_path = os.path.normpath(\n",
    "            os.path.join(new_dir, 'eco_' + eco, scen_id, \n",
    "                         scen_id + '_pu_selected.csv'))\n",
    "        pu_selected.to_csv(pu_selected_path)\n",
    "        \n",
    "        # create path for 'updated_pu_dat' file in 'scen_id' directory\n",
    "        updated_pu_dat_path = os.path.normpath(\n",
    "            os.path.join(new_dir, 'eco_' + eco, scen_id, \n",
    "                         scen_id + '_updated_pu.dat'))\n",
    "        updated_pu_dat.to_csv(updated_pu_dat_path)\n",
    "        \n",
    "        # BEGIN MULTILOOP FOR EACH TEST IN EACH ECOSYSTEM DIRECTORY        \n",
    "        while count <= end_count[eco]:\n",
    "            # create directory for loop, to store Marxan input/output files\n",
    "            os.chdir(ecotest_data_path)\n",
    "            loop_count = 'loop_' + str(f\"{count:02d}\")\n",
    "            os.makedirs(loop_count)\n",
    "            loop_count_path = os.path.normcase(os.path.join(\n",
    "                ecotest_data_path, loop_count))\n",
    "            os.chdir(loop_count_path)\n",
    "            \n",
    "            # COPY IN INPUT FILE FROM 'orig_input_files' DIRECTORY\n",
    "            shutil.copy(input_dat_path, os.getcwd())\n",
    "\n",
    "            # CREATE INPUT DIRECTORY\n",
    "            # which is where the four remaining .dat files will be stored\n",
    "            os.makedirs('input')\n",
    "            eco_input_data_path = os.path.normpath(os.path.join(\n",
    "                ecotest_data_path, loop_count, 'input'))\n",
    "            os.chdir(eco_input_data_path)\n",
    "            \n",
    "            # COPY IN THE 3 DAT FILES THAT WILL REMAIN UNCHANGED AS LOOPCOUNT\n",
    "            # PROGRESSES (bound.dat, puvsp.dat and spec.dat) \n",
    "            unchanged_dat_files = (bound_dat_path, \n",
    "                                   puvsp_dat_path, \n",
    "                                   spec_dat_path)\n",
    "            for file in unchanged_dat_files:\n",
    "                shutil.copy(file, os.getcwd())\n",
    "        \n",
    "            # GET APPROPRIATE 'pu.dat' FILE FOR LOOPCOUNT\n",
    "            # This is where the loopcount determines if the original 'pu.dat' \n",
    "            # file should be used (if Loop 1), or if the 'updated pu.dat' file\n",
    "            # generated from the previous loops should be used (Loops 2-End) \n",
    "            if count == 1:\n",
    "                shutil.copy(orig_pu_dat_path, os.getcwd())\n",
    "                pu_dat = pd.read_csv(orig_pu_dat_path)\n",
    "            else:\n",
    "                shutil.copy(updated_pu_dat_path, os.getcwd())\n",
    "                os.rename(scen_id + '_updated_pu.dat','pu.dat')\n",
    "            \n",
    "            # create remaining directories\n",
    "            os.chdir(loop_count_path)\n",
    "            os.makedirs('output')\n",
    "            os.makedirs('report')\n",
    "            os.makedirs('pu')      \n",
    "\n",
    "            # BEGIN MARXAN ANALYSIS RUN\n",
    "            print('\\n\\n' + scen_id + \" \" + loop_count + \n",
    "                  ': MARXAN ANALYSIS INITIATED')   \n",
    "            # call on marxan executable (currently using v2.43)\n",
    "            os.startfile(marxan_243_path)\n",
    "            \n",
    "            # DEFINE A PAUSE FOR MARXAN EXECUTION, USING ONE OF TWO METHODS\n",
    "            # This is needed to allow Marxan time to finish writing \n",
    "            # output files before the workflow tries to locate them            \n",
    "            # NOTE: ONE OPTION MUST BE COMMENTED OUT BEFORE RUNNING THE CELL \n",
    "            \n",
    "            # OPTION 1: Hit Enter to Continue \n",
    "            # Wait for Marxan pop-up execution to complete, then press 'Enter'\n",
    "            # at prompt in screen output window after 'The End' is seen\n",
    "            # (overall quickest, but requires attention)\n",
    "#             def pause():\n",
    "#                 programPause = input(\"Press the <ENTER> key to continue...\")\n",
    "#             pause()\n",
    "#             print('Wait to see 'The End' at bottom of Marxan execution '\n",
    "#                  'pop-up before pressing Enter')\n",
    "\n",
    "            # OPTION 2: Set sleep timer length\n",
    "            # Define a sleep timer so that Python will simply count down that \n",
    "            # number of seconds before moving on. Need to ensure that the \n",
    "            # sleep time set > filewriting/execution, or errors in reading \n",
    "            # output files will occur\n",
    "            # (automates the workflow, but takes longer time overall)\n",
    "            print('time.sleep(15) applied to pause workflow execution while '\n",
    "                  'Marxan output files are written')\n",
    "            time.sleep(2) # Sleep for 10 seconds\n",
    "          \n",
    "            # WHEN MARXAN COMPLETES, GET BEST RUN SOLUTION AND UPDATE PU.DAT\n",
    "\n",
    "            # 1- test for output files, to see if run completed successfully\n",
    "            # open '_best' file created by Marxan and saved to 'output' dir\n",
    "            globfile_best = glob(os.path.normpath(os.path.join(\n",
    "                ecotest_data_path, loop_count, 'output', '*_best.csv')))            \n",
    "            # if no file is found, print error message to screen\n",
    "            if globfile_best == []:\n",
    "                output = print (scen_id + \": ERROR: 'pu_selected' file not \"\n",
    "                                \"found - check output/log. \\nWill need to \"\n",
    "                                \"resolve error and rerun Marxan if final \"\n",
    "                                \"output files haven't completed successfully\")  \n",
    "            else:\n",
    "                #Create list of the selected cells from 'best_run' output file\n",
    "                best_run_file = pd.read_csv(globfile_best[0])\n",
    "                selected_df = best_run_file[best_run_file['SOLUTION'] == 1]\n",
    "                selected_cells = selected_df['PUID'].tolist()\n",
    "                print(selected_cells)\n",
    "                for puid in selected_cells:\n",
    "                    # Update the status of those cells in pu.dat from \n",
    "                    # '0'-available to '3'-unavailable/locked-out\n",
    "                    updated_pu_dat.at[puid,'status']=3\n",
    "                    # Update the status of those cells in pu_select's select \n",
    "                    # column to show in which run they were selected\n",
    "                    pu_selected.at[puid, 'select'] = (\n",
    "                        'Select_' + str(f\"{count:02d}\"))\n",
    "                # add additional summary info to 'pu_selected'\n",
    "                pu_selected['dir_path'] = new_dir\n",
    "                pu_selected['Short_Name'] = eco               \n",
    "                pu_selected['current_test_level'] = test\n",
    "                pu_selected['Current_IUCN_TH'] = current_iucn_th\n",
    "                pu_selected['US_km2'] = us_km2\n",
    "                pu_selected['US_m2'] = us_m2\n",
    "                pu_selected['30% of US_m2'] = us_m2*prop\n",
    "                pu_selected['KBA @ current test (m_2)'] = target2\n",
    "                pu_selected['BLM'] = blm\n",
    "                pu_selected['SPF'] = spf\n",
    "                # save updated 'updated_pu_dat' file for next loop\n",
    "                updated_pu_dat.to_csv(updated_pu_dat_path)\n",
    "\n",
    "            # add +1 to count, and continue 'while' loop\n",
    "            count = count+1\n",
    "            os.chdir(eco_data_path)\n",
    "            \n",
    "            # save 'pu_selected' file at ecotest_path level (ex mesic025)\n",
    "            pu_selected.to_csv(pu_selected_path) \n",
    "\n",
    "            print(scen_id + ('info from ' + scen_id + \n",
    "                             ' will be added to final summary\\n'))\n",
    "            # Append 'pu_selected' to 'select_summary_df' for final summary df\n",
    "            select_summary_ls.append(pu_selected)\n",
    "        \n",
    "# save info from loop stored in 'select_summary_ls' to '_final_summary.csv'\n",
    "final_summary_df = pd.concat(select_summary_ls)\n",
    "final_summary_df.to_csv(os.path.normpath(\n",
    "os.path.join(new_dir, 'final_summary.csv')), index=False)\n",
    "print(\"\\n'final_summary.csv' saved to \" + new_dir)\n",
    "        \n",
    "os.getcwd()\n",
    "print('\\nloop completed successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "629dea51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'break_here' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23284\\3726834190.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# inserting line to break execution betweeen workflow loops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbreak_here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'break_here' is not defined"
     ]
    }
   ],
   "source": [
    "# inserting line to break execution betweeen workflow loops\n",
    "# (so that file writing can complete before final summary process begins)\n",
    "break_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7db2f77c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_dir C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\n",
      "ecotestdirs include 12 directories\n",
      "ecotest_data_path C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\mesic10_run\n",
      "\n",
      "Begin loop for scen_id: dome025_run\n",
      "C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\dome025_run\n",
      "cwd C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\dome025_run\\selected_plot\n",
      "globfile_selected contains: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\dome025_run\\dome025_run_pu_selected.csv\n",
      "shp_layer_crs_path: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\source_data\\dome_espg_5070.shp\n",
      "eco: dome\n",
      "reprojected shp file check = PASS\n",
      "dome025_run_merged.shp file check = PASS\n",
      "dome025_run : merged shapefile saved to 'selected_plot' directory\n",
      "reprojected tif file check = PASS\n",
      "dome025_run: dome025_run'_merged_results.csv' saved to 'selected_plot' dir\n",
      "preparing plots...\n",
      "selected_km: 481.5009\n",
      "eco_extent_km: 810\n",
      "conserv_tgt_km: 243.0\n",
      "selected_prop: 0.5944455555555556\n",
      "target2_km: 20.25\n",
      "target2_m: 20250000.0\n",
      "test_level: 0.25\n",
      "current_iucn_th: 0.1\n",
      "eco_extent_m: 810000000\n",
      "dome025_run: _pu_selections_over_raster saved as .png\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "dome025_runinfo from dome025_run will be added to final summary\n",
      "\n",
      "\n",
      "Begin loop for scen_id: dome05_run\n",
      "C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\dome05_run\n",
      "cwd C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\dome05_run\\selected_plot\n",
      "globfile_selected contains: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\dome05_run\\dome05_run_pu_selected.csv\n",
      "shp_layer_crs_path: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\source_data\\dome_espg_5070.shp\n",
      "eco: dome\n",
      "reprojected shp file check = PASS\n",
      "dome05_run_merged.shp file check = PASS\n",
      "dome05_run : merged shapefile saved to 'selected_plot' directory\n",
      "reprojected tif file check = PASS\n",
      "dome05_run: dome05_run'_merged_results.csv' saved to 'selected_plot' dir\n",
      "preparing plots...\n",
      "selected_km: 685.1466\n",
      "eco_extent_km: 810\n",
      "conserv_tgt_km: 243.0\n",
      "selected_prop: 0.8458600000000001\n",
      "target2_km: 40.5\n",
      "target2_m: 40500000.0\n",
      "test_level: 0.5\n",
      "current_iucn_th: 0.1\n",
      "eco_extent_m: 810000000\n",
      "dome05_run: _pu_selections_over_raster saved as .png\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "dome05_runinfo from dome05_run will be added to final summary\n",
      "\n",
      "\n",
      "Begin loop for scen_id: dome075_run\n",
      "C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\dome075_run\n",
      "cwd C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\dome075_run\\selected_plot\n",
      "globfile_selected contains: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\dome075_run\\dome075_run_pu_selected.csv\n",
      "shp_layer_crs_path: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\source_data\\dome_espg_5070.shp\n",
      "eco: dome\n",
      "reprojected shp file check = PASS\n",
      "dome075_run_merged.shp file check = PASS\n",
      "dome075_run : merged shapefile saved to 'selected_plot' directory\n",
      "reprojected tif file check = PASS\n",
      "dome075_run: dome075_run'_merged_results.csv' saved to 'selected_plot' dir\n",
      "preparing plots...\n",
      "selected_km: 810.2106\n",
      "eco_extent_km: 810\n",
      "conserv_tgt_km: 243.0\n",
      "selected_prop: 1.00026\n",
      "target2_km: 60.75000000000001\n",
      "target2_m: 60750000.00000001\n",
      "test_level: 0.75\n",
      "current_iucn_th: 0.1\n",
      "eco_extent_m: 810000000\n",
      "dome075_run: _pu_selections_over_raster saved as .png\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "dome075_runinfo from dome075_run will be added to final summary\n",
      "\n",
      "\n",
      "Begin loop for scen_id: dome10_run\n",
      "C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\dome10_run\n",
      "cwd C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\dome10_run\\selected_plot\n",
      "globfile_selected contains: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\dome10_run\\dome10_run_pu_selected.csv\n",
      "shp_layer_crs_path: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dome\\source_data\\dome_espg_5070.shp\n",
      "eco: dome\n",
      "reprojected shp file check = PASS\n",
      "dome10_run_merged.shp file check = PASS\n",
      "dome10_run : merged shapefile saved to 'selected_plot' directory\n",
      "reprojected tif file check = PASS\n",
      "dome10_run: dome10_run'_merged_results.csv' saved to 'selected_plot' dir\n",
      "preparing plots...\n",
      "selected_km: 245.1132\n",
      "eco_extent_km: 810\n",
      "conserv_tgt_km: 243.0\n",
      "selected_prop: 0.30260888888888887\n",
      "target2_km: 81.0\n",
      "target2_m: 81000000.0\n",
      "test_level: 1.0\n",
      "current_iucn_th: 0.1\n",
      "eco_extent_m: 810000000\n",
      "dome10_run: _pu_selections_over_raster saved as .png\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "dome10_runinfo from dome10_run will be added to final summary\n",
      "\n",
      "\n",
      "Begin loop for scen_id: dune025_run\n",
      "C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\dune025_run\n",
      "cwd C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\dune025_run\\selected_plot\n",
      "globfile_selected contains: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\dune025_run\\dune025_run_pu_selected.csv\n",
      "shp_layer_crs_path: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\source_data\\dune_espg_5070.shp\n",
      "eco: dune\n",
      "reprojected shp file check = PASS\n",
      "dune025_run_merged.shp file check = PASS\n",
      "dune025_run : merged shapefile saved to 'selected_plot' directory\n",
      "reprojected tif file check = PASS\n",
      "dune025_run: dune025_run'_merged_results.csv' saved to 'selected_plot' dir\n",
      "preparing plots...\n",
      "selected_km: 12.1995\n",
      "eco_extent_km: 18\n",
      "conserv_tgt_km: 5.3999999999999995\n",
      "selected_prop: 0.6777500000000001\n",
      "target2_km: 0.225\n",
      "target2_m: 225000.0\n",
      "test_level: 0.25\n",
      "current_iucn_th: 0.05\n",
      "eco_extent_m: 18000000\n",
      "dune025_run: _pu_selections_over_raster saved as .png\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "dune025_runinfo from dune025_run will be added to final summary\n",
      "\n",
      "\n",
      "Begin loop for scen_id: dune05_run\n",
      "C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\dune05_run\n",
      "cwd C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\dune05_run\\selected_plot\n",
      "globfile_selected contains: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\dune05_run\\dune05_run_pu_selected.csv\n",
      "shp_layer_crs_path: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\source_data\\dune_espg_5070.shp\n",
      "eco: dune\n",
      "reprojected shp file check = PASS\n",
      "dune05_run_merged.shp file check = PASS\n",
      "dune05_run : merged shapefile saved to 'selected_plot' directory\n",
      "reprojected tif file check = PASS\n",
      "dune05_run: dune05_run'_merged_results.csv' saved to 'selected_plot' dir\n",
      "preparing plots...\n",
      "selected_km: 17.1747\n",
      "eco_extent_km: 18\n",
      "conserv_tgt_km: 5.3999999999999995\n",
      "selected_prop: 0.95415\n",
      "target2_km: 0.45\n",
      "target2_m: 450000.0\n",
      "test_level: 0.5\n",
      "current_iucn_th: 0.05\n",
      "eco_extent_m: 18000000\n",
      "dune05_run: _pu_selections_over_raster saved as .png\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "dune05_runinfo from dune05_run will be added to final summary\n",
      "\n",
      "\n",
      "Begin loop for scen_id: dune075_run\n",
      "C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\dune075_run\n",
      "cwd C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\dune075_run\\selected_plot\n",
      "globfile_selected contains: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\dune075_run\\dune075_run_pu_selected.csv\n",
      "shp_layer_crs_path: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\source_data\\dune_espg_5070.shp\n",
      "eco: dune\n",
      "reprojected shp file check = PASS\n",
      "dune075_run_merged.shp file check = PASS\n",
      "dune075_run : merged shapefile saved to 'selected_plot' directory\n",
      "reprojected tif file check = PASS\n",
      "dune075_run: dune075_run'_merged_results.csv' saved to 'selected_plot' dir\n",
      "preparing plots...\n",
      "selected_km: 17.7453\n",
      "eco_extent_km: 18\n",
      "conserv_tgt_km: 5.3999999999999995\n",
      "selected_prop: 0.98585\n",
      "target2_km: 0.6750000000000002\n",
      "target2_m: 675000.0000000001\n",
      "test_level: 0.75\n",
      "current_iucn_th: 0.05\n",
      "eco_extent_m: 18000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dune075_run: _pu_selections_over_raster saved as .png\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "dune075_runinfo from dune075_run will be added to final summary\n",
      "\n",
      "\n",
      "Begin loop for scen_id: dune10_run\n",
      "C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\dune10_run\n",
      "cwd C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\dune10_run\\selected_plot\n",
      "globfile_selected contains: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\dune10_run\\dune10_run_pu_selected.csv\n",
      "shp_layer_crs_path: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_dune\\source_data\\dune_espg_5070.shp\n",
      "eco: dune\n",
      "reprojected shp file check = PASS\n",
      "dune10_run_merged.shp file check = PASS\n",
      "dune10_run : merged shapefile saved to 'selected_plot' directory\n",
      "reprojected tif file check = PASS\n",
      "dune10_run: dune10_run'_merged_results.csv' saved to 'selected_plot' dir\n",
      "preparing plots...\n",
      "selected_km: 5.6763\n",
      "eco_extent_km: 18\n",
      "conserv_tgt_km: 5.3999999999999995\n",
      "selected_prop: 0.31535\n",
      "target2_km: 0.9\n",
      "target2_m: 900000.0\n",
      "test_level: 1.0\n",
      "current_iucn_th: 0.05\n",
      "eco_extent_m: 18000000\n",
      "dune10_run: _pu_selections_over_raster saved as .png\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "dune10_runinfo from dune10_run will be added to final summary\n",
      "\n",
      "\n",
      "Begin loop for scen_id: mesic025_run\n",
      "C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\mesic025_run\n",
      "cwd C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\mesic025_run\\selected_plot\n",
      "globfile_selected contains: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\mesic025_run\\mesic025_run_pu_selected.csv\n",
      "shp_layer_crs_path: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\source_data\\mesic_espg_5070.shp\n",
      "eco: mesic\n",
      "reprojected shp file check = PASS\n",
      "mesic025_run_merged.shp file check = PASS\n",
      "mesic025_run : merged shapefile saved to 'selected_plot' directory\n",
      "reprojected tif file check = PASS\n",
      "mesic025_run: mesic025_run'_merged_results.csv' saved to 'selected_plot' dir\n",
      "preparing plots...\n",
      "selected_km: 622.9152\n",
      "eco_extent_km: 982\n",
      "conserv_tgt_km: 294.59999999999997\n",
      "selected_prop: 0.6343331975560081\n",
      "target2_km: 12.275\n",
      "target2_m: 12275000.0\n",
      "test_level: 0.25\n",
      "current_iucn_th: 0.05\n",
      "eco_extent_m: 982000000\n",
      "mesic025_run: _pu_selections_over_raster saved as .png\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "mesic025_runinfo from mesic025_run will be added to final summary\n",
      "\n",
      "\n",
      "Begin loop for scen_id: mesic05_run\n",
      "C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\mesic05_run\n",
      "cwd C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\mesic05_run\\selected_plot\n",
      "globfile_selected contains: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\mesic05_run\\mesic05_run_pu_selected.csv\n",
      "shp_layer_crs_path: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\source_data\\mesic_espg_5070.shp\n",
      "eco: mesic\n",
      "reprojected shp file check = PASS\n",
      "mesic05_run_merged.shp file check = PASS\n",
      "mesic05_run : merged shapefile saved to 'selected_plot' directory\n",
      "reprojected tif file check = PASS\n",
      "mesic05_run: mesic05_run'_merged_results.csv' saved to 'selected_plot' dir\n",
      "preparing plots...\n",
      "selected_km: 896.0688\n",
      "eco_extent_km: 982\n",
      "conserv_tgt_km: 294.59999999999997\n",
      "selected_prop: 0.9124936863543788\n",
      "target2_km: 24.55\n",
      "target2_m: 24550000.0\n",
      "test_level: 0.5\n",
      "current_iucn_th: 0.05\n",
      "eco_extent_m: 982000000\n",
      "mesic05_run: _pu_selections_over_raster saved as .png\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "mesic05_runinfo from mesic05_run will be added to final summary\n",
      "\n",
      "\n",
      "Begin loop for scen_id: mesic075_run\n",
      "C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\mesic075_run\n",
      "cwd C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\mesic075_run\\selected_plot\n",
      "globfile_selected contains: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\mesic075_run\\mesic075_run_pu_selected.csv\n",
      "shp_layer_crs_path: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\source_data\\mesic_espg_5070.shp\n",
      "eco: mesic\n",
      "reprojected shp file check = PASS\n",
      "mesic075_run_merged.shp file check = PASS\n",
      "mesic075_run : merged shapefile saved to 'selected_plot' directory\n",
      "reprojected tif file check = PASS\n",
      "mesic075_run: mesic075_run'_merged_results.csv' saved to 'selected_plot' dir\n",
      "preparing plots...\n",
      "selected_km: 981.8604\n",
      "eco_extent_km: 982\n",
      "conserv_tgt_km: 294.59999999999997\n",
      "selected_prop: 0.9998578411405296\n",
      "target2_km: 36.82500000000001\n",
      "target2_m: 36825000.00000001\n",
      "test_level: 0.75\n",
      "current_iucn_th: 0.05\n",
      "eco_extent_m: 982000000\n",
      "mesic075_run: _pu_selections_over_raster saved as .png\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "mesic075_runinfo from mesic075_run will be added to final summary\n",
      "\n",
      "\n",
      "Begin loop for scen_id: mesic10_run\n",
      "C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\mesic10_run\n",
      "cwd C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\mesic10_run\\selected_plot\n",
      "globfile_selected contains: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\mesic10_run\\mesic10_run_pu_selected.csv\n",
      "shp_layer_crs_path: C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\\eco_mesic\\source_data\\mesic_espg_5070.shp\n",
      "eco: mesic\n",
      "reprojected shp file check = PASS\n",
      "mesic10_run_merged.shp file check = PASS\n",
      "mesic10_run : merged shapefile saved to 'selected_plot' directory\n",
      "reprojected tif file check = PASS\n",
      "mesic10_run: mesic10_run'_merged_results.csv' saved to 'selected_plot' dir\n",
      "preparing plots...\n",
      "selected_km: 303.4503\n",
      "eco_extent_km: 982\n",
      "conserv_tgt_km: 294.59999999999997\n",
      "selected_prop: 0.3090125254582485\n",
      "target2_km: 49.1\n",
      "target2_m: 49100000.0\n",
      "test_level: 1.0\n",
      "current_iucn_th: 0.05\n",
      "eco_extent_m: 982000000\n",
      "mesic10_run: _pu_selections_over_raster saved as .png\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "mesic10_runinfo from mesic10_run will be added to final summary\n",
      "\n",
      "\n",
      "begin loop for dome\n",
      "dome_hexcell_as%_total_extent saved as .png'\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "\n",
      "begin loop for dune\n",
      "dune_hexcell_as%_total_extent saved as .png'\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "\n",
      "begin loop for mesic\n",
      "mesic_hexcell_as%_total_extent saved as .png'\n",
      "\n",
      "\n",
      "and will be included in 'final_plots.pdf'\n",
      "\n",
      "'shp_summary.csv' saved to C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\n",
      "\n",
      "'final_plots.pdf' saved to C:\\Users\\cwsnd\\earth-analytics\\data\\kba_thresh_sa\\20220628_103352_fullrun_2plots\n",
      "\n",
      "loop completed successfully\n"
     ]
    }
   ],
   "source": [
    "# 2ND PART OF CURRENT WORKFLOW - MARXAN 2.43 or 4.06 ONLY\n",
    "\n",
    "# THIS WILL MERGE INFORMATION FROM THE 'pu_selected' FILE CREATED IN 1ST \n",
    "# WORKFLOW TO THE HEX SHAPEFILE, IN ORDER TO BE ABLE TO SHOW WHICH HEXES WERE \n",
    "# SELECTED.  THEN THE 'puvsp.dat' INPUT FILE WILL BE MERGED TO THE SHAPEFILE, \n",
    "# TO PROVIDE THE AMOUNT OF ECOSYSTEM (in m2) CONTAINED IN EACH HEX.  THIS \n",
    "# ALLOWS THE AREA OF THE SELECTION TO BE MEASURED AND PLOTTED, TO DETERMINE \n",
    "# IF THE SOLUTION MEETS REQUIREMENTS.  SUMMARY INFORMATION FROM THE RUNS WILL \n",
    "# ALSO BE COLLECTED AND SAVED TO A .CSV FILE FOR FURTHER ANALYSIS.\n",
    "\n",
    "# Create empty lists outside the loop to store information:\n",
    "# for plot images \n",
    "plot_im_list = []\n",
    "\n",
    "# for info from shapefile, after its merged with 'puvsp.dat' and 'pu_selected'\n",
    "shp_summary_ls = []\n",
    "\n",
    "os.chdir(new_dir)\n",
    "print('\\nnew_dir ' + new_dir)\n",
    "\n",
    "# Define 'ecotestdirs' glob list, to find all directories ending in '*_run' \n",
    "# (ex. 'dome025_run')\n",
    "ecotestdirs = sorted(glob(os.path.join(data_path, '*' + testrun_basename, '*', \n",
    "                                       '*_run')))\n",
    "print('ecotestdirs include ' + str(len(ecotestdirs)) + ' directories')\n",
    "print('ecotest_data_path ' + ecotest_data_path)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for ecotestdir in ecotestdirs:\n",
    "\n",
    "    scen_id = os.path.split(ecotestdirs[count])[1]\n",
    "    print('\\nBegin loop for scen_id: ' + scen_id)\n",
    "    os.chdir(ecotestdir)\n",
    "    print(ecotestdir)\n",
    "    get_eco = (''.join([i for i in scen_id if not i.isdigit()]))\n",
    "    eco = get_eco.replace(get_eco[(len(get_eco)-4):], '')\n",
    "    eco_data_path = os.path.normpath(os.path.join(new_dir, 'eco_' + eco))\n",
    "    ecotest_data_path = os.path.normpath(os.path.join(new_dir, 'eco_' + eco, \n",
    "                                                      scen_id))\n",
    "    \n",
    "    # create 'selected_plot' dir if it doesn't already exist\n",
    "    # (this is where the plots showing selected hexes will be stored)\n",
    "    selected_plot_dir_path = os.path.normpath(os.path.join(ecotestdir, \n",
    "                                                          'selected_plot'))\n",
    "    if os.path.isdir(selected_plot_dir_path):\n",
    "        os.chdir(selected_plot_dir_path)\n",
    "    else:\n",
    "        os.makedirs('selected_plot')\n",
    "        os.chdir('selected_plot')\n",
    "    print('cwd ' + os.getcwd())\n",
    "   \n",
    "    # try to open 'pu_selected' file created in first workflow loop cell \n",
    "    globfile_selected = glob(os.path.normpath(\n",
    "        os.path.join(ecotestdir, '*pu_selected*')))\n",
    "    print('globfile_selected contains: ' + globfile_selected[0])\n",
    "    if globfile_selected == []:\n",
    "        output = print (scen_id + \": ERROR: 'pu_selected' file not found\")\n",
    "    else:\n",
    "        # If found, merge 'pu_selected' with reprojected copy of the shp file\n",
    "        # check if reprojected shp in 'source_data' already exists; create if\n",
    "        # not found\n",
    "        shp_layer_crs_path = os.path.normpath(os.path.join(\n",
    "            new_dir, \n",
    "            'eco_' + eco, \n",
    "            'source_data', \n",
    "            eco + \"_espg_\" + espg +'.shp'))\n",
    "        print('shp_layer_crs_path: ' + shp_layer_crs_path)\n",
    "        print('eco: ' + eco)\n",
    "        if glob(os.path.normpath(os.path.join(\n",
    "            new_dir, '*', 'source_data', eco + \"_espg_\" + espg +'.shp'))):\n",
    "            print('reprojected shp file check = PASS')\n",
    "        else:\n",
    "            # open the original shp file from 'eco_data_path/source_data' \n",
    "            orig_shp_data_path = glob(os.path.join(new_dir, '*', \n",
    "                                                   \"source_data\", \n",
    "                                                   eco + '.shp'))[0]\n",
    "            print('\\n reprojecting source shapefile;\\norig_shp_data_path ' \n",
    "                  + orig_shp_data_path)\n",
    "            orig_shp_layer = gpd.read_file(orig_shp_data_path)\n",
    "            # reproject CRS of shp\n",
    "            shp_layer_crs = orig_shp_layer.to_crs(epsg=espg)\n",
    "            # create new .shp file\n",
    "            shp_layer_crs.to_file(shp_layer_crs_path, index=False)\n",
    "\n",
    "        # open reprojected shp layer and prepare to merge with other files\n",
    "        merged_shp = gpd.read_file(shp_layer_crs_path)\n",
    "        # merge reprojected shp file with 'pu_selected' & 'puvsp_dat' dfs                \n",
    "        # add 'id' index to enable merge with other files\n",
    "        merged_shp.insert(0, 'id', range(1, 1 + len(merged_shp)))\n",
    "        merged_shp.set_index('id')\n",
    "        # get 'pu_selected' file from 'globfile_selected' list\n",
    "        pu_selected_path = globfile_selected[0]\n",
    "        pu_selected = pd.read_csv(pu_selected_path).set_index('id')\n",
    "        # merge 'pu_selected' to shp layer (adds 'select' column, & more *)\n",
    "        merged_shp = merged_shp.merge(pu_selected, on='id')\n",
    "        # open 'puvsp.dat' from input directory\n",
    "        puvsp_path = glob(os.path.normpath(os.path.join(ecotestdir, '*', \n",
    "                                                        'input', \n",
    "                                                        'puvsp.dat')))[0]\n",
    "        # merge with shp layer to get 'amount' from puvsp\n",
    "        puvsp_dat = pd.read_csv(puvsp_path)\n",
    "        puvsp_dat = puvsp_dat.rename(columns={'pu': 'id'}).set_index('id')\n",
    "        merged_shp = merged_shp.merge(puvsp_dat, on='id')\n",
    "        \n",
    "        # use 'amount' value to calculate 'percent_of_total' \n",
    "        # (the proportion of total ecosystem extent found in each hexcell)\n",
    "        merged_shp['percent_of_total'] = (\n",
    "            merged_shp['amount']/merged_shp['US_m2'])\n",
    "#         print('percent of total: ' + merged_shp[percent_of_total])\n",
    "#         print(merged_shp)\n",
    "\n",
    "        # save merged shapefile as new file\n",
    "        # check if file already exists, if not create it\n",
    "        merged_shp_layer_path = os.path.normpath(os.path.join(\n",
    "            ecotest_data_path,\n",
    "            'selected_plot', \n",
    "            scen_id + \"_merged.shp\"))\n",
    "        if os.path.exists(merged_shp_layer_path):\n",
    "            print(scen_id + \"_merged.shp file check = PASS\")\n",
    "        else:\n",
    "            # save merged shp with add'l 'selected' info as new shape file\n",
    "            # THIS WOULD BE THE TIME TO CHECK FOR COLUMN NAMES >10 CHARS\n",
    "            merged_shp.to_file(merged_shp_layer_path, index=False)\n",
    "            print (scen_id + ': ' + eco + '.shp merged with ' + scen_id + \n",
    "                   \"'pu_selected' and 'puvsp.dat', saved as \" + scen_id +\n",
    "                   \"merged.shp\") \n",
    "        # verify shp file exists, and print update to screen\n",
    "        if os.path.exists(merged_shp_layer_path):\n",
    "            print(scen_id + \" : merged shapefile saved to 'selected_plot' \"\n",
    "                  \"directory\") \n",
    "        else:\n",
    "            print(scen_id + (\": Error: reprojected shapefile was not able\"\n",
    "               \" to be saved\"))\n",
    "\n",
    "        # check if reprojected tif in 'source_data' exists, if not create it\n",
    "        tif_layer_crs_path = os.path.normpath(os.path.join(\n",
    "            new_dir, 'eco_' + eco, 'source_data', \n",
    "            eco + \"_espg_\" + espg +'.tif'))\n",
    "        if os.path.exists(tif_layer_crs_path):\n",
    "            print('reprojected tif file check = PASS')\n",
    "        else:\n",
    "            # open the tif file saved at 'eco_data_path/source_data' location\n",
    "            tif_data_path = os.path.join(new_dir, 'eco_' + eco, 'source_data', \n",
    "                                         eco + '.tif')\n",
    "            tif_layer = rxr.open_rasterio(tif_data_path, \n",
    "                                          masked=True).squeeze()\n",
    "            # reproject CRS of tif - \n",
    "            # first create a rasterio crs object\n",
    "            crs_espg = CRS.from_string('EPSG:' + espg)\n",
    "            # then reproject tif using the crs object\n",
    "            tif_layer_crs = tif_layer.rio.reproject(crs_espg)\n",
    "            # create new .tif file\n",
    "            tif_layer_crs.rio.to_raster(tif_layer_crs_path)\n",
    "            # verify tif file exits, and print update to screen\n",
    "            if os.path.exists(tif_layer_crs_path):\n",
    "                print(scen_id + ': Raster reprojected to ESPG: ' + espg + \n",
    "                      \" and saved to 'source_data' directory\")\n",
    "            else:\n",
    "                print(scen_id + (\": Error: reprojected raster was not \"\n",
    "                                 \"able to be saved\"))\n",
    "\n",
    "        # get data from merged shp, to include in 'final_summary.csv'  \n",
    "        merged_shp_df = merged_shp[['id', \n",
    "                                    'amount',\n",
    "                                    'percent_of_total',\n",
    "                                    'select',\n",
    "                                    'Short_Name',\n",
    "                                    'Current_IUCN_TH',\n",
    "                                    'current_test_level',\n",
    "                                    'KBA @ current test (m_2)',\n",
    "                                    'US_km2',\n",
    "                                    'US_m2',\n",
    "                                    '30% of US_m2',\n",
    "                                    'BLM',\n",
    "                                    'SPF',\n",
    "                                    'dir_path',]].copy()\n",
    "                \n",
    "        merged_shp_df.set_index('id')\n",
    "\n",
    "        merged_shp_df.to_csv(scen_id + '_merged_results.csv')\n",
    "        print (scen_id + ': ' + scen_id + (\"'_merged_results.csv' saved \"\n",
    "                                           \"to 'selected_plot' dir\"))\n",
    "        ###    \n",
    "\n",
    "        # CREATE PLOT SHOWING MULITPLE LOOP'S SELECTIONS OVER THE RASTER\n",
    "        # * VISUALIZATIONS SHOWING HEXCELL SELECTION FROM BEST RUN AND \n",
    "        # HEATMAP OF HEXCELL EXTENT AS A PROPORTION OF TOTAL EXTENT\n",
    "        # solution, and save each as a .png image file\n",
    "        print ('preparing plots...')\n",
    "\n",
    "        # define raster extent for plotting\n",
    "        raster_extent = plotting_extent(tif_layer_crs,\n",
    "                                         tif_layer_crs.rio.transform())\n",
    "        \n",
    "        # get metrics to include in figtitle\n",
    "        # total amount (m2) of ecosystem included in selection\n",
    "        selected_m = merged_shp.query(\n",
    "            \"select!='not selected'\")['amount'].sum()\n",
    "        selected_km = selected_m/1000000\n",
    "        selected_m_string = str(\"{:,.2f}\".format(selected_m))\n",
    "        selected_km_string = str(\"{:,.2f}\".format(selected_km))\n",
    "\n",
    "        # get total extent of ecosystem (from the amount column, in puvsp.dat)\n",
    "        eco_extent_km = eco_subset_df.at[eco,'US_km2']\n",
    "        eco_extent_m = eco_extent_km * 1000000\n",
    "        eco_extent_km_string = str(\"{:,.2f}\".format(eco_extent_km))\n",
    "        eco_extent_m_string = str(\"{:,.2f}\".format(eco_extent_m))\n",
    "        \n",
    "        # get Conservation Target value (currently 30% x total extent)\n",
    "        conserv_tgt_km = prop * eco_extent_km\n",
    "        conserv_tgt_km_string = str(\"{:.2f}\".format(conserv_tgt_km))\n",
    "        \n",
    "        # get current test level\n",
    "#         test_level = merged_shp_df['current_test_level']\n",
    "#         test_level_string = str(\"{:.0%}\".format(test_level.mean())) \n",
    "        \n",
    "        # get selected proporion of total\n",
    "        selected_prop = selected_km / eco_extent_km\n",
    "        sel_prop_string = str(\"{:.2%}\".format(selected_prop))\n",
    "        \n",
    "        # set target2 value as string, for inclusion in figure title\n",
    "#         us_m2 = eco_subset_df.at[eco,'US_km2']*1000000\n",
    "        test_level = merged_shp_df['current_test_level'].mean()\n",
    "        test_level_string = str(\"{:.0%}\".format(test_level))\n",
    "        current_iucn_th = eco_subset_df.at[eco,'Current_IUCN_TH']\n",
    "        target2_m = (test_level * current_iucn_th * eco_extent_m).mean()\n",
    "        target2_km = target2_m/1000000\n",
    "        target2_m_string = str(\"{:,.2f}\".format(target2_m))\n",
    "        target2_km_string = str(\"{:,.2f}\".format(target2_km))\n",
    "        \n",
    "        # print figure title info to screen for validation\n",
    "        print('selected_km: ' + str(selected_km) + \n",
    "              '\\neco_extent_km: ' + str(eco_extent_km) + \n",
    "              '\\nconserv_tgt_km: ' + str(conserv_tgt_km) +\n",
    "              '\\nselected_prop: ' + str(selected_prop) +\n",
    "              '\\ntarget2_km: ' + str(target2_km) + \n",
    "              '\\ntarget2_m: ' + str(target2_m) + \n",
    "              '\\ntest_level: ' + str(test_level) +\n",
    "              '\\ncurrent_iucn_th: ' + str(current_iucn_th) +\n",
    "              '\\neco_extent_m: ' + str(eco_extent_m))\n",
    "    \n",
    "        # create strings for individual lines in figtitle\n",
    "        ft1 = (scen_id.upper() + \" - Searching for KBA @ \" + test_level_string \n",
    "               + \" Current IUCN Value\\n\")\n",
    "        ft2 = (\"Total Ecosytem Extent: \" + eco_extent_km_string + \" sq km\\n\")\n",
    "        ft3 = (\"Conservation Target: \" + conserv_tgt_km_string + \" sq km\\n\")\n",
    "        ft3 = (\"KBA target size: \" + target2_km_string + \" sq km\\n\")\n",
    "        ft4 = (\"Total Selected Ecosystem \" + selected_km_string + \"sq km\\n(\" +\n",
    "               sel_prop_string + \" of Total Extent)\")\n",
    "        \n",
    "        selected_title_txt = ft1 + ft2 + ft3 + ft4\n",
    "        \n",
    "        # PLOT (3 LAYERS) - BEST SELECTION, RASTER, AND BASEMAP\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        merged_shp.plot(column='select',\n",
    "                        cmap='nipy_spectral_r', # orig used viridis \n",
    "                        ax=ax, \n",
    "                        alpha=0.50, \n",
    "                        legend=True)\n",
    "                          \n",
    "        ax.set(title=selected_title_txt)\n",
    "#         ax.set_axis_off()\n",
    "        ax.axes.xaxis.set_visible(False)\n",
    "        ax.axes.yaxis.set_visible(False)\n",
    "        ax.patch.set_edgecolor('black')\n",
    "        cx.add_basemap(ax=ax, crs=shp_layer_crs.crs)\n",
    "        ax.imshow(tif_layer_crs, cmap='jet', extent=raster_extent, \n",
    "                  interpolation='nearest')\n",
    "        plt.savefig((scen_id + '_pu_selections_over_raster.png'), \n",
    "                    facecolor='w', edgecolor='k', dpi=600)\n",
    "        plt.close(fig)\n",
    "        print(scen_id + \": _pu_selections_over_raster saved as .png\\n\")\n",
    "\n",
    "        # convert 'selected' plot to image and add to 'plot_im_list', so \n",
    "        # that it'll be included in final pdf of plot images\n",
    "        plot_im = glob(os.path.normpath(os.path.join(\n",
    "            os.getcwd(), scen_id + \"_pu_selections_over_raster.png\")))\n",
    "        plot_im = Image.open(plot_im[0])\n",
    "        plot_im = plot_im.convert('RGB')\n",
    "        plot_im_list.append(plot_im) \n",
    "        print(\"\\nand will be included in 'final_plots.pdf'\")\n",
    "        print(scen_id + (\n",
    "            'info from ' + scen_id + ' will be added to final summary\\n'))\n",
    "        \n",
    "        count = count+1\n",
    "\n",
    "for eco in eco_list:\n",
    "    print('\\nbegin loop for ' + eco)\n",
    "    eco_data_path = os.path.normpath(os.path.join(new_dir, 'eco_' + eco))\n",
    "#     ecotest_data_path = os.path.normpath(os.path.join(new_dir, 'eco_' + eco, \n",
    "#                                                       scen_id))\n",
    "    os.chdir(eco_data_path)\n",
    "    \n",
    "    # define paths needed to get correct info for eco plot (no test level data needed)\n",
    "    merged_shp_layer_path = glob(os.path.normpath(os.path.join(\n",
    "        '*','selected_plot', '*_merged.shp')))[0]   \n",
    "    merged_shp = gpd.read_file(merged_shp_layer_path)\n",
    "    \n",
    "    # define raster extent for plotting\n",
    "    tif_layer_crs_path = os.path.normpath(os.path.join(\n",
    "            os.getcwd(), 'source_data', eco + \"_espg_\" + espg +'.tif'))\n",
    "#     tif_layer_crs_path = os.path.normpath(os.path.join(\n",
    "#             new_dir, 'eco_' + eco, 'source_data', \n",
    "#             eco + \"_espg_\" + espg +'.tif'))\n",
    "    tif_layer_crs = rxr.open_rasterio(tif_layer_crs_path, \n",
    "                                      masked=True).squeeze()\n",
    "    raster_extent = plotting_extent(tif_layer_crs,\n",
    "                                    tif_layer_crs.rio.transform())\n",
    "    \n",
    "    # PLOT (3 LAYERS) - 'PERCENT_OF_TOTAL', RASTER, AND BASEMAP\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "    fig.suptitle(t=(\"Percentage of the Total Ecosystem Extent \"\n",
    "                 \"Containined in Each Hexcell\\n\"))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    merged_shp.plot(column='percent_of', \n",
    "                    cmap='RdYlGn', \n",
    "                    ax=ax, \n",
    "                    alpha=0.65, \n",
    "                    legend=True)\n",
    "    ax.set(title=(eco + \": Percentage of Total Ecosystem Extent \"\n",
    "                  \"Containined in Each Hexcell\\n\"))\n",
    "    cx.add_basemap(ax=ax, crs=merged_shp.crs, \n",
    "                    source=cx.providers.CartoDB.Positron) \n",
    "    ax.imshow(tif_layer_crs, cmap='jet', extent=raster_extent,\n",
    "      interpolation='nearest')\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "    ax.set_title(eco.upper())\n",
    "    plt.savefig((eco + '_hexcell_as%_total_extent.png'), facecolor='w', \n",
    "                edgecolor='k', dpi=600)\n",
    "    print(eco + \"_hexcell_as%_total_extent saved as .png'\\n\")\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # THE FINAL PLOTS PDF ENDS UP GETTING 3 COPIES OF MESIC CURRENTLY?\n",
    "    \n",
    "    # convert '% of total' plot to image and add to 'plot_im_list', so \n",
    "    # that it'll be included in final pdf of plot images\n",
    "    plot_im = glob(os.path.normpath(os.path.join(\n",
    "    os.getcwd(), eco + \"_hexcell_as%_total_extent.png\")))\n",
    "    plot_im = Image.open(plot_im[0])\n",
    "    plot_im = plot_im.convert('RGB')\n",
    "    plot_im_list.append(plot_im) \n",
    "    print(\"\\nand will be included in 'final_plots.pdf'\")\n",
    "    \n",
    "#         ax.imshow(tif_layer_crs, cmap='jet', extent=raster_extent, \n",
    "#                   interpolation='nearest')\n",
    "#         plt.savefig((scen_id + '_pu_selections_over_raster.png'), \n",
    "#                     facecolor='w', edgecolor='k', dpi=600)\n",
    "#         plt.close(fig)\n",
    "#         print(scen_id + \": _pu_selections_over_raster saved as .png\\n\")\n",
    "\n",
    "    # Append 'merged_shp_df' to 'shp_summary_ls' for final summary df\n",
    "    shp_summary_ls.append(merged_shp_df)\n",
    "        \n",
    "# combine all dfs stored in the shp_summary_ls list into one pandas dataframe,\n",
    "# and then save that dataframe as a .csv file\n",
    "shp_summary_df = pd.concat(shp_summary_ls)\n",
    "shp_summary_df.to_csv(os.path.normpath(\n",
    "    os.path.join(new_dir, 'shp_summary.csv')), index=False)\n",
    "print(\"\\n'shp_summary.csv' saved to \" + new_dir)\n",
    "\n",
    "# save plot images to pdf (*currently duplicates the 1st image, needs fix)\n",
    "plots_pdf_path = os.path.normpath(os.path.join(new_dir, \n",
    "                                               'combined_plots.pdf'))\n",
    "plot_im_list[0].save(plots_pdf_path, save_all=True, \n",
    "                     append_images=plot_im_list)\n",
    "\n",
    "print(\"\\n'final_plots.pdf' saved to \" + new_dir)\n",
    "\n",
    "print('\\nloop completed successfully')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 424.844,
   "position": {
    "height": "717px",
    "left": "2236px",
    "right": "20px",
    "top": "176px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
